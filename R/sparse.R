#' NUTS sampling for TMB models using a sparse inverse mass
#' matrix (beta)
#'
#' @param obj The TMB object with random effects turned on and
#'   optimized
#' @param iter Total iterations to run (warmup + sampling)
#' @param warmup Total warmup iterations. Defaults to
#'   \code{iter}/2 based on Stan defaults, but when using dense,
#'   sparse, or diag metrics a much shorter warmup can be used
#'   (e.g., 150), especially if paired with a 'unit_e' Stan
#'   metric. Use \code{\link{plot_sampler_params}} to investigate
#'   warmup performance and adjust as necessary for subsequent
#'   runs.
#' @param metric A character specifying which metric to use.
#'   Defaults to "auto" which uses an algorithm to select the
#'   best metric (see details), otherwise one of "sparse",
#'   "dense", "diag", "unit", or "sparse-J" can be specified.
#' @param init Either 'last.par.best' (default), 'random',
#'   'random-t', or 'unif'. The former starts from the joint
#'   mode, while 'random' and 'random-t' draw from multivariate
#'   normal or multivariate t with 2 degrees of freedom
#'   distributions using the inverse joint precision matrix as a
#'   covariance matrix. 'random-t' is provided to allow for more
#'   dispersed initial values. 'unif' will draw U(-2,2) samples
#'   for all parameters, similar ot Stan's default behavior. If
#'   the joint NLL is undefined at the initial values then the
#'   model will exit and return the initial vector for further
#'   investigation by the user, if desired. Note that
#'   \code{\link{StanEstimators::stan_sample}} only allows for
#'   the same init vector for all chains currently. If a seed is
#'   specified it will be set and thus the inits used will be
#'   reproducible. The inits are also returned in the 'inits'
#'   slot of the fitted object.
#' @param chains Number of chains
#' @param cores Number of parallel cores to use, defaults to
#'   \code{chains} so set this to 1 to execute serial chains.
#' @param thin The thinning rate (defaults to 1).
#' @param control NUTS control list, currently available options
#'   are 'adapt_delta', 'max_treedepth', and 'metric' which is
#'   the type of metric adaptation for Stan to do with options
#'   ('unit_e', 'diag_e', or 'dense_e'). For dense and sparse
#'   metrics this usually can be 'unit_e' to skip adaptation.
#'   NULL values (default) revert to \code{stan_sample} defaults.
#' @param seed Random number seed, used for generating inital
#'   values (if 'random") and for NUTS.
#' @param laplace Whether to leave the Laplace approximation on
#'   and only use NUTS to sample the fixed effects, or turn it
#'   off and sample from the joint parameter space (default).
#' @param skip_optimization Whether to skip optimization or not
#'   (default).
#' @param Q The sparse precision matrix. It is calculated
#'   internally if not specified (default).
#' @param Qinv The dense matrix (M). It is calculated internally
#'   if not specified (default).
#' @param globals A named list of objects to pass to new R
#'   sessions when running in parallel and using RTMB. Typically
#'   this is the `data` object for now.
#' @param model_name An optional character giving the model name.
#'   If NULL it will use the DLL name which for RTMB models is
#'   just 'RTMB'. The name is used only for printing.
#' @param refresh How often to print updates to console
#'   (integer). 0 will turn off printing. The default is 100.
#' @param print Whether to print summary of run (default) or not
#' @param ... Additional arguments to pass to
#'   \code{\link{StanEstimators::stan_sample}}.
#' @return A fitted MCMC object of class 'adfit'
#' @details The TMB metric is used to decorrelate/descale the
#'   posterior before sampling using the Stan algorithms via the
#'   StanEstimator interface. The default is 'auto' which uses an
#'   algorithm to determine the optimal metric to use for a
#'   particular model. The algorithm depends on whether Q and/or
#'   M=Qinv are available, the extent of parameter correlations,
#'   and the speed of gradient calculations. The chosen metric
#'   and reasoning are printed to the console before NUTS
#'   sampling. A sparse and dense matrix will decorrelate and
#'   descale the posterior in the same way, but the sparse one
#'   will be more efficient with high levels of sparsity and
#'   larger dimensions. The 'diag' option is to take the marginal
#'   SDs from M and thus only descales, while the 'unit' option
#'   is the default Stan algorithm and should be used with mass
#'   matrix adaptation. The 'sparse-J' is constructued to be
#'   mathematically equivalent to 'dense' but computiontally
#'   faster, but generally shoudl only be used for
#'   testing/exploration. Note that the \code{metric} is the TMB
#'   metric and distinct from the Stan metric which is controlled
#'   via the \code{control} list.
#' @export
sample_sparse_tmb <-
  function(obj, iter=2000, warmup=floor(iter/2),
           chains=4, cores=chains, thin=1,
           control=NULL, seed=NULL, laplace=FALSE,
           init=c('last.par.best', 'random', 'random-t', 'unif'),
           metric=c('auto', 'unit', 'diag', 'dense',  'sparse', 'sparse-J'),
           skip_optimization=FALSE, Q=NULL, Qinv=NULL,
           globals=NULL, model_name=NULL, refresh=NULL,
           print=TRUE,
           rotation_only=FALSE,
           ...){

  iter <- iter-warmup
  metric <- match.arg(metric)
  init <- match.arg(init)
  obj$env$beSilent()
  if(!is.null(model_name)){
    stopifnot(is.character(model_name))
  } else {
    model_name <- obj$env$DLL
  }
  inputs <- .get_inputs(obj=obj, skip_optimization=skip_optimization,
                        laplace=laplace, metric=metric, Q=Q, Qinv=Qinv)
  mle <- inputs$mle
  Q <- inputs$Q
  Qinv <- inputs$Qinv

  ## prepare to run via StanEstimators
  mydll <- unclass(getLoadedDLLs()[[obj$env$DLL]])$path
  isRTMB <- ifelse(obj$env$DLL=='RTMB', TRUE, FALSE)
  if(!isRTMB){
    packages <- c("TMB", "Matrix")
    obj2 <- obj
    if(!laplace){
      message("Rebuilding TMB obj without random effects...")
      obj2 <- TMB::MakeADFun(data=obj$env$data, parameters=obj$env$parList(),
                             map=obj$env$map,
                             random=NULL, silent=TRUE,
                             DLL=obj$env$DLL)
    }
  } else {
    packages <- c("RTMB", "Matrix")
    obj2 <- obj
    if(!laplace){
      message("Rebuilding RTMB obj without random effects...")
      obj2 <- RTMB::MakeADFun(func=obj$env$data, parameters=obj$env$parList(),
                              map=obj$env$map,
                              random=NULL, silent=TRUE,
                              DLL=obj$env$DLL)
    }
  }
  rotation <- .rotate_posterior(metric=metric, fn=obj2$fn, gr=obj2$gr, Q=Q, Qinv=Qinv, y.cur=mle$est)
  if(rotation_only) return(rotation)
  metric <- rotation$metric # update if using auto for printing later
  fsparse <- function(v) {dyn.load(mydll); -rotation$fn2(v)}
  gsparse <- function(v) -as.numeric(rotation$gr2(v))
  inits <- rotation$x.cur
  if(init!='last.par.best'){
    if(!is.null(seed)) set.seed(seed)
    if(init=='random-t'){
      if(is.null(Qinv))
        stop("No Qinv found so cannot use random inits. Try 'last.par.best' or 'unif' instead'")
      inits <- as.numeric(rotation$x.cur + mvtnorm::rmvt(n=1, sigma=Qinv, df=2))
      if(!is.finite(obj2$fn(inits))) {
        message("random rmvt inits resulted in NaN NLL, try 'random' instead or investigate returned inits")
        return(inits)
      }
    } else if(init=='random'){
      if(is.null(Qinv))
        stop("No Qinv found so cannot use random inits. Try 'last.par.best' or 'unif' instead'")

      inits <- as.numeric(rotation$x.cur + mvtnorm::rmvnorm(n=1, sigma=Qinv))
      if(!is.finite(obj2$fn(inits))) {
        message("random rmvnorm inits resulted in NaN NLL, try 'last.par.best' instead or investigate returned inits")
        return(inits)
      }
    } else if(init=='unif'){
      inits <- runif(n=length(rotation$x.cur), min=-2, max=2)
      if(!is.finite(obj2$fn(inits))) {
        message("random uniform inits resulted in NaN NLL, try 'last.par.best' or 'random' instead or investigate returned inits")
        return(inits)
      }
    }
  } # end of random init options
  if(!is.null(mle$est)){
    nll0=round(-obj2$fn(mle$est),3)
  } else {
    nll0='NA'
  }
  message("log-posterior at inits=", round(-fsparse(inits),3),"; at joint mode=",nll0)
  finv <- rotation$finv
  globals2 <- list(obj2 = obj2, mydll=mydll, rotation=rotation)
  ## the user must pass data objects
  if(isRTMB) globals2 <- c(globals2,globals)
  message("Starting MCMC sampling...")
  if(cores>1) message("Preparing parallel workspace...")
  fit <- stan_sample(fn=fsparse, par_inits=inits,
                     grad_fun=gsparse, num_samples=iter,
                     num_warmup=warmup, thin=thin,
                     globals = globals2, packages=packages,
                     adapt_delta=control$adapt_delta,
                     adapt_window=control$adapt_window,
                     adapt_init_buffer=control$adapt_init_buffer,
                     adapt_term_buffer=control$adapt_term_buffer,
                     metric=control$metric,
                     max_treedepth=control$max_treedepth,
                     parallel_chains=cores, save_warmup=TRUE,
                     num_chains = chains, seed = seed,
                     refresh=refresh, ...)

  fit2 <- as.tmbfit(fit, mle=mle, invf=finv, metric=metric, model=model_name)
  fit2$time.Q <- inputs$time.Q; fit2$time.Qinv <- inputs$time.Qinv; fit2$time.opt <- inputs$time.opt
  fit2$inits <- inits
  ## gradient timings to check for added overhead
  if(require(microbenchmark)){
    bench <- microbenchmark(obj2$gr(inits),
                            gsparse(inits),
                            times=500, unit='s')
    fit2$time.gr <- summary(bench)$median[1]
    fit2$time.gr2 <- summary(bench)$median[2]
  } else {
    warning("Package microbenchmark required to do accurate gradient timings, using system.time() instead")
    fit2$time.gr <-
      as.numeric(system.time(trash <- replicate(1000, obj2$gr(inits)))[3])
    fit2$time.gr2 <-
      as.numeric(system.time(trash <- replicate(1000, gsparse(inits)))[3])
  }
  cat('\n\n')
  if(print) print(fit2)
  return(invisible(fit2))
}


#' Extract posterior samples from a tmbfit object
#' @param x A fitted tmbfit object
#' @param invf The inverse function to decorrelate the parameters
#' @param parnames A vector of parameter names, excluding lp__
#' @param array Whether to return a data.frame (default) or array
#'   which is used in constructing other objects downstream
#' @export
get_post <- function(x, invf, parnames, array=FALSE) {
  p <- x@draws |> as.data.frame()
  q <- subset(p, select=-c(lp__, .iteration, .draw, .chain))
  names(q) <- parnames
  if(ncol(q)==1){
    q <- as.data.frame(apply(q, 1, invf)) |> cbind(p$lp__)
  } else {
    q <- as.data.frame(t(apply(q, 1, invf))) |> cbind(p$lp__)
  }
  colnames(q) <- c(parnames, 'lp__')
  ## build array
  if(array){
    samples <- array(NA, dim=c(max(p$.iter), max(p$.chain), 1 + length(parnames)),
                     dimnames = list(NULL, NULL, c(parnames, "lp__")))
    for(chain in 1:max(p$.chain))
      samples[,chain,] <- as.matrix(q[p$.chain==chain,])
    return(samples)
  }
  return(q)
}


#' Construtor for tmbfit objects
#' @param x A fitted MCMC object
#' @param mle A list of MLE parameters
#' @param invf The inverse function for the parameters
#' @param metric The metric used
#' @param model A character giving the model name
#' @export
as.tmbfit <- function(x, mle, invf, metric, model='anonymous'){
  parnames <- mle$parnames
  ## move lp__ to end to match order of draws
  mon <- StanEstimators::summary(x)
  mon$variable <- c('lp__', parnames)
  mon <- rbind(mon[-1,], mon[1,])
  mon$n_eff <- mon$ess_bulk
  mon$Rhat <- mon$rhat
  ## prepare objects to use the pairs_admb function
  post <- get_post(x, invf, parnames=parnames, TRUE)
  sp <- as.data.frame(x@diagnostics)
  spl <- list()
  for(chain in 1:max(sp$.chain)){
    spl[[chain]] <- as.matrix(sp[sp$.chain==chain,1:6])
  }
  timing <- sapply(x@timing, function(x) unlist(x))
  thin <- as.numeric(x@metadata$thin)
  warmup <- ceiling(as.numeric(x@metadata$num_warmup)/thin)
  iter <- ceiling(as.numeric(x@metadata$num_samples)/thin)
  if(dim(post)[1] != warmup + iter){
    stop("Error in output dimensions: iter=",iter, "; warmup=", warmup,
         "; nrow(post)=", nrow(post))
  }
  x <- list(samples=post, sampler_params=spl, mle=mle,
            monitor=mon, model=model,
            metric=metric,
            par_names=mle$parnames,
            max_treedepth=x@metadata$max_depth,
            warmup=warmup, iter=iter, thin=thin,
            time.warmup=timing[1,],
            time.sampling=timing[2,],
            time.total=timing[1,]+timing[2,],
            ## iter=as.numeric(x@metadata$num_samples)+as.numeric(x@metadata$num_warmup),
            algorithm='NUTS')
  adfit(x)
}

#' Print matrix stats
#'
#' @param x matrix object
#' @param name
#'
.print.mat.stats <- function(x){
  if(is.null(x)) return(NULL)
  if(NROW(x)==1) return(NULL) # not a matrix!
  nm <- deparse(substitute(x))
  e <- eigen(x,TRUE)
  mine <- min(e$value); maxe <- max(e$value); ratio <- maxe/mine
  pct.sparsity <- round(100*mean(x[lower.tri(x)] == 0),2)
  message(nm, " is ", pct.sparsity,
          "% zeroes, with condition factor=",round(ratio,0),
          ' (min=',round(mine,3), ', max=', round(maxe,1),")")
}

#' Prepare inputs for sparse sampling
#'  @param obj Object
#'  @param skip_optimization Whether to skip or not
#'  @param laplace Whether to due the LA or not
#'  @param metric Which metric
#'  @param Q Sparse precision
#'  @param Qinv Inverse of Q
#'  @return A list containing Q, Qinv, the mle list, and timings
.get_inputs <- function(obj, skip_optimization, laplace, metric, Q, Qinv) {

  time.opt <- time.Q <- time.Qinv <- 0
  if(!skip_optimization){
    message("Optimizing...")
    time.opt <-
      as.numeric(system.time(opt <- with(obj, nlminb(par, fn, gr)))[3])
  }
  hasRE <-  !is.null(obj$env$random)
  if(laplace & !hasRE)
    stop("No random effects found so laplace=TRUE fails, set to FALSE")
  if( (laplace | !hasRE) & metric=='sparse')
    stop("sparse metric only allowed with random effects
           and laplace=FALSE")
  if(!laplace){
    if(is.null(Q) & hasRE){
      message("Getting Q...")
      time.Q <- as.numeric(system.time(
        sdr <- sdreport(obj, getJointPrecision=TRUE))[3])
      Q <- sdr$jointPrecision
    }
    if(is.null(Qinv)){
      if(!is.null(Q)){
        ## Q found above
        message("Inverting Q...")
        time.Qinv <- as.numeric(system.time(Qinv <- solve(Q))[3])
      } else if(!hasRE){
        ## fixed effect only model
        time.Qinv <- as.numeric(system.time(Qinv <- sdreport(obj)$cov.fixed)[3])
      } else {
        stop("something wrong here")
      }
    }
    .print.mat.stats(Q)
    .print.mat.stats(Qinv)
    mle <- obj$env$last.par.best
    ## Make parameter names unique if vectors exist
    parnames <- names(mle)
    parnames <- as.vector((unlist(sapply(unique(parnames), function(x){
      temp <- parnames[parnames==x]
      if(length(temp)>1) paste0(temp,'[',1:length(temp),']') else temp
    }))))
    stopifnot(all.equal(length(mle), nrow(Qinv)))
  } else {
    message("Getting M for fixed effects...")
    time.Qinv <- as.numeric(system.time(sdr <- sdreport(obj))[3])
    Qinv <- sdr$cov.fixed
    .print.mat.stats(Qinv)
    if(is.null(opt))
      stop("No opt object found, rerun with 'skip_optimization=FALSE'")
    mle <- opt$par
    ## Make parameter names unique if vectors exist
    parnames <- names(mle)
    parnames <- as.vector((unlist(sapply(unique(parnames), function(x){
      temp <- parnames[parnames==x]
      if(length(temp)>1) paste0(temp,'[',1:length(temp),']') else temp
    }))))
    stopifnot(all.equal(length(mle), nrow(Qinv)))
  }
  ses <- suppressWarnings(sqrt(diag(Qinv)))
  mycor <- suppressWarnings(cov2cor(Qinv))
  if(!all(is.finite(ses))){
    if(metric %in% c('unit', 'auto')){
      warning("Some standard errors estimated to be NaN, filling with dummy values so unit metric works. The 'mle' slot will be wrong so do not use it")
      cor <- diag(length(mle))
      ses <- rep(1,length(mle))
    } else {
      stop("Some standard errors estimated to be NaN, use 'unit' metric for models without a mode or positive definite Hessian")
    }
  }
  mle <- list(nopar=length(mle), est=mle, se=ses,
              cor=mycor, parnames=parnames, Q=Q,
              Qinv=Qinv)
 out <- list(Q=Q, Qinv=Qinv, mle=mle, time.opt=time.opt, time.Qinv=time.Qinv, time.Q=time.Q)
 return(out)
}

#' Update algorithm for mass matrix.
#'
#' @param metric The metric to use
#' @param fn The current fn function.
#' @param gr The current gr function
#' @param y.cur The current parameter vector in unrotated (Y) space.
#' @param Q The sparse precision matrix
#' @param Qinv The inverse of Q
.rotate_posterior <- function(metric, fn, gr, Q,  Qinv, y.cur){
  ## Rotation done using choleski decomposition
  ## First case is a dense mass matrix
  M <- as.matrix(Qinv)
  if(metric=='dense'){
    # took this out b/c it was warning too often, better way to test?
    #if(!matrixcalc::is.symmetric.matrix(M) ||
    #  !matrixcalc::is.positive.definite(M))
    # warning("Estimated dense matrix was not positive definite so may be unreliable. Try different metric or turn on the laplace if there are random effects if it fails.")
    J <- NULL
    chd <- t(chol(M))               # lower triangular Cholesky decomp.
    chd.inv <- solve(chd)               # inverse
    ## Define rotated fn and gr functions
    fn2 <- function(x) fn(chd %*% x)
    gr2 <- function(x) {as.vector( gr(chd %*% x) %*% chd )}
    ## Now rotate back to "x" space using the new mass matrix M
    x.cur <- as.numeric(chd.inv %*% y.cur)
    finv <- function(x){
      t(chd %*% x)
    }
  } else if(metric=='diag'){
    M <- diag(M)
    ## diagonal but not unit
      J <- NULL
      chd <- sqrt(M)
      fn2 <- function(x) fn(chd * x)
      gr2 <- function(x) as.vector(gr(chd * x) ) * chd
      ## Now rotate back to "x" space using the new mass matrix M. M is a
      ## vector here. Note the big difference in efficiency without the
      ## matrix operations.
      x.cur <- (1/chd) * y.cur
      finv <- function(x) chd*x
  } else if(metric=='unit') {
    ## unit metric, change nothing
    fn2 <- function(x) fn(x)
    gr2 <- function(x) gr(x)
    x.cur <- y.cur
    finv <- function(x) x
    chd <- J <- NULL
  } else if(metric=='sparse-J'){
    # This metric is carefully constructured to match the dense
    # metric up to numerical precision. But as it is slower it is
    # not typically used.
    stopifnot(require(Matrix))
    if(!is(Q,"Matrix")) stop("Q is not a Matrix object, something went wrong")
    # M is actually Q, i.e., the inverse-mass
    # Antidiagonal matrix JJ = I
    J = Matrix::sparseMatrix( i=1:nrow(Q), j=nrow(Q):1 )
    #chd <- Cholesky(M, super=FALSE, perm=FALSE)
    #chd <- Matrix::Cholesky(M, super=TRUE, perm=FALSE)
    chd <- Matrix::Cholesky(J%*%Q%*%J, super=TRUE, perm=FALSE) # perm
    Linv_times_x = function(chd,x){
      as.numeric(J%*% Matrix::solve(chd, Matrix::solve(chd, J%*%x, system="Lt"), system="Pt"))
    }
    x_times_Linv = function(chd,x){
      #x %*% chol()
      as.numeric(J%*%Matrix::solve(chd, Matrix::solve(chd, Matrix::t(x%*%J), system="L"), system="Pt"))
    }
    fn2 <- function(x){
      Linv_x = Linv_times_x(chd, x)
      fn(Linv_x)
    }
    gr2 <- function(x){
      Linv_x = Linv_times_x(chd, x)
      grad = gr( Linv_x )
      as.vector(  x_times_Linv(chd, grad) )
    }
    ## Now rotate back to "x" space using the new mass matrix M
    #  solve(t(chol(solve(M)))) ~~ IS EQUAL TO ~~ J%*%chol(M)%*%J
    # J%*%chol(J%*%prec%*%J) %*% J%*%x
    x.cur <- as.numeric(J%*%chol(J%*%Q%*%J) %*% J%*%y.cur)
    finv <- function(x){
      t(as.numeric(J%*%Matrix::solve(chd, Matrix::solve(chd, J%*%x, system="Lt"), system="Pt")))
    }
  } else if(metric=='sparse'){
    # Do Cholesky on Q permuted directly
    J <- NULL
    chd <- Matrix::Cholesky(Q, super=TRUE, perm=TRUE)
    L <- as(chd, "sparseMatrix")
    perm <- chd@perm + 1L
    iperm <- Matrix::invPerm(perm)
    # Drop all numerical zeros and convert to triangular storage
    L <- tril(drop0(L)) ## class(L) == "dtCMatrix"
    Lt <- Matrix::t(L) ## class(Lt) == "dtCMatrix"
    x.cur <- as.vector(Matrix::t(L) %*% y.cur[perm])
    fn2 <- function(y)  fn(Matrix::solve(Lt, y)[iperm])
    gr2 <- function(y){
      x <- Matrix::solve(Lt, y)[iperm]
      Matrix::solve(L, as.numeric(gr(x))[perm])
    }
    finv <- function(x)   as.numeric(Matrix::solve(Lt, x)[iperm])
  } else if(metric=='auto'){
    ## use recursion then pick the right one depending on several criteria
    if(!is.null(Q) && NROW(Q)>1) rsparse <- .rotate_posterior(metric='sparse', fn=fn, gr=gr, Q=Q, Qinv=Qinv, y.cur=y.cur)
    if(!is.null(Qinv))
      rdiag <- .rotate_posterior(metric='diag', fn=fn, gr=gr, Q=Q, Qinv=Qinv, y.cur=y.cur)
    if(!is.null(Qinv) && NROW(Qinv)>1){
      rdense <- tryCatch(.rotate_posterior(metric='dense', fn=fn, gr=gr, Q=Q, Qinv=Qinv, y.cur=y.cur),
                         error=function(e) "Failed")
    }
    runit <- .rotate_posterior(metric='unit', fn=fn, gr=gr, Q=Q, Qinv=Qinv, y.cur=y.cur)

    if(NROW(Qinv)==1){
      message("diag metric selected b/c only 1 parameter")
      return(rdiag)
    }

    if(is.character(rdense)){
      message("unit metric selected b/c Qinv was not positive definite")
      return(runit)
    }

    if(is.null(Q)){
      if(is.null(Qinv)){
        # must be unit since no other option
        message("unit metric selected b/c no Q or Qinv info available")
        return(runit)
      } else {
        # no Q but does have Qinv, e.g., a model w/o RE or using the LA
        ## check for high correlations
        cors <- cov2cor(Qinv)[lower.tri(Qinv, diag=FALSE)]
        if(NROW(cors)==1) {
          message("diag metric selected b/c only a single parameter")
          return(rdiag)
        } else if(max(abs(cors))<.3){
          message("diag metric selected b/c no Q available and low correlations")
          return(rdiag)
        } else {
          message("dense metric selected b/c no Q availabile and high correlations")
          return(rdense)
        }
      }
    } else {
      # has a Q
      cors <- cov2cor(Qinv)[lower.tri(Qinv, diag=FALSE)]
      if(max(abs(cors))<.3){
        message("diag metric selected b/c of and low correlations")
        return(rdiag)
      } else {
        if(!require(microbenchmark)){
          message("sparse metric selected b/c no timing available -- please install microbenchmark")
          ## check for speed differences
          return(rsparse)
        } else {
          bench <- microbenchmark::microbenchmark(rdense$gr2(rdense$x.cur),
                                                  rsparse$gr2(rsparse$x.cur),
                                                  times = 500)
          tdense <- summary(bench)$median[1]
          tsparse <- summary(bench)$median[2]
          if(tdense < tsparse){
            message("dense metric selected b/c faster than sparse and high correlations")
            return(rdense)
          } else {
            message("sparse metric selected b/c faster than dense and high correlations")
            return(rsparse)
          }
        }
      }
    }
  }  else {
    stop("Invalid metric")
  }
  ## Redefine these functions
  ## Need to adjust the current parameters so the chain is
  ## continuous. First rotate to be in Y space.
  return(list(gr2=gr2, fn2=fn2, finv=finv, x.cur=x.cur, chd=chd, J=J, metric=metric))
}




#' Make an image plot showing the correlation (lower triangle)
#' and sparsity (upper triangle).
#'
#' @param fit A fitted object
#' @param Q A sparse matrix. If NULL it will be extracted from
#'   \code{fit}.
#'
#' @details This function is used to visualize the sparsity and
#'   correlation patterns of the joint model. The upper triangle
#'   shows whether an element is 0 (white) or not (gray), while
#'   the lower triangle shows the correlation calculated from
#'   \code{cov2cor(solve(Q))}.
#' @return A plot created by \code{Matrix::image}.
#' @export
plot_Q <- function(fit, Q=NULL){
  if(is.null(Q)){
    if(!is.adfit(fit)) stop("fit is not a valid fitted object")
    if(is.null(fit$mle$Q)) return(NULL)
    nn <- length(fit$par_names)
    corr <- cov2cor(fit$mle$Qinv)
    Q <- fit$mle$Q
  } else {
    corr <- cov2cor(solve(Q))
  }
  Q[Q!=0] <- 1e-10
  Q[lower.tri(Q,TRUE)] <- corr[lower.tri(Q,TRUE)]
  Matrix::image(Q, useRaster=TRUE, at=seq(-1,1, len=50))
}
