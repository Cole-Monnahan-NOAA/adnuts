<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Sparse NUTS for TMB models • adnuts</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Sparse NUTS for TMB models">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">adnuts</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.1.2.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/adnuts.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/NUTS-for-ADMB-models.html">NUTS for ADMB models</a></li>
    <li><a class="dropdown-item" href="../articles/SNUTS-for-TMB-models.html">Sparse NUTS for TMB models</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/Cole-Monnahan-NOAA/adnuts/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Sparse NUTS for TMB models</h1>
                        <h4 data-toc-skip class="author">Cole C.
Monnahan</h4>
            
            <h4 data-toc-skip class="date">2025-08-13</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/Cole-Monnahan-NOAA/adnuts/blob/HEAD/vignettes/articles/SNUTS-for-TMB-models.Rmd" class="external-link"><code>vignettes/articles/SNUTS-for-TMB-models.Rmd</code></a></small>
      <div class="d-none name"><code>SNUTS-for-TMB-models.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://Cole-Monnahan-NOAA.github.io/adnuts">adnuts</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="differences-between-tmb-and-rtmb">Differences between TMB and RTMB<a class="anchor" aria-label="anchor" href="#differences-between-tmb-and-rtmb"></a>
</h2>
<p><code>adnuts</code> implements the sparse no-u-turn sampler (SNUTS)
as introduced and detailed in <span class="citation">(C. C. Monnahan et
al. in prep)</span>. This only works for TMB models because Stan
currently has no way to pass and use a sparse metric. Both TMB and RTMB
models can be used without user specification, including parallel
chains. The <code>sample_snuts</code> function will detect which is used
internally and adjust accordingly. If the user wants to use models from
both packages in the same session then one needs to be unloaded, e.g.,
<code>if('TMB' %in% .packages()) detach(package:TMB)</code>, before the
other package is loaded.</p>
<p>If the RTMB model uses external functions or data sets then they must
be passed through via a list in the <code>globals</code> argument so
they are available to rebuild the ‘obj’ in the parallel R sessions.
Optionally, the <code>model_name</code> can be specified in the call,
otherwise your model will be labeled “RTMB” in the output. TMB models do
not require a globals input and the model name is pulled from the DLL
name, but can be overridden if desired.</p>
</div>
<div class="section level2">
<h2 id="comparison-to-tmbstan">Comparison to tmbstan<a class="anchor" aria-label="anchor" href="#comparison-to-tmbstan"></a>
</h2>
<p>The related package ‘tmbstan’ <span class="citation">(C. C. Monnahan
and Kristensen 2018)</span> also allows users to link TMB models to the
Stan algorithms. ‘tmbstan’ links through the package ‘rstan’, while
‘adnuts’ modifies the objective and gradient functions and then passes
those to ‘cmdstan’ through the ‘StanEstimators’ R package interface. For
models without large correlations or scale differences,
<code>tmbstan</code> is likely to be faster than ‘adnuts’ due to lower
overhead and may be a better option. Eventually, Stan may add SNUTS
functionality and an interface to ‘tmbstan’ developed, and in that case
<code>tmbstan</code> may be a better long term option. For TMB users
now, SNUTS via <code>adnuts</code> is likely to be the best overall
package for Bayesian inference.</p>
</div>
<div class="section level2">
<h2 id="snuts-for-tmb-models-from-existing-packages-sdmtmb-glmmtmb-etc-">SNUTS for TMB models from existing packages (sdmTMB, glmmTMB,
etc.)<a class="anchor" aria-label="anchor" href="#snuts-for-tmb-models-from-existing-packages-sdmtmb-glmmtmb-etc-"></a>
</h2>
<p><code>adnuts</code> works for custom TMB and RTMB models developed
locally, but also for those that come in packages. Most packages will
return the TMB ‘obj’ which can then be passed into
<code>sample_snuts</code>.</p>
<p>For instance the <code>glmmTMB</code> package can be run like
this:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/glmmTMB/glmmTMB" class="external-link">glmmTMB</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">Salamanders</span><span class="op">)</span></span>
<span><span class="va">obj</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/glmmTMB/man/glmmTMB.html" class="external-link">glmmTMB</a></span><span class="op">(</span><span class="va">count</span><span class="op">~</span><span class="va">spp</span> <span class="op">*</span> <span class="va">mined</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span><span class="op">|</span><span class="va">site</span><span class="op">)</span>, <span class="va">Salamanders</span>, family<span class="op">=</span><span class="st">"nbinom2"</span><span class="op">)</span><span class="op">$</span><span class="va">obj</span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sample_snuts.html">sample_snuts</a></span><span class="op">(</span><span class="va">obj</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="basic-usage">Basic usage<a class="anchor" aria-label="anchor" href="#basic-usage"></a>
</h2>
<p>The recommended usage for TMB users is to let the
<code>sample_snuts</code> function automatically detect the metric to
use and the length of warmup period, especially for pilot runs during
model development.</p>
<p>I demonstrate basic usage using a very simple RTMB version of the
eight schools model that has been examined extensively in the Bayesian
literature. The first step is to build the TMB object ‘obj’ that
incorporates priors and Jacobians for parameter transformations. Note
that the R function returns the negative un-normalized log-posterior
density.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/kaskr/RTMB" class="external-link">RTMB</a></span><span class="op">)</span></span>
<span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>y<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">28</span>,  <span class="fl">8</span>, <span class="op">-</span><span class="fl">3</span>,  <span class="fl">7</span>, <span class="op">-</span><span class="fl">1</span>,  <span class="fl">1</span>, <span class="fl">18</span>, <span class="fl">12</span><span class="op">)</span>,</span>
<span>            sigma<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">15</span>, <span class="fl">10</span>, <span class="fl">16</span>, <span class="fl">11</span>,  <span class="fl">9</span>, <span class="fl">11</span>, <span class="fl">10</span>, <span class="fl">18</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">pars</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>mu<span class="op">=</span><span class="fl">0</span>, logtau<span class="op">=</span><span class="fl">0</span>, eta<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">8</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">f</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">pars</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/RTMB/man/TMB-interface.html" class="external-link">getAll</a></span><span class="op">(</span><span class="va">dat</span>, <span class="va">pars</span><span class="op">)</span></span>
<span>  <span class="va">theta</span> <span class="op">&lt;-</span> <span class="va">mu</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">logtau</span><span class="op">)</span> <span class="op">*</span> <span class="va">eta</span>;</span>
<span>  <span class="va">lp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">eta</span>, <span class="fl">0</span>,<span class="fl">1</span>, log<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span><span class="op">+</span> <span class="co"># prior</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">y</span>,<span class="va">theta</span>,<span class="va">sigma</span>,log<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span><span class="op">+</span> <span class="co">#likelihood</span></span>
<span>    <span class="va">logtau</span>                          <span class="co"># jacobian</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/RTMB/man/TMB-interface.html" class="external-link">REPORT</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="op">-</span><span class="va">lp</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="va">obj</span> <span class="op">&lt;-</span> <span class="fu">MakeADFun</span><span class="op">(</span>func<span class="op">=</span><span class="va">f</span>, parameters<span class="op">=</span><span class="va">pars</span>,</span>
<span>                 random<span class="op">=</span><span class="st">"eta"</span>, silent<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="section level3">
<h3 id="posterior-sampling-with-snuts">Posterior sampling with SNUTS<a class="anchor" aria-label="anchor" href="#posterior-sampling-with-snuts"></a>
</h3>
<p>The most common task is to draw samples from the posterior density
defined by this model. This is done with the <code>sample_snuts</code>
function as follows:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sample_snuts.html">sample_snuts</a></span><span class="op">(</span><span class="va">obj</span>, refresh<span class="op">=</span><span class="fl">0</span>, seed<span class="op">=</span><span class="fl">1</span>,</span>
<span>                    model_name <span class="op">=</span> <span class="st">'schools'</span>,</span>
<span>                    cores<span class="op">=</span><span class="fl">1</span>, chains<span class="op">=</span><span class="fl">1</span>,</span>
<span>                    globals<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>dat<span class="op">=</span><span class="va">dat</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Optimizing...</span></span>
<span><span class="co">#&gt; Getting Q...</span></span>
<span><span class="co">#&gt; Inverting Q...</span></span>
<span><span class="co">#&gt; Q is 62.22% zeroes, with condition factor=56 (min=0.044, max=2.5)</span></span>
<span><span class="co">#&gt; Rebuilding RTMB obj without random effects...</span></span>
<span><span class="co">#&gt; diag metric selected b/c of low correlations</span></span>
<span><span class="co">#&gt; log-posterior at inits=-34.661; at conditional mode=-34.661</span></span>
<span><span class="co">#&gt; Starting MCMC sampling...</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Gradient evaluation took 8.1e-05 seconds</span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.81 seconds.</span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Elapsed Time: 0.066 seconds (Warm-up)</span></span>
<span><span class="co">#&gt;                0.366 seconds (Sampling)</span></span>
<span><span class="co">#&gt;                0.432 seconds (Total)</span></span>
<span><span class="co">#&gt; 5 of 1150 (0.43%) iterations ended with a divergence.</span></span>
<span><span class="co">#&gt; These divergent transitions indicate that HMC is not fully able to explore the posterior distribution.</span></span>
<span><span class="co">#&gt; Try increasing adapt_delta closer to 1.</span></span>
<span><span class="co">#&gt; If this doesn't remove all divergences, try to reparameterize the model.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Model 'schools' has 10 pars, and was fit using NUTS with a 'diag' metric</span></span>
<span><span class="co">#&gt; 1 chain(s) of 1150 total iterations (150 warmup) were used</span></span>
<span><span class="co">#&gt; Average run time per chain was 0.43 seconds </span></span>
<span><span class="co">#&gt; Minimum ESS=296.92 (29.69%), and maximum Rhat=1.002</span></span>
<span><span class="co">#&gt; There were 0 divergences after warmup</span></span></code></pre></div>
<p>The returned object <code>fit</code> (an object of ‘adfit’ S3 class)
contains the posterior samples and other relevant information for a
Bayesian analysis.</p>
<p>Here a ‘diag’ (diagonal) metric is selected and a very short warmup
period of 150 iterations is used, with mass matrix adaptation in Stan
disabled. See below for more details on mass matrix adaptation within
Stan.</p>
<p>Notice that no optimization was done before calling
<code>sample_snuts</code>. When the model has already been optimized,
you can skip that by setting <code>skip_optimization=TRUE</code>, and
even pass in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Σ</mi><mo>=</mo><msup><mi>Q</mi><mrow><mi>−</mi><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\Sigma=Q^{-1}</annotation></semantics></math>
via arguments <code>Q</code> and <code>Qinv</code> to bypass this step
and save some run time. This may also be required if the model
optimization routine internal to <code>sample_snuts</code> is
insufficient. In that case, the user should optimize prior to SNUTS
sampling. The returned fitted object contains a slot called
<code>mle</code> (for maximum likelihood estimates) which has the
conditional mode (‘est’), the marginal standard errors ‘se’, a joint
correlation matrix (‘cor’), and the sparse precision matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">mle</span><span class="op">)</span></span>
<span><span class="co">#&gt; List of 5</span></span>
<span><span class="co">#&gt;  $ nopar: int 10</span></span>
<span><span class="co">#&gt;  $ est  : Named num [1:10] 7.92441 1.8414 0.47811 0.00341 -0.2329 ...</span></span>
<span><span class="co">#&gt;   ..- attr(*, "names")= chr [1:10] "mu" "logtau" "eta[1]" "eta[2]" ...</span></span>
<span><span class="co">#&gt;  $ se   : Named num [1:10] 4.725 0.732 0.959 0.872 0.945 ...</span></span>
<span><span class="co">#&gt;   ..- attr(*, "names")= chr [1:10] "mu" "logtau" "eta[1]" "eta[2]" ...</span></span>
<span><span class="co">#&gt;  $ cor  : num [1:10, 1:10] 1 0.0558 -0.1031 -0.2443 -0.114 ...</span></span>
<span><span class="co">#&gt;   ..- attr(*, "dimnames")=List of 2</span></span>
<span><span class="co">#&gt;   .. ..$ : chr [1:10] "mu" "logtau" "eta[1]" "eta[2]" ...</span></span>
<span><span class="co">#&gt;   .. ..$ : chr [1:10] "mu" "logtau" "eta[1]" "eta[2]" ...</span></span>
<span><span class="co">#&gt;  $ Q    :Formal class 'dsCMatrix' [package "Matrix"] with 7 slots</span></span>
<span><span class="co">#&gt;   .. ..@ i       : int [1:27] 0 1 2 3 4 5 6 7 8 9 ...</span></span>
<span><span class="co">#&gt;   .. ..@ p       : int [1:11] 0 10 19 20 21 22 23 24 25 26 ...</span></span>
<span><span class="co">#&gt;   .. ..@ Dim     : int [1:2] 10 10</span></span>
<span><span class="co">#&gt;   .. ..@ Dimnames:List of 2</span></span>
<span><span class="co">#&gt;   .. .. ..$ : chr [1:10] "mu" "logtau" "eta[1]" "eta[2]" ...</span></span>
<span><span class="co">#&gt;   .. .. ..$ : chr [1:10] "mu" "logtau" "eta[1]" "eta[2]" ...</span></span>
<span><span class="co">#&gt;   .. ..@ x       : num [1:27] 0.0603 -0.0144 0.028 0.0631 0.0246 ...</span></span>
<span><span class="co">#&gt;   .. ..@ uplo    : chr "L"</span></span>
<span><span class="co">#&gt;   .. ..@ factors :List of 1</span></span>
<span><span class="co">#&gt;   .. .. ..$ SPdCholesky:Formal class 'dCHMsuper' [package "Matrix"] with 10 slots</span></span>
<span><span class="co">#&gt;   .. .. .. .. ..@ x       : num [1:100] 1.06 0 0 0 0 ...</span></span>
<span><span class="co">#&gt;   .. .. .. .. ..@ super   : int [1:2] 0 10</span></span>
<span><span class="co">#&gt;   .. .. .. .. ..@ pi      : int [1:2] 0 10</span></span>
<span><span class="co">#&gt;   .. .. .. .. ..@ px      : int [1:2] 0 100</span></span>
<span><span class="co">#&gt;   .. .. .. .. ..@ s       : int [1:10] 0 1 2 3 4 5 6 7 8 9</span></span>
<span><span class="co">#&gt;   .. .. .. .. ..@ type    : int [1:6] 2 1 1 1 1 1</span></span>
<span><span class="co">#&gt;   .. .. .. .. ..@ colcount: int [1:10] 3 3 3 3 3 3 4 3 2 1</span></span>
<span><span class="co">#&gt;   .. .. .. .. ..@ perm    : int [1:10] 9 8 7 6 5 4 0 2 3 1</span></span>
<span><span class="co">#&gt;   .. .. .. .. ..@ Dim     : int [1:2] 10 10</span></span>
<span><span class="co">#&gt;   .. .. .. .. ..@ Dimnames:List of 2</span></span>
<span><span class="co">#&gt;   .. .. .. .. .. ..$ : chr [1:10] "mu" "logtau" "eta[1]" "eta[2]" ...</span></span>
<span><span class="co">#&gt;   .. .. .. .. .. ..$ : chr [1:10] "mu" "logtau" "eta[1]" "eta[2]" ...</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="diagnostics">Diagnostics<a class="anchor" aria-label="anchor" href="#diagnostics"></a>
</h3>
<p>The common MCMC diagnostics potential scale reduction (Rhat) and
minimum ESS, as well as the NUTS divergences (see <a href="https://mc-stan.org/docs/reference-manual/analysis.html" class="external-link">diagnostics
section</a> of the rstan manual), are printed to console by default or
can be accessed in more depth via the <code>monitor</code> slot:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="co">#&gt; Model 'schools' has 10 pars, and was fit using NUTS with a 'diag' metric</span></span>
<span><span class="co">#&gt; 1 chain(s) of 1150 total iterations (150 warmup) were used</span></span>
<span><span class="co">#&gt; Average run time per chain was 0.43 seconds </span></span>
<span><span class="co">#&gt; Minimum ESS=296.92 (29.69%), and maximum Rhat=1.002</span></span>
<span><span class="co">#&gt; There were 0 divergences after warmup</span></span>
<span></span>
<span><span class="va">fit</span><span class="op">$</span><span class="va">monitor</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; drws_smm [11 × 12] (S3: draws_summary/tbl_df/tbl/data.frame)</span></span>
<span><span class="co">#&gt;  $ variable: chr [1:11] "mu" "logtau" "eta[1]" "eta[2]" ...</span></span>
<span><span class="co">#&gt;  $ mean    : num [1:11] 1.715 1.992 0.425 -0.019 -0.218 ...</span></span>
<span><span class="co">#&gt;  $ median  : num [1:11] 1.6549 2.2596 0.4623 -0.0369 -0.2074 ...</span></span>
<span><span class="co">#&gt;  $ sd      : num [1:11] 1.008 1.496 1.031 1.015 0.973 ...</span></span>
<span><span class="co">#&gt;  $ mad     : num [1:11] 0.95 1.215 1.001 0.956 0.946 ...</span></span>
<span><span class="co">#&gt;  $ q5      : num [1:11] 0.096 -0.729 -1.349 -1.74 -1.809 ...</span></span>
<span><span class="co">#&gt;  $ q95     : num [1:11] 3.43 3.82 2.06 1.64 1.46 ...</span></span>
<span><span class="co">#&gt;  $ rhat    : num [1:11] 1.001 0.999 1 1 1.002 ...</span></span>
<span><span class="co">#&gt;  $ ess_bulk: num [1:11] 833 324 1535 1498 1545 ...</span></span>
<span><span class="co">#&gt;  $ ess_tail: num [1:11] 498 288 893 717 828 ...</span></span>
<span><span class="co">#&gt;  $ n_eff   : num [1:11] 833 324 1535 1498 1545 ...</span></span>
<span><span class="co">#&gt;  $ Rhat    : num [1:11] 1.001 0.999 1 1 1.002 ...</span></span>
<span><span class="co">#&gt;  - attr(*, "num_args")= list()</span></span></code></pre></div>
<p>A specialized <code>pairs</code> plotting function is available
(formally called <code>pairs_admb</code>) to examine pair-wise behavior
of the posteriors. This can be useful to help diagnose particularly slow
mixing parameters. This function also displays the conditional mode
(point) and 95% bivariate confidence region (ellipses) as calculated
from the approximate covariance matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Σ</mi><mo>=</mo><msup><mi>Q</mi><mrow><mi>−</mi><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\Sigma=Q^{-1}</annotation></semantics></math>.
The parameters to show can be specified either vie a character vector
like <code>pars=c('mu', 'logtau', 'eta[1]')</code> or an integer vector
like <code>pars=1:3</code>, and when using the latter the parameters can
be ordered by slowest mixing (‘slow’), fastest mixing (‘fast’) or by the
largest discrepancies in the approximate marginal variance from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
and the posterior samples (‘mismatch’). NUTS divergences are shown as
green points. See help and further information at
<code><a href="../reference/pairs.adfit.html">?pairs.adfit</a></code>.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html" class="external-link">pairs</a></span><span class="op">(</span><span class="va">fit</span>, order<span class="op">=</span><span class="st">'slow'</span><span class="op">)</span></span></code></pre></div>
<p><img src="SNUTS-for-TMB-models_files/figure-html/pairs-schools-1.png" width="700"></p>
<p>In some cases it is useful to diagnose the NUTS behavior by examining
the “sampler parameters”, which contain information about the individual
NUTS trajectories.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/extract_sampler_params.html">extract_sampler_params</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; 'data.frame':    1000 obs. of  8 variables:</span></span>
<span><span class="co">#&gt;  $ chain        : num  1 1 1 1 1 1 1 1 1 1 ...</span></span>
<span><span class="co">#&gt;  $ iteration    : num  151 152 153 154 155 156 157 158 159 160 ...</span></span>
<span><span class="co">#&gt;  $ accept_stat__: num  0.988 0.973 0.99 0.929 0.842 ...</span></span>
<span><span class="co">#&gt;  $ stepsize__   : num  0.536 0.536 0.536 0.536 0.536 ...</span></span>
<span><span class="co">#&gt;  $ treedepth__  : num  3 3 3 3 3 3 3 3 3 3 ...</span></span>
<span><span class="co">#&gt;  $ n_leapfrog__ : num  7 7 7 7 7 7 7 7 7 7 ...</span></span>
<span><span class="co">#&gt;  $ divergent__  : num  0 0 0 0 0 0 0 0 0 0 ...</span></span>
<span><span class="co">#&gt;  $ energy__     : num  46.1 45.2 42.3 39.8 39.7 ...</span></span>
<span><span class="co">## or plot them directly</span></span>
<span><span class="fu"><a href="../reference/plot_sampler_params.html">plot_sampler_params</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span></code></pre></div>
<p><img src="SNUTS-for-TMB-models_files/figure-html/sp-schools-1.png" width="700"></p>
<p>The ShinyStan tool is also available and provides a convenient,
interactive way to check diagnostics via the function
<code><a href="../reference/launch_shinytmb.html">launch_shinytmb()</a></code>, but also explore estimates and other
important quantities. This is a valuable tool for a workflow with
‘adnuts’.</p>
</div>
<div class="section level3">
<h3 id="bayesian-inference">Bayesian inference<a class="anchor" aria-label="anchor" href="#bayesian-inference"></a>
</h3>
<p>After checking for signs of non-convergence the results can be used
for inference. Posterior samples for parameters can be extracted and
examined in R by casting the fitted object to an R data.frame. These
posterior samples can then be put back into the TMB object
<code>obj$report()</code> function to extract any desired “generated
quantity” in Stan terminology. Below is a demonstration of how to do
this for the quantity theta (a vector of length 8).</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="va">post</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; 'data.frame':    1000 obs. of  10 variables:</span></span>
<span><span class="co">#&gt;  $ mu    : num  6 9.67 3.93 12.17 7.92 ...</span></span>
<span><span class="co">#&gt;  $ logtau: num  0.0852 0.7415 2.0695 2.6354 2.4339 ...</span></span>
<span><span class="co">#&gt;  $ eta[1]: num  0.944 -0.79 0.202 1.447 -0.473 ...</span></span>
<span><span class="co">#&gt;  $ eta[2]: num  0.659 -1.061 1.001 -1.135 0.503 ...</span></span>
<span><span class="co">#&gt;  $ eta[3]: num  -1.162 1.08 -0.917 0.305 -1.236 ...</span></span>
<span><span class="co">#&gt;  $ eta[4]: num  -0.5655 0.7594 -0.3337 0.0423 -0.6287 ...</span></span>
<span><span class="co">#&gt;  $ eta[5]: num  0.914 -0.855 0.315 -1.349 -0.233 ...</span></span>
<span><span class="co">#&gt;  $ eta[6]: num  0.899 -1.269 -0.68 -0.231 -0.832 ...</span></span>
<span><span class="co">#&gt;  $ eta[7]: num  1.5982 -0.9183 0.7886 0.0198 0.6867 ...</span></span>
<span><span class="co">#&gt;  $ eta[8]: num  -0.202 0.262 -0.209 0.771 -0.996 ...</span></span>
<span><span class="co">## now get a generated quantity, here theta which is a vector of</span></span>
<span><span class="co">## length 8 so becomes a matrix of posterior samples</span></span>
<span><span class="va">theta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">post</span>,<span class="fl">1</span>, \<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">obj</span><span class="op">$</span><span class="fu">report</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">$</span><span class="va">theta</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">theta</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt;  num [1:1000, 1:8] 7.03 8.01 5.53 32.35 2.53 ...</span></span></code></pre></div>
<p>Likewise, marginal distributions can be explored visually and
compared to the approximate estimate from the conditional mode and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Σ</mi><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math>
(red lines):</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_marginals.html">plot_marginals</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span></code></pre></div>
<p><img src="SNUTS-for-TMB-models_files/figure-html/marginals-schools-1.png" width="700"></p>
</div>
</div>
<div class="section level2">
<h2 id="a-more-complicated-example">A more complicated example<a class="anchor" aria-label="anchor" href="#a-more-complicated-example"></a>
</h2>
<p>To demonstrate more than the basic usage I will use a more
complicated model. I modified the ChickWeight random slopes and
intercepts example from the RTMB introduction. Modifications include:
switching SD parameters to log space and adding a Jacobian, adding broad
priors for these SDs, and adding a ‘loglik’ vector for PSIS-LOO
(below).</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span> </span>
<span><span class="va">parameters</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>  mua<span class="op">=</span><span class="fl">0</span>,          <span class="co">## Mean slope</span></span>
<span>  logsda<span class="op">=</span><span class="fl">0</span>,          <span class="co">## Std of slopes</span></span>
<span>  mub<span class="op">=</span><span class="fl">0</span>,          <span class="co">## Mean intercept</span></span>
<span>  logsdb<span class="op">=</span><span class="fl">0</span>,          <span class="co">## Std of intercepts</span></span>
<span>  logsdeps<span class="op">=</span><span class="fl">1</span>,        <span class="co">## Residual Std</span></span>
<span>  a<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">50</span><span class="op">)</span>,   <span class="co">## Random slope by chick</span></span>
<span>  b<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">50</span><span class="op">)</span>    <span class="co">## Random intercept by chick</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">f</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">parms</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://github.com/kaskr/RTMB" class="external-link">RTMB</a></span><span class="op">)</span> <span class="co"># for tmbstan</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/RTMB/man/TMB-interface.html" class="external-link">getAll</a></span><span class="op">(</span><span class="va">ChickWeight</span>, <span class="va">parms</span>, warn<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span></span>
<span>  <span class="va">sda</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">logsda</span><span class="op">)</span></span>
<span>  <span class="va">sdb</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">logsdb</span><span class="op">)</span></span>
<span>  <span class="va">sdeps</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">logsdeps</span><span class="op">)</span></span>
<span>  <span class="co">## Optional (enables extra RTMB features)</span></span>
<span>  <span class="va">weight</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/RTMB/man/TMB-interface.html" class="external-link">OBS</a></span><span class="op">(</span><span class="va">weight</span><span class="op">)</span></span>
<span>  <span class="va">predWeight</span> <span class="op">&lt;-</span> <span class="va">a</span><span class="op">[</span><span class="va">Chick</span><span class="op">]</span> <span class="op">*</span> <span class="va">Time</span> <span class="op">+</span> <span class="va">b</span><span class="op">[</span><span class="va">Chick</span><span class="op">]</span></span>
<span>  <span class="va">loglik</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">weight</span>, <span class="va">predWeight</span>, sd<span class="op">=</span><span class="va">sdeps</span>, log<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># calculate the target density</span></span>
<span>  <span class="va">lp</span> <span class="op">&lt;-</span>   <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">loglik</span><span class="op">)</span><span class="op">+</span> <span class="co"># likelihood</span></span>
<span>    <span class="co"># random effect vectors</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">a</span>, mean<span class="op">=</span><span class="va">mua</span>, sd<span class="op">=</span><span class="va">sda</span>, log<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">b</span>, mean<span class="op">=</span><span class="va">mub</span>, sd<span class="op">=</span><span class="va">sdb</span>, log<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="co"># broad half-normal priors on SD pars</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">sda</span>, <span class="fl">0</span>, <span class="fl">10</span>, log<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">sdb</span>, <span class="fl">0</span>, <span class="fl">10</span>, log<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">sdeps</span>, <span class="fl">0</span>, <span class="fl">10</span>, log<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="co"># jacobian adjustments</span></span>
<span>    <span class="va">logsda</span> <span class="op">+</span> <span class="va">logsdb</span> <span class="op">+</span> <span class="va">logsdeps</span></span>
<span>  </span>
<span>  <span class="co"># reporting</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/RTMB/man/TMB-interface.html" class="external-link">REPORT</a></span><span class="op">(</span><span class="va">loglik</span><span class="op">)</span>       <span class="co"># for PSIS-LOO</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/RTMB/man/TMB-interface.html" class="external-link">ADREPORT</a></span><span class="op">(</span><span class="va">predWeight</span><span class="op">)</span> <span class="co"># delta method</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/RTMB/man/TMB-interface.html" class="external-link">REPORT</a></span><span class="op">(</span><span class="va">predWeight</span><span class="op">)</span>   <span class="co"># standard report</span></span>
<span>  </span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="op">-</span><span class="va">lp</span><span class="op">)</span> <span class="co"># negative log-posterior density</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">obj</span> <span class="op">&lt;-</span> <span class="fu">MakeADFun</span><span class="op">(</span><span class="va">f</span>, <span class="va">parameters</span>, random<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"a"</span>, <span class="st">"b"</span><span class="op">)</span>, silent<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="asymptotic-frequentist-approximatation-vs-full-posterior">Asymptotic (frequentist) approximatation vs full posterior<a class="anchor" aria-label="anchor" href="#asymptotic-frequentist-approximatation-vs-full-posterior"></a>
</h2>
<p>Instead of sampling from the posterior with MCMC (SNUTS), I can use
asymptotic tools from TMB to get a quick approximation of the
parameters, their covariances, but also uncertainties of generated
quantities via the generalized delta method. See the TMB documentation
for more background. Briefly, the marginal posterior mode is found and a
joint precision matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
determined at the conditional mode.
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Σ</mi><mo>=</mo><mi>Q</mi><mrow><mi>−</mi><mn>1</mn></mrow></mrow><annotation encoding="application/x-tex">\Sigma=Q{-1}</annotation></semantics></math>
is the covariance of the parameters.</p>
<p>First I optimize the model and call TMB’s <code>sdreport</code>
function to get approximate uncertainties via the delta method and the
joint precision matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># optimize</span></span>
<span><span class="va">opt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span><span class="op">(</span><span class="va">obj</span>, <span class="fu"><a href="https://rdrr.io/r/stats/nlminb.html" class="external-link">nlminb</a></span><span class="op">(</span><span class="va">par</span>, <span class="va">fn</span>, <span class="va">gr</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># get generalized delta method results and Q</span></span>
<span><span class="va">sdrep</span> <span class="op">&lt;-</span> <span class="fu">sdreport</span><span class="op">(</span><span class="va">obj</span>, getJointPrecision<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># get the generalized delta method estimates of asymptotic</span></span>
<span><span class="co"># standard errors</span></span>
<span><span class="va">est</span> <span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">as.list</a></span><span class="op">(</span><span class="va">sdrep</span>, <span class="st">'Estimate'</span>, report<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span><span class="op">$</span><span class="va">predWeight</span></span>
<span><span class="va">se</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">as.list</a></span><span class="op">(</span><span class="va">sdrep</span>, <span class="st">'Std. Error'</span>, report<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span><span class="op">$</span><span class="va">predWeight</span></span>
<span></span>
<span><span class="va">Q</span> <span class="op">&lt;-</span> <span class="va">sdrep</span><span class="op">$</span><span class="va">jointPrecision</span></span>
<span><span class="co"># can get the joint covariance and correlation like this</span></span>
<span><span class="va">Sigma</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/solve.html" class="external-link">solve</a></span><span class="op">(</span><span class="va">Q</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">cor</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">cov2cor</a></span><span class="op">(</span><span class="va">Sigma</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/plot_Q.html">plot_Q</a></span><span class="op">(</span>Q<span class="op">=</span><span class="va">Q</span><span class="op">)</span></span></code></pre></div>
<p><img src="SNUTS-for-TMB-models_files/figure-html/unnamed-chunk-3-1.png" width="700"></p>
<p>Now I run SNUTS on it and get posterior samples to compare to.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># some very strong negative correlations so I expect a dense or</span></span>
<span><span class="co"># sparse metric to be selected with SNUTS. Because I optimized</span></span>
<span><span class="co"># above can skip that</span></span>
<span><span class="va">mcmc</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sample_snuts.html">sample_snuts</a></span><span class="op">(</span><span class="va">obj</span>, chains<span class="op">=</span><span class="fl">1</span>, init<span class="op">=</span><span class="st">'random'</span>, seed<span class="op">=</span><span class="fl">1234</span>,</span>
<span>                     refresh<span class="op">=</span><span class="fl">0</span>, skip_optimization<span class="op">=</span><span class="cn">TRUE</span>,</span>
<span>                     Q<span class="op">=</span><span class="va">Q</span>, Qinv<span class="op">=</span><span class="va">Sigma</span><span class="op">)</span></span>
<span><span class="co">#&gt; Q is 91.85% zeroes, with condition factor=74028 (min=0.014, max=1018.9)</span></span>
<span><span class="co">#&gt; Rebuilding RTMB obj without random effects...</span></span>
<span><span class="co">#&gt; dense metric selected b/c faster than sparse and high correlation (0.81)</span></span>
<span><span class="co">#&gt; log-posterior at inits=-2627.037; at conditional mode=-2574.481</span></span>
<span><span class="co">#&gt; Starting MCMC sampling...</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Gradient evaluation took 0.00013 seconds</span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 1.3 seconds.</span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Elapsed Time: 0.232 seconds (Warm-up)</span></span>
<span><span class="co">#&gt;                1.193 seconds (Sampling)</span></span>
<span><span class="co">#&gt;                1.425 seconds (Total)</span></span>
<span><span class="co">#&gt; 1 of 1150 (0.09%) iterations ended with a divergence.</span></span>
<span><span class="co">#&gt; These divergent transitions indicate that HMC is not fully able to explore the posterior distribution.</span></span>
<span><span class="co">#&gt; Try increasing adapt_delta closer to 1.</span></span>
<span><span class="co">#&gt; If this doesn't remove all divergences, try to reparameterize the model.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Model 'RTMB' has 105 pars, and was fit using NUTS with a 'dense' metric</span></span>
<span><span class="co">#&gt; 1 chain(s) of 1150 total iterations (150 warmup) were used</span></span>
<span><span class="co">#&gt; Average run time per chain was 1.43 seconds </span></span>
<span><span class="co">#&gt; Minimum ESS=324.07 (32.41%), and maximum Rhat=1.023</span></span>
<span><span class="co">#&gt; There were 0 divergences after warmup</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="va">mcmc</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="../reference/plot_uncertainties.html">plot_uncertainties</a></span><span class="op">(</span><span class="va">mcmc</span><span class="op">)</span></span></code></pre></div>
<p><img src="SNUTS-for-TMB-models_files/figure-html/unnamed-chunk-4-1.png" width="700"></p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co">## get posterior of generated quantities</span></span>
<span><span class="va">predWeight</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">post</span>,<span class="fl">1</span>, \<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">obj</span><span class="op">$</span><span class="fu">report</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">$</span><span class="va">predWeight</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">predWeight</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt;  num [1:1000, 1:578] 28.1 29.3 23.5 24.8 26.7 ...</span></span>
<span></span>
<span><span class="co"># compare asymptotic vs posterior intervals of first few chicks</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">ii</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">y</span> <span class="op">&lt;-</span> <span class="va">predWeight</span><span class="op">[</span>,<span class="va">ii</span><span class="op">]</span></span>
<span>  <span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>, len<span class="op">=</span><span class="fl">200</span><span class="op">)</span></span>
<span>  <span class="va">y2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">x</span>,<span class="va">est</span><span class="op">[</span><span class="va">ii</span><span class="op">]</span>, <span class="va">se</span><span class="op">[</span><span class="va">ii</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/hist.html" class="external-link">hist</a></span><span class="op">(</span><span class="va">y</span>, freq<span class="op">=</span><span class="cn">FALSE</span>, ylim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">y2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y2</span>, col<span class="op">=</span><span class="fl">2</span>, lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p><img src="SNUTS-for-TMB-models_files/figure-html/unnamed-chunk-4-2.png" width="700"></p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="fu"><a href="https://rdrr.io/r/grDevices/dev.html" class="external-link">dev.off</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; null device </span></span>
<span><span class="co">#&gt;           1</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="simulation-of-parameters-and-data">Simulation of parameters and data<a class="anchor" aria-label="anchor" href="#simulation-of-parameters-and-data"></a>
</h2>
<p>Simulation of data can be done directly in R. Specialized simulation
functionality exists for TMB, and to a lesser degree RTMB, but I keep it
simple here for demonstration purposes.</p>
<p>Both data and parameters can be simulated and I explore that
below.</p>
<div class="section level3">
<h3 id="prior-and-posterior-predictive-distributions">Prior and posterior predictive distributions<a class="anchor" aria-label="anchor" href="#prior-and-posterior-predictive-distributions"></a>
</h3>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># simulation of data sets can be done manually in R. For instance</span></span>
<span><span class="co"># to get posterior predictive I loop through each posterior</span></span>
<span><span class="co"># sample and draw new data.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">351231</span><span class="op">)</span></span>
<span><span class="va">simdat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">post</span>,<span class="fl">1</span>, \<span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">{</span></span>
<span>   <span class="va">yhat</span> <span class="op">&lt;-</span> <span class="va">obj</span><span class="op">$</span><span class="fu">report</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">$</span><span class="va">predWeight</span></span>
<span>   <span class="va">ysim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span>n<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">yhat</span><span class="op">)</span>, <span class="va">yhat</span>, sd<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">x</span><span class="op">[</span><span class="st">'logsdeps'</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/boxplot.html" class="external-link">boxplot</a></span><span class="op">(</span><span class="va">simdat</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">24</span><span class="op">]</span>, main<span class="op">=</span><span class="st">'Posterior predictive'</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html" class="external-link">points</a></span><span class="op">(</span><span class="va">ChickWeight</span><span class="op">$</span><span class="va">weight</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">24</span><span class="op">]</span>, col<span class="op">=</span><span class="fl">2</span>, cex<span class="op">=</span><span class="fl">2</span>, pch<span class="op">=</span><span class="fl">16</span><span class="op">)</span></span></code></pre></div>
<p><img src="SNUTS-for-TMB-models_files/figure-html/unnamed-chunk-5-1.png" width="700"></p>
<p>Prior predictive sampling would be done in the same way but is not
shown here.</p>
</div>
<div class="section level3">
<h3 id="joint-precision-sampling">Joint precision sampling<a class="anchor" aria-label="anchor" href="#joint-precision-sampling"></a>
</h3>
<p>Samples can be drawn from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>,
assuming multivariate normality, as follows:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># likewise I can simulate draws from Q to get approximate samples</span></span>
<span><span class="va">postQ</span> <span class="op">&lt;-</span> <span class="fu">mvtnorm</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/mvtnorm/man/Mvnorm.html" class="external-link">rmvnorm</a></span><span class="op">(</span><span class="fl">1000</span>, mean<span class="op">=</span><span class="va">mcmc</span><span class="op">$</span><span class="va">mle</span><span class="op">$</span><span class="va">est</span>, sigma<span class="op">=</span><span class="va">Sigma</span><span class="op">)</span></span></code></pre></div>
<p>These samples could be put back into the <code>report</code> function
to get a distribution of a generated quantity, for instance.</p>
</div>
</div>
<div class="section level2">
<h2 id="model-selection-with-psis-loo">Model selection with PSIS-LOO<a class="anchor" aria-label="anchor" href="#model-selection-with-psis-loo"></a>
</h2>
<p>PSIS-LOO is the recommended way to compare predictive performance of
Bayesian models. I use it to compare a simplified Chicks model below
using the <code>map</code> argument to turn off estimation of the random
intercepts (‘b’). All this requires is for the vector of log-likelihood
values to be available for each posterior draw. I facilitate this via a
<code>REPORT(loglik)</code> call above.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mc-stan.org/loo/" class="external-link">loo</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; This is loo version 2.8.0</span></span>
<span><span class="co">#&gt; - Online documentation and vignettes at mc-stan.org/loo</span></span>
<span><span class="co">#&gt; - As of v2.0.0 loo defaults to 1 core but we recommend using as many as possible. Use the 'cores' argument or set options(mc.cores = NUM_CORES) for an entire session.</span></span>
<span><span class="co">#&gt; - Windows 10 users: loo may be very slow if 'mc.cores' is set in your .Rprofile file (see https://github.com/stan-dev/loo/issues/94).</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span>mc.cores<span class="op">=</span><span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/detectCores.html" class="external-link">detectCores</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">loglik</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">post</span>,<span class="fl">1</span>, \<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">obj</span><span class="op">$</span><span class="fu">report</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">$</span><span class="va">loglik</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">loo1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/loo/reference/loo.html" class="external-link">loo</a></span><span class="op">(</span><span class="va">loglik</span>, cores<span class="op">=</span><span class="fl">4</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">loo1</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Computed from 1000 by 578 log-likelihood matrix.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;          Estimate   SE</span></span>
<span><span class="co">#&gt; elpd_loo  -2351.8 19.9</span></span>
<span><span class="co">#&gt; p_loo        88.5  6.9</span></span>
<span><span class="co">#&gt; looic      4703.6 39.7</span></span>
<span><span class="co">#&gt; ------</span></span>
<span><span class="co">#&gt; MCSE of elpd_loo is NA.</span></span>
<span><span class="co">#&gt; MCSE and ESS estimates assume independent draws (r_eff=1).</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Pareto k diagnostic values:</span></span>
<span><span class="co">#&gt;                           Count Pct.    Min. ESS</span></span>
<span><span class="co">#&gt; (-Inf, 0.67]   (good)     572   99.0%   103     </span></span>
<span><span class="co">#&gt;    (0.67, 1]   (bad)        6    1.0%   &lt;NA&gt;    </span></span>
<span><span class="co">#&gt;     (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;    </span></span>
<span><span class="co">#&gt; See help('pareto-k-diagnostic') for details.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">loo1</span><span class="op">)</span></span></code></pre></div>
<p><img src="SNUTS-for-TMB-models_files/figure-html/unnamed-chunk-7-1.png" width="700"></p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># I can compare that to a simpler model which doesn't have</span></span>
<span><span class="co"># random effects on the slope</span></span>
<span><span class="va">obj2</span> <span class="op">&lt;-</span> <span class="fu">MakeADFun</span><span class="op">(</span><span class="va">f</span>, <span class="va">parameters</span>, random<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"a"</span><span class="op">)</span>, silent<span class="op">=</span><span class="cn">TRUE</span>,</span>
<span>                  map<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>b<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">parameters</span><span class="op">$</span><span class="va">b</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, </span>
<span>                           logsdb<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="cn">NA</span><span class="op">)</span>,</span>
<span>                           mub<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="cn">NA</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">mcmc2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sample_snuts.html">sample_snuts</a></span><span class="op">(</span><span class="va">obj2</span>, chains<span class="op">=</span><span class="fl">1</span>, seed<span class="op">=</span><span class="fl">1215</span>, refresh<span class="op">=</span><span class="fl">0</span><span class="op">)</span></span>
<span><span class="co">#&gt; Optimizing...</span></span>
<span><span class="co">#&gt; Getting Q...</span></span>
<span><span class="co">#&gt; Inverting Q...</span></span>
<span><span class="co">#&gt; Q is 88.9% zeroes, with condition factor=8423 (min=0.128, max=1080.5)</span></span>
<span><span class="co">#&gt; Rebuilding RTMB obj without random effects...</span></span>
<span><span class="co">#&gt; diag metric selected b/c of low correlations</span></span>
<span><span class="co">#&gt; log-posterior at inits=-2745.519; at conditional mode=-2745.519</span></span>
<span><span class="co">#&gt; Starting MCMC sampling...</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Gradient evaluation took 8.7e-05 seconds</span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.87 seconds.</span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Elapsed Time: 0.126 seconds (Warm-up)</span></span>
<span><span class="co">#&gt;                0.733 seconds (Sampling)</span></span>
<span><span class="co">#&gt;                0.859 seconds (Total)</span></span>
<span><span class="co">#&gt; 1 of 1150 (0.09%) iterations ended with a divergence.</span></span>
<span><span class="co">#&gt; These divergent transitions indicate that HMC is not fully able to explore the posterior distribution.</span></span>
<span><span class="co">#&gt; Try increasing adapt_delta closer to 1.</span></span>
<span><span class="co">#&gt; If this doesn't remove all divergences, try to reparameterize the model.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Model 'RTMB' has 53 pars, and was fit using NUTS with a 'diag' metric</span></span>
<span><span class="co">#&gt; 1 chain(s) of 1150 total iterations (150 warmup) were used</span></span>
<span><span class="co">#&gt; Average run time per chain was 0.86 seconds </span></span>
<span><span class="co">#&gt; Minimum ESS=402.16 (40.22%), and maximum Rhat=1.007</span></span>
<span><span class="co">#&gt; There were 0 divergences after warmup</span></span>
<span><span class="va">post2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="va">mcmc2</span><span class="op">)</span></span>
<span><span class="va">loglik2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">post2</span>,<span class="fl">1</span>, \<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">obj2</span><span class="op">$</span><span class="fu">report</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">$</span><span class="va">loglik</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">loo2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/loo/reference/loo.html" class="external-link">loo</a></span><span class="op">(</span><span class="va">loglik2</span>, cores<span class="op">=</span><span class="fl">4</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">loo2</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Computed from 1000 by 578 log-likelihood matrix.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;          Estimate   SE</span></span>
<span><span class="co">#&gt; elpd_loo  -2613.1 14.4</span></span>
<span><span class="co">#&gt; p_loo        31.8  3.0</span></span>
<span><span class="co">#&gt; looic      5226.2 28.9</span></span>
<span><span class="co">#&gt; ------</span></span>
<span><span class="co">#&gt; MCSE of elpd_loo is NA.</span></span>
<span><span class="co">#&gt; MCSE and ESS estimates assume independent draws (r_eff=1).</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Pareto k diagnostic values:</span></span>
<span><span class="co">#&gt;                           Count Pct.    Min. ESS</span></span>
<span><span class="co">#&gt; (-Inf, 0.67]   (good)     577   99.8%   195     </span></span>
<span><span class="co">#&gt;    (0.67, 1]   (bad)        1    0.2%   &lt;NA&gt;    </span></span>
<span><span class="co">#&gt;     (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;    </span></span>
<span><span class="co">#&gt; See help('pareto-k-diagnostic') for details.</span></span>
<span><span class="fu"><a href="https://mc-stan.org/loo/reference/loo_compare.html" class="external-link">loo_compare</a></span><span class="op">(</span><span class="va">loo1</span>, <span class="va">loo2</span><span class="op">)</span></span>
<span><span class="co">#&gt;        elpd_diff se_diff</span></span>
<span><span class="co">#&gt; model1    0.0       0.0 </span></span>
<span><span class="co">#&gt; model2 -261.3      19.3</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="advanced-features">Advanced features<a class="anchor" aria-label="anchor" href="#advanced-features"></a>
</h2>
<div class="section level3">
<h3 id="adaptation-of-stan-diagonal-mass-matrix">Adaptation of Stan diagonal mass matrix<a class="anchor" aria-label="anchor" href="#adaptation-of-stan-diagonal-mass-matrix"></a>
</h3>
<p>When the estimate of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
does not well approximate the posterior surface, then it may be
advantageous to adapt a diagonal mass matrix to account for changes in
scale. This can be controlled via the <code>adapt_stan_metric</code>
argument. This argument is automatically set to FALSE when using a
metric other than ‘stan’ and ‘unit’ since all other metrics in theory
already descale the posterior. This can be overridden by setting it
equal to TRUE</p>
<p>Here I run three versions of the model and compare the NUTS stepsize.
The model version without adaptation uses a shorter warmup period</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">adapted1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sample_snuts.html">sample_snuts</a></span><span class="op">(</span><span class="va">obj</span>, chains<span class="op">=</span><span class="fl">1</span>, seed<span class="op">=</span><span class="fl">1234</span>, refresh<span class="op">=</span><span class="fl">0</span>,</span>
<span>                        skip_optimization<span class="op">=</span><span class="cn">TRUE</span>, Q<span class="op">=</span><span class="va">Q</span>, Qinv<span class="op">=</span><span class="va">Sigma</span>,</span>
<span>                        metric<span class="op">=</span><span class="st">'auto'</span>, adapt_stan_metric <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Q is 91.85% zeroes, with condition factor=74028 (min=0.014, max=1018.9)</span></span>
<span><span class="co">#&gt; Rebuilding RTMB obj without random effects...</span></span>
<span><span class="co">#&gt; dense metric selected b/c faster than sparse and high correlation (0.81)</span></span>
<span><span class="co">#&gt; log-posterior at inits=-2574.481; at conditional mode=-2574.481</span></span>
<span><span class="co">#&gt; Starting MCMC sampling...</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Gradient evaluation took 0.000152 seconds</span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 1.52 seconds.</span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Elapsed Time: 1.747 seconds (Warm-up)</span></span>
<span><span class="co">#&gt;                2.118 seconds (Sampling)</span></span>
<span><span class="co">#&gt;                3.865 seconds (Total)</span></span>
<span><span class="co">#&gt; 5 of 2000 (0.25%) iterations ended with a divergence.</span></span>
<span><span class="co">#&gt; These divergent transitions indicate that HMC is not fully able to explore the posterior distribution.</span></span>
<span><span class="co">#&gt; Try increasing adapt_delta closer to 1.</span></span>
<span><span class="co">#&gt; If this doesn't remove all divergences, try to reparameterize the model.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Model 'RTMB' has 105 pars, and was fit using NUTS with a 'dense' metric</span></span>
<span><span class="co">#&gt; 1 chain(s) of 2000 total iterations (1000 warmup) were used</span></span>
<span><span class="co">#&gt; Average run time per chain was 3.87 seconds </span></span>
<span><span class="co">#&gt; Minimum ESS=661.27 (66.13%), and maximum Rhat=1.008</span></span>
<span><span class="co">#&gt; There were 0 divergences after warmup</span></span>
<span><span class="va">adapted2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sample_snuts.html">sample_snuts</a></span><span class="op">(</span><span class="va">obj</span>, chains<span class="op">=</span><span class="fl">1</span>, seed<span class="op">=</span><span class="fl">1234</span>, refresh<span class="op">=</span><span class="fl">0</span>,</span>
<span>                     skip_optimization<span class="op">=</span><span class="cn">TRUE</span>, Q<span class="op">=</span><span class="va">Q</span>, Qinv<span class="op">=</span><span class="va">Sigma</span>,</span>
<span>                     metric<span class="op">=</span><span class="st">'stan'</span>, adapt_stan_metric <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Rebuilding RTMB obj without random effects...</span></span>
<span><span class="co">#&gt; log-posterior at inits=-2574.399</span></span>
<span><span class="co">#&gt; Starting MCMC sampling...</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Gradient evaluation took 9.3e-05 seconds</span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.93 seconds.</span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Elapsed Time: 8.602 seconds (Warm-up)</span></span>
<span><span class="co">#&gt;                3.038 seconds (Sampling)</span></span>
<span><span class="co">#&gt;                11.64 seconds (Total)</span></span>
<span><span class="co">#&gt; 23 of 2000 (1.15%) iterations ended with a divergence.</span></span>
<span><span class="co">#&gt; These divergent transitions indicate that HMC is not fully able to explore the posterior distribution.</span></span>
<span><span class="co">#&gt; Try increasing adapt_delta closer to 1.</span></span>
<span><span class="co">#&gt; If this doesn't remove all divergences, try to reparameterize the model.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Model 'RTMB' has 105 pars, and was fit using NUTS with a 'stan' metric</span></span>
<span><span class="co">#&gt; 1 chain(s) of 2000 total iterations (1000 warmup) were used</span></span>
<span><span class="co">#&gt; Average run time per chain was 11.64 seconds </span></span>
<span><span class="co">#&gt; Minimum ESS=580.82 (58.08%), and maximum Rhat=1.007</span></span>
<span><span class="co">#&gt; There were 0 divergences after warmup</span></span>
<span><span class="va">sp1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/extract_sampler_params.html">extract_sampler_params</a></span><span class="op">(</span><span class="va">mcmc</span>, inc_warmup <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">iteration</span> <span class="op">&lt;=</span> <span class="fl">1050</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span>type<span class="op">=</span><span class="st">'descaled + not adapted'</span><span class="op">)</span></span>
<span><span class="va">sp2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/extract_sampler_params.html">extract_sampler_params</a></span><span class="op">(</span><span class="va">adapted1</span>, inc_warmup <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">iteration</span> <span class="op">&lt;=</span> <span class="fl">1050</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span>type<span class="op">=</span><span class="st">'descaled + adapted'</span><span class="op">)</span></span>
<span><span class="va">sp3</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/extract_sampler_params.html">extract_sampler_params</a></span><span class="op">(</span><span class="va">adapted2</span>, inc_warmup <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">iteration</span> <span class="op">&lt;=</span> <span class="fl">1050</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span>type<span class="op">=</span><span class="st">'adapted'</span><span class="op">)</span></span>
<span><span class="va">sp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="va">sp1</span>, <span class="va">sp2</span>, <span class="va">sp3</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">sp</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">iteration</span>, y<span class="op">=</span><span class="va">stepsize__</span>, color<span class="op">=</span><span class="va">type</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html" class="external-link">scale_y_log10</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html" class="external-link">theme_bw</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html" class="external-link">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">'top'</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>color<span class="op">=</span><span class="cn">NULL</span>, x<span class="op">=</span><span class="st">'warmup'</span><span class="op">)</span></span></code></pre></div>
<p><img src="SNUTS-for-TMB-models_files/figure-html/unnamed-chunk-8-1.png" width="700"></p>
<p>It is apparent that during the first warmup phase the model with Stan
defaults (‘adapted’ in the above plot) has a large adjustment in
stepsize and this corresponds to very long trajectory lengths and thus
increased computational time. If descaled using
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
the adaptation does nothing (‘descaled + adapted’), which is why such a
short warmup period can be used with SNUTS (‘descaled + not adapted’) in
this case, and often which is why the default warmup is short and
adaptation disabled for SNUTS.</p>
<p>In other cases a longer warmup and mass matrix adaptation will make a
difference, see for example the ‘wildf’ model in <span class="citation">C. C. Monnahan et al. (in prep)</span>.</p>
</div>
<div class="section level3">
<h3 id="embedded-laplace-approximation-snuts">Embedded Laplace approximation SNUTS<a class="anchor" aria-label="anchor" href="#embedded-laplace-approximation-snuts"></a>
</h3>
<p>This approach uses NUTS (or SNUTS) to sample from the marginal
posterior using the Laplace approximation to integrate the random
effects. This was first explored in <span class="citation">(C. C.
Monnahan and Kristensen 2018)</span> and later in more detail in <span class="citation">(Margossian et al. 2020)</span> who called it the
‘embedded Laplace approximation’. <span class="citation">(C. C. Monnahan
et al. in prep)</span> applied this to a much larger set of models and
found mixed results.</p>
<p>It is trivial to try in SNUTS by simply declaring
<code>laplace=TRUE</code>.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ela</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sample_snuts.html">sample_snuts</a></span><span class="op">(</span><span class="va">obj</span>, chains<span class="op">=</span><span class="fl">1</span>, laplace<span class="op">=</span><span class="cn">TRUE</span>, refresh<span class="op">=</span><span class="fl">0</span><span class="op">)</span></span>
<span><span class="co">#&gt; Optimizing...</span></span>
<span><span class="co">#&gt; Getting M for fixed effects...</span></span>
<span><span class="co">#&gt; Qinv is 0% zeroes, with condition factor=3107 (min=0.001, max=3.3)</span></span>
<span><span class="co">#&gt; diag metric selected b/c low correlations</span></span>
<span><span class="co">#&gt; log-posterior at inits=-2451.942; at conditional mode=-17038.961</span></span>
<span><span class="co">#&gt; Starting MCMC sampling...</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Gradient evaluation took 0.000993 seconds</span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 9.93 seconds.</span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Elapsed Time: 1.166 seconds (Warm-up)</span></span>
<span><span class="co">#&gt;                5.193 seconds (Sampling)</span></span>
<span><span class="co">#&gt;                6.359 seconds (Total)</span></span>
<span><span class="co">#&gt; 1 of 1150 (0.09%) iterations ended with a divergence.</span></span>
<span><span class="co">#&gt; These divergent transitions indicate that HMC is not fully able to explore the posterior distribution.</span></span>
<span><span class="co">#&gt; Try increasing adapt_delta closer to 1.</span></span>
<span><span class="co">#&gt; If this doesn't remove all divergences, try to reparameterize the model.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Model 'RTMB' has 5 pars, and was fit using NUTS with a 'diag' metric</span></span>
<span><span class="co">#&gt; 1 chain(s) of 1150 total iterations (150 warmup) were used</span></span>
<span><span class="co">#&gt; Average run time per chain was 6.36 seconds </span></span>
<span><span class="co">#&gt; Minimum ESS=574.05 (57.4%), and maximum Rhat=1.006</span></span>
<span><span class="co">#&gt; There were 0 divergences after warmup</span></span></code></pre></div>
<p>Here I can see there are only 5 model parameters (the fixed effects),
and that a diagonal metric was chosen due to minimal correlations among
these parameters. ELA will typically take longer to run, but have higher
minESS and so it is best to compare the efficiency (minESS per time)
which I do not do here.</p>
<p>Exploring ELA is a good opportunity to show how SNUTS can fail. I
demonstrate this with the notoriously difficult ‘funnel’ model which is
a hierarchical model without any data. This model has strongly varying
curvature and thus is <strong>not</strong> well-approximated by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>
so SNUTS mixes poorly. But after turning on ELA, it mixes fine and
recovers the</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Funnel example ported to RTMB from</span></span>
<span><span class="co"># https://mc-stan.org/docs/cmdstan-guide/diagnose_utility.html#running-the-diagnose-command</span></span>
<span><span class="co">## the (negative) posterior density as a function in R</span></span>
<span><span class="va">f</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">pars</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/RTMB/man/TMB-interface.html" class="external-link">getAll</a></span><span class="op">(</span><span class="va">pars</span><span class="op">)</span></span>
<span>  <span class="va">lp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">y</span>, <span class="fl">0</span>, <span class="fl">3</span>, log<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span> <span class="op">+</span> <span class="co"># prior</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">y</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span>, log<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span> <span class="co"># likelihood</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="op">-</span><span class="va">lp</span><span class="op">)</span> <span class="co"># TMB expects negative log posterior</span></span>
<span><span class="op">}</span></span>
<span><span class="va">obj</span> <span class="op">&lt;-</span> <span class="fu">RTMB</span><span class="fu">::</span><span class="fu">MakeADFun</span><span class="op">(</span><span class="va">f</span>, <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>y<span class="op">=</span><span class="op">-</span><span class="fl">1.12</span>, x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">9</span><span class="op">)</span><span class="op">)</span>, random<span class="op">=</span><span class="st">'x'</span>, silent<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co">### Now SNUTS</span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sample_snuts.html">sample_snuts</a></span><span class="op">(</span><span class="va">obj</span>, seed<span class="op">=</span><span class="fl">1213</span>, refresh<span class="op">=</span><span class="fl">0</span>, init<span class="op">=</span><span class="st">'random'</span><span class="op">)</span></span>
<span><span class="co">#&gt; Optimizing...</span></span>
<span><span class="co">#&gt; Getting Q...</span></span>
<span><span class="co">#&gt; Inverting Q...</span></span>
<span><span class="co">#&gt; Q is 100% zeroes, with condition factor=9 (min=0.111, max=1)</span></span>
<span><span class="co">#&gt; Rebuilding RTMB obj without random effects...</span></span>
<span><span class="co">#&gt; diag metric selected b/c of low correlations</span></span>
<span><span class="co">#&gt; log-posterior at inits=-237.116; at conditional mode=-10.288</span></span>
<span><span class="co">#&gt; Starting MCMC sampling...</span></span>
<span><span class="co">#&gt; Preparing parallel workspace...</span></span>
<span><span class="co">#&gt; Chain 1: Gradient evaluation took 0.000122 seconds</span></span>
<span><span class="co">#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.22 seconds.</span></span>
<span><span class="co">#&gt; Chain 1: Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; Chain 2: Gradient evaluation took 0.000116 seconds</span></span>
<span><span class="co">#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1.16 seconds.</span></span>
<span><span class="co">#&gt; Chain 2: Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; Chain 3: Gradient evaluation took 0.000107 seconds</span></span>
<span><span class="co">#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 1.07 seconds.</span></span>
<span><span class="co">#&gt; Chain 3: Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; Chain 4: Gradient evaluation took 0.00011 seconds</span></span>
<span><span class="co">#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 1.1 seconds.</span></span>
<span><span class="co">#&gt; Chain 4: Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; Chain 3:  Elapsed Time: 0.957 seconds (Warm-up)</span></span>
<span><span class="co">#&gt; Chain 3:                2.436 seconds (Sampling)</span></span>
<span><span class="co">#&gt; Chain 3:                3.393 seconds (Total)</span></span>
<span><span class="co">#&gt; Chain 4:  Elapsed Time: 0.473 seconds (Warm-up)</span></span>
<span><span class="co">#&gt; Chain 4:                2.74 seconds (Sampling)</span></span>
<span><span class="co">#&gt; Chain 4:                3.213 seconds (Total)</span></span>
<span><span class="co">#&gt; Chain 1:  Elapsed Time: 0.329 seconds (Warm-up)</span></span>
<span><span class="co">#&gt; Chain 1:                3.914 seconds (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1:                4.243 seconds (Total)</span></span>
<span><span class="co">#&gt; Chain 2:  Elapsed Time: 0.71 seconds (Warm-up)</span></span>
<span><span class="co">#&gt; Chain 2:                6.747 seconds (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2:                7.457 seconds (Total)</span></span>
<span><span class="co">#&gt; 39 of 4600 (0.85%) iterations ended with a divergence.</span></span>
<span><span class="co">#&gt; These divergent transitions indicate that HMC is not fully able to explore the posterior distribution.</span></span>
<span><span class="co">#&gt; Try increasing adapt_delta closer to 1.</span></span>
<span><span class="co">#&gt; If this doesn't remove all divergences, try to reparameterize the model.</span></span>
<span><span class="co">#&gt; 4 of 4 chains had an E-BFMI below the nominal threshold of 0.3 which suggests that HMC may have trouble exploring the target distribution.</span></span>
<span><span class="co">#&gt; If possible, try to reparameterize the model.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Model 'RTMB' has 10 pars, and was fit using NUTS with a 'diag' metric</span></span>
<span><span class="co">#&gt; 4 chain(s) of 1150 total iterations (150 warmup) were used</span></span>
<span><span class="co">#&gt; Average run time per chain was 4.58 seconds </span></span>
<span><span class="co">#&gt; Minimum ESS=92.75 (2.32%), and maximum Rhat=1.044</span></span>
<span><span class="co">#&gt; !! Warning: Signs of non-convergence found. Do not use for inference !!</span></span>
<span><span class="co">#&gt; There were 4 divergences after warmup</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html" class="external-link">pairs</a></span><span class="op">(</span><span class="va">fit</span>, pars<span class="op">=</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<p><img src="SNUTS-for-TMB-models_files/figure-html/funnel-1.png" width="700"></p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># hasn't recovered the prior b/c it's not converged, particularly</span></span>
<span><span class="co"># for small y values</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html" class="external-link">hist</a></span><span class="op">(</span><span class="va">post</span><span class="op">$</span><span class="va">y</span>, freq<span class="op">=</span><span class="cn">FALSE</span>, xlim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">10</span>,<span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">x</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">10</span>,<span class="fl">10</span>, len<span class="op">=</span><span class="fl">200</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">0</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v<span class="op">=</span><span class="va">fit</span><span class="op">$</span><span class="va">mle</span><span class="op">$</span><span class="va">est</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, col<span class="op">=</span><span class="fl">2</span>, lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<p><img src="SNUTS-for-TMB-models_files/figure-html/funnel-2.png" width="700"></p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Now turn on ELA and it easily recovers the prior on y</span></span>
<span><span class="va">fit.ela</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sample_snuts.html">sample_snuts</a></span><span class="op">(</span><span class="va">obj</span>, laplace<span class="op">=</span><span class="cn">TRUE</span>, refresh<span class="op">=</span><span class="fl">0</span>, init<span class="op">=</span><span class="st">'random'</span>, seed<span class="op">=</span><span class="fl">12312</span><span class="op">)</span></span>
<span><span class="co">#&gt; Optimizing...</span></span>
<span><span class="co">#&gt; Getting M for fixed effects...</span></span>
<span><span class="co">#&gt; diag metric selected b/c only 1 parameter</span></span>
<span><span class="co">#&gt; log-posterior at inits=-3.181; at conditional mode=-2.087</span></span>
<span><span class="co">#&gt; Starting MCMC sampling...</span></span>
<span><span class="co">#&gt; Preparing parallel workspace...</span></span>
<span><span class="co">#&gt; Chain 1: Gradient evaluation took 0.018099 seconds</span></span>
<span><span class="co">#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 180.99 seconds.</span></span>
<span><span class="co">#&gt; Chain 1: Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; Chain 2: Gradient evaluation took 0.021238 seconds</span></span>
<span><span class="co">#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 212.38 seconds.</span></span>
<span><span class="co">#&gt; Chain 2: Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; Chain 3: Gradient evaluation took 0.024513 seconds</span></span>
<span><span class="co">#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 245.13 seconds.</span></span>
<span><span class="co">#&gt; Chain 3: Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; Chain 4: Gradient evaluation took 0.020786 seconds</span></span>
<span><span class="co">#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 207.86 seconds.</span></span>
<span><span class="co">#&gt; Chain 4: Adjust your expectations accordingly!</span></span>
<span><span class="co">#&gt; Chain 1:  Elapsed Time: 0.271 seconds (Warm-up)</span></span>
<span><span class="co">#&gt; Chain 1:                1.241 seconds (Sampling)</span></span>
<span><span class="co">#&gt; Chain 1:                1.512 seconds (Total)</span></span>
<span><span class="co">#&gt; Chain 2:  Elapsed Time: 0.219 seconds (Warm-up)</span></span>
<span><span class="co">#&gt; Chain 2:                1.18 seconds (Sampling)</span></span>
<span><span class="co">#&gt; Chain 2:                1.399 seconds (Total)</span></span>
<span><span class="co">#&gt; Chain 3:  Elapsed Time: 0.287 seconds (Warm-up)</span></span>
<span><span class="co">#&gt; Chain 3:                1.115 seconds (Sampling)</span></span>
<span><span class="co">#&gt; Chain 3:                1.402 seconds (Total)</span></span>
<span><span class="co">#&gt; Chain 4:  Elapsed Time: 0.249 seconds (Warm-up)</span></span>
<span><span class="co">#&gt; Chain 4:                1.16 seconds (Sampling)</span></span>
<span><span class="co">#&gt; Chain 4:                1.409 seconds (Total)</span></span>
<span><span class="co">#&gt; 6 of 4600 (0.13%) iterations ended with a divergence.</span></span>
<span><span class="co">#&gt; These divergent transitions indicate that HMC is not fully able to explore the posterior distribution.</span></span>
<span><span class="co">#&gt; Try increasing adapt_delta closer to 1.</span></span>
<span><span class="co">#&gt; If this doesn't remove all divergences, try to reparameterize the model.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Model 'RTMB' has 1 pars, and was fit using NUTS with a 'diag' metric</span></span>
<span><span class="co">#&gt; 4 chain(s) of 1150 total iterations (150 warmup) were used</span></span>
<span><span class="co">#&gt; Average run time per chain was 1.43 seconds </span></span>
<span><span class="co">#&gt; Minimum ESS=1834.24 (45.86%), and maximum Rhat=1.002</span></span>
<span><span class="co">#&gt; There were 0 divergences after warmup</span></span>
<span><span class="co"># you just get the prior back b/c the Laplace approximation is</span></span>
<span><span class="co"># accurate</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html" class="external-link">pairs</a></span><span class="op">(</span><span class="va">fit.ela</span><span class="op">)</span></span></code></pre></div>
<p><img src="SNUTS-for-TMB-models_files/figure-html/unnamed-chunk-10-1.png" width="700"></p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">post.ela</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="va">fit.ela</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html" class="external-link">hist</a></span><span class="op">(</span><span class="va">post.ela</span><span class="op">$</span><span class="va">y</span>, freq<span class="op">=</span><span class="cn">FALSE</span>, breaks<span class="op">=</span><span class="fl">30</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">x</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">10</span>,<span class="fl">10</span>, len<span class="op">=</span><span class="fl">200</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">0</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="SNUTS-for-TMB-models_files/figure-html/unnamed-chunk-10-2.png" width="700"></p>
</div>
<div class="section level3">
<h3 id="linking-to-other-stan-algorithms-via-stanestimators">Linking to other Stan algorithms via StanEstimators<a class="anchor" aria-label="anchor" href="#linking-to-other-stan-algorithms-via-stanestimators"></a>
</h3>
<p><code>sample_snuts</code> links to the
<code><a href="https://rdrr.io/pkg/StanEstimators/man/stan_sample.html" class="external-link">StanEstimators::stan_sample</a></code> function for NUTS sampling.
However, this package provides other algorithms given a model and these
may be of interest to some users. I focus on the Pathfinder algorithm
and an RTMB model.</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Construct a joint model (no random effects)</span></span>
<span><span class="va">obj2</span> <span class="op">&lt;-</span> <span class="fu">MakeADFun</span><span class="op">(</span>func<span class="op">=</span><span class="va">obj</span><span class="op">$</span><span class="va">env</span><span class="op">$</span><span class="va">data</span>, parameters<span class="op">=</span><span class="va">obj</span><span class="op">$</span><span class="va">env</span><span class="op">$</span><span class="fu">parList</span><span class="op">(</span><span class="op">)</span>, </span>
<span>                  map<span class="op">=</span><span class="va">obj</span><span class="op">$</span><span class="va">env</span><span class="op">$</span><span class="va">map</span>, random<span class="op">=</span><span class="cn">NULL</span>, silent<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co"># TMB does negative log densities so convert to form used by Stan</span></span>
<span><span class="va">fn</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span><span class="va">obj2</span><span class="op">$</span><span class="fu">fn</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="va">grad_fun</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span><span class="va">obj2</span><span class="op">$</span><span class="fu">gr</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="va">pf</span> <span class="op">&lt;-</span> <span class="fu">StanEstimators</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/StanEstimators/man/stan_pathfinder.html" class="external-link">stan_pathfinder</a></span><span class="op">(</span>fn<span class="op">=</span><span class="va">fn</span>, grad_fun<span class="op">=</span><span class="va">grad_fun</span>, refresh<span class="op">=</span><span class="fl">100</span>,</span>
<span>                      par_inits <span class="op">=</span> <span class="va">obj</span><span class="op">$</span><span class="va">env</span><span class="op">$</span><span class="va">last.par.best</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Path [1] :Initial log joint density = -10.287998</span></span>
<span><span class="co">#&gt; Path [1] : Iter      log prob        ||dx||      ||grad||     alpha      alpha0      # evals       ELBO    Best ELBO        Notes </span></span>
<span><span class="co">#&gt;               2       8.084e+01      3.600e+01   4.441e-15    1.000e+00  1.000e+00        51 -1.711e+19 -1.711e+19                  </span></span>
<span><span class="co">#&gt; Path [1] :Best Iter: [1] ELBO (-35.650319) evaluations: (51)</span></span>
<span><span class="co">#&gt; Path [2] :Initial log joint density = -10.287998</span></span>
<span><span class="co">#&gt; Path [2] : Iter      log prob        ||dx||      ||grad||     alpha      alpha0      # evals       ELBO    Best ELBO        Notes </span></span>
<span><span class="co">#&gt;               2       8.084e+01      3.600e+01   4.441e-15    1.000e+00  1.000e+00        51 -3.999e+20 -3.999e+20                  </span></span>
<span><span class="co">#&gt; Path [2] :Best Iter: [1] ELBO (-34.141497) evaluations: (51)</span></span>
<span><span class="co">#&gt; Path [3] :Initial log joint density = -10.287998</span></span>
<span><span class="co">#&gt; Path [3] : Iter      log prob        ||dx||      ||grad||     alpha      alpha0      # evals       ELBO    Best ELBO        Notes </span></span>
<span><span class="co">#&gt;               2       8.084e+01      3.600e+01   4.441e-15    1.000e+00  1.000e+00        51 -3.115e+20 -3.115e+20                  </span></span>
<span><span class="co">#&gt; Path [3] :Best Iter: [1] ELBO (-50.148681) evaluations: (51)</span></span>
<span><span class="co">#&gt; Path [4] :Initial log joint density = -10.287998</span></span>
<span><span class="co">#&gt; Path [4] : Iter      log prob        ||dx||      ||grad||     alpha      alpha0      # evals       ELBO    Best ELBO        Notes </span></span>
<span><span class="co">#&gt;               2       8.084e+01      3.600e+01   4.441e-15    1.000e+00  1.000e+00        51 -1.012e+22 -1.012e+22                  </span></span>
<span><span class="co">#&gt; Path [4] :Best Iter: [1] ELBO (-60.410036) evaluations: (51)</span></span>
<span><span class="co">#&gt; Total log probability function evaluations:4104</span></span>
<span><span class="co">#&gt; Pareto k value (1.6) is greater than 0.7. Importance resampling was not able to improve the approximation, which may indicate that the approximation itself is poor.</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="linking-to-other-bayesian-tools">Linking to other Bayesian tools<a class="anchor" aria-label="anchor" href="#linking-to-other-bayesian-tools"></a>
</h3>
<p>It is straightforward to pass <code>adnuts</code> output into other
Bayesian R packages. I demonstrate this with <code>bayesplot</code>.</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mc-stan.org/bayesplot/" class="external-link">bayesplot</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; This is bayesplot version 1.11.1</span></span>
<span><span class="co">#&gt; - Online documentation and vignettes at mc-stan.org/bayesplot</span></span>
<span><span class="co">#&gt; - bayesplot theme set to bayesplot::theme_default()</span></span>
<span><span class="co">#&gt;    * Does _not_ affect other ggplot2 plots</span></span>
<span><span class="co">#&gt;    * See ?bayesplot_theme_set for details on theme setting</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyr.tidyverse.org" class="external-link">tidyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org" class="external-link">dplyr</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Attaching package: 'dplyr'</span></span>
<span><span class="co">#&gt; The following objects are masked from 'package:stats':</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     filter, lag</span></span>
<span><span class="co">#&gt; The following objects are masked from 'package:base':</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     intersect, setdiff, setequal, union</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="va">mcmc</span><span class="op">)</span></span>
<span><span class="va">pars</span> <span class="op">&lt;-</span> <span class="va">mcmc</span><span class="op">$</span><span class="va">par_names</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/MCMC-intervals.html" class="external-link">mcmc_areas</a></span><span class="op">(</span><span class="va">post</span>, pars<span class="op">=</span><span class="va">pars</span><span class="op">)</span></span></code></pre></div>
<p><img src="SNUTS-for-TMB-models_files/figure-html/bayesplot-1.png" width="700"></p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/MCMC-traces.html" class="external-link">mcmc_trace</a></span><span class="op">(</span><span class="va">post</span>, pars<span class="op">=</span><span class="va">pars</span><span class="op">)</span></span></code></pre></div>
<p><img src="SNUTS-for-TMB-models_files/figure-html/bayesplot-2.png" width="700"></p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/bayesplot-colors.html" class="external-link">color_scheme_set</a></span><span class="op">(</span><span class="st">"red"</span><span class="op">)</span></span>
<span><span class="va">np</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/extract_sampler_params.html">extract_sampler_params</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/pivot_longer.html" class="external-link">pivot_longer</a></span><span class="op">(</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">chain</span>, <span class="va">iteration</span><span class="op">)</span>, names_to<span class="op">=</span><span class="st">'Parameter'</span>, values_to<span class="op">=</span><span class="st">'Value'</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span>Iteration<span class="op">=</span><span class="va">iteration</span>, <span class="va">Parameter</span>, <span class="va">Value</span>, Chain<span class="op">=</span><span class="va">chain</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>Parameter<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="va">Parameter</span><span class="op">)</span>,</span>
<span>         Iteration<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/integer.html" class="external-link">as.integer</a></span><span class="op">(</span><span class="va">Iteration</span><span class="op">)</span>,</span>
<span>         Chain<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/integer.html" class="external-link">as.integer</a></span><span class="op">(</span><span class="va">Chain</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/MCMC-nuts.html" class="external-link">mcmc_nuts_energy</a></span><span class="op">(</span><span class="va">np</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ggtitle</a></span><span class="op">(</span><span class="st">"NUTS Energy Diagnostic"</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html" class="external-link">theme_minimal</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</span></span>
<span><span class="co">#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</span></span></code></pre></div>
<p><img src="SNUTS-for-TMB-models_files/figure-html/bayesplot-3.png" width="700"></p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># finally, posterior predictive for first 24 observations</span></span>
<span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/PPC-intervals.html" class="external-link">ppc_intervals</a></span><span class="op">(</span>y<span class="op">=</span><span class="va">ChickWeight</span><span class="op">$</span><span class="va">weight</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">24</span><span class="op">]</span>, yrep<span class="op">=</span><span class="va">simdat</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">24</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<p><img src="SNUTS-for-TMB-models_files/figure-html/bayesplot-4.png" width="700"></p>
</div>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-margossian2020" class="csl-entry">
Margossian, Charles, Aki Vehtari, Daniel Simpson, and Raj Agrawal. 2020.
<span>“Hamiltonian <span>M</span>onte <span>C</span>arlo Using an
Adjoint-Differentiated <span>L</span>aplace Approximation:
<span>B</span>ayesian Inference for Latent <span>G</span>aussian Models
and Beyond.”</span> In <em>Advances in <span>N</span>eural
<span>I</span>nformation <span>P</span>rocessing
<span>S</span>ystems</em>, edited by H. Larochelle, M. Ranzato, R.
Hadsell, M. F. Balcan, and H. Lin, 33:9086–97. Curran Associates, Inc.
<a href="https://proceedings.neurips.cc/paper_files/paper/2020/file/673de96b04fa3adcae1aacda704217ef-Paper.pdf" class="external-link">https://proceedings.neurips.cc/paper_files/paper/2020/file/673de96b04fa3adcae1aacda704217ef-Paper.pdf</a>.
</div>
<div id="ref-monnahan2018" class="csl-entry">
Monnahan, C. C, and Kasper Kristensen. 2018. <span>“No-u-Turn Sampling
for Fast Bayesian Inference in ADMB and TMB: Introducing the Adnuts and
Tmbstan r Packages.”</span> <em>PloS One</em> 13 (5).
</div>
<div id="ref-monnahan2025" class="csl-entry">
Monnahan, C. C., Thorson J. T., K. Kristensen, and B. Carpenter. in
prep. <span>“Leveraging Sparsity to Improve No-u-Turn Sampling
Efficiency for Hierarchical Bayesian Models.”</span> <em>arXiv
Preprint</em>, in prep.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Cole Monnahan.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
