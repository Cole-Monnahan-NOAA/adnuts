[{"path":"/articles/adnuts.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"No-U-turn sampling for TMB and ADMB models","text":"adnuts’ (pronounced -D NUTS like -D MB) main purpose provide wrapper performing Bayesian analyses using -U-turn (NUTS) algorithm (Hoffman Gelman 2014) TMB (Kristensen et al. 2016) ADMB (Fournier et al. 2012) models. TMB models NUTS algorithm Stan software (Carpenter et al. 2017) linked StanEstimators R package. adnuts implements sparse NUTS (SNUTS) algorithm (Monnahan et al. prep) decorrelating descaling posterior distribution prior passing Stan. models high correlations sparse precision matrices, SNUTS can substantially improve sampling efficiency. models without strong global correlations, related package tmbstan likely faster due lower overhead may better option. Eventually, Stan may include SNUTS functionality case tmbstan may better long term option. TMB users now, SNUTS via adnuts likely best overall package Bayesian inference. Importantly, works TMB RTMB models, can run TMB models existing packages. ADMB models contain algorithm code internally, package provides user convenient environment run diagnose Markov chains, make inference. Development ADMB models frozen maintain backwards compatibility near future. package aims give ADMB models similar functionality software Stan rstan particular (Carpenter et al. 2017; Stan Development Team 2017).","code":""},{"path":"/articles/adnuts.html","id":"history","dir":"Articles","previous_headings":"","what":"History","title":"No-U-turn sampling for TMB and ADMB models","text":"package undergone several shifts focus. Initially, developed provide NUTS implementation models log-density log-density gradient written R functions (e.g., TMB). However, tmbstan package developed became preferred option TMB users, focus switched ADMB models TMB functionality de-emphasized. Now, development SNUTS, primary focus adnuts TMB sampling via SNUTS approach.","code":""},{"path":[]},{"path":"/articles/NUTS-for-ADMB-models.html","id":"setting-up-the-model","dir":"Articles","previous_headings":"Sampling for ADMB models","what":"Setting up the model","title":"NUTS for ADMB models","text":"general little needed prepare ADMB model use adnuts. model, user must build template file return negative log likelihood value given data parameters. user responsible ensuring valid reasonable model specified. Typical model building practices building complexity slowly validating simulated data strongly encouraged. Users must manually specify priors, otherwise implicit improper uniform distributions unbounded parameters, proper uniform distributions bounded parameters (see details). ADMB model executable file contains code necessary NUTS RWM. run, typically various input files generates many output files. , strongly recommend putting model subdirectory directory containing R script (passed path argument). required parallel execution recommended general.","code":""},{"path":"/articles/NUTS-for-ADMB-models.html","id":"sampling-with-sample_nuts-and-sample_rwm","dir":"Articles","previous_headings":"Sampling for ADMB models","what":"Sampling with sample_nuts and sample_rwm","title":"NUTS for ADMB models","text":"Sampling ADMB models accomplished R functions sample_nuts sample_rwm replace deprecated function sample_admb. functions designed similar Stan’s stan function naming conventions behavior. differences necessary, passing model name path. two MCMC algorithms, NUTS RWM, built ADMB source code just wrapper function. Also note function optimization Variational Inference. default behavior NUTS run 3 chains 2000 iterations, warmup (.e., burn-) phase first 1000. external thinning (sense done automatically within algorithm), thus -mcsave option work NUTS design. defaults work well case diagonal mass matrix adaptation done (e.g., hierarchical models). adaptation often requires long warmup period. models starting good mass matrix (e.g., MLE covariance previous run), much shorter warmup period can used. instance warmup=200 iter=800 multiple chains may work sufficiently well model development. Users RWM algorithm accustomed running millions iterations high thinning rate. !. key thing understand NUTS runs long needs get nearly independent samples. Consult Stan documentation advice workflow NUTS models (e.g., guide) poorly-constructed -parameterized models, NUTS algorithm potentially catastrophically slow. likely common many existing fisheries stock assessment models. cases can informative run RWM algorithm sample_rwm often provides fast feedback user can determine cause poor mixing (see [@monnahan2019]). Consult ADMB documentation information workflow samplers. adnuts provides new options RWM compared command line previous ADMB versions (besides better console output), option parallel execution integration MCMC diagnostic tools provided adnuts sufficiently appealing users. model appropriately parameterized, NUTS used. work optimal parameterizations fisheries model needed. vignette covers functionality package. One important overlap Stan control argument, allows user control NUTS algorithm: Metric mass matrix (adapted diagonal dense matrix) [metric] Maximum treedepth trajectories [max_treedepth’] Target acceptance rate [adapt_delta] Step size, NULL (recommended) adapted [stepsize] Mass matrix adaptation tuning parameters (recommended change) [adapt_init_buffer, adapt_term_buffer, adapt_window] function returns list (class adfit) whose elements mimic returned stan useful plugging rstan tools (see ).","code":""},{"path":"/articles/NUTS-for-ADMB-models.html","id":"mceval-phase-and-posterior-outputs","dir":"Articles","previous_headings":"Sampling for ADMB models","what":"mceval phase and posterior outputs","title":"NUTS for ADMB models","text":"special output files required run model adnuts. addition, user can still use mceval_phase flag run specific code saved samples. ADMB saves posterior draws .psv file. executing model -mceval loop samples execute procedure section flag mceval_phase() evaluating 1. behavior unchanged adnuts, complicated running multiple chains multiple .psv files. Thus, sample_nuts combines chains R writes single .psv file containing samples chains (warmup thinned samples discarded). also works parallel (see ). Consequently, user set mceval=TRUE, run -mceval command line adnuts finishes sampling, order generate desired output files. Previously, ADMB required estimated covariance function use random walk Metropolis (RWM) algorithm. Thus, models without valid mode Hessian inverted use MCMC methods. adnuts neither MLE covariance estimate needed NUTS adapts tuning parameters automatically (see ). However, mode exists recommend estimating model normally running MCMC. sample_nuts sample_rwm strongly recommended running MCMC. However, convenience function runs chains command line. list returned contains element cmd shows user exact command used call ADMB model command line. command line can also useful quick tests.","code":""},{"path":"/articles/NUTS-for-ADMB-models.html","id":"bounds-priors","dir":"Articles","previous_headings":"Sampling for ADMB models","what":"Bounds & Priors","title":"NUTS for ADMB models","text":"Parameter priors must specified manually ADMB template file. instance, standard normal prior parameter B subtracted objective f+=dnorm(B,0.0,1.0). Note contributed statistical functions ADMB, dnorm, return negative log density thus must added objective function. Parameter transformations limited box constraints within ADMB template (e.g., init_bounded_number). used, puts implicit uniform prior parameter bounds. Implicit improper uniform priors occur unbounded parameter explicit prior. analysis can proceed data contain information update prior, chains wander negative positive infinity fail diagnostic checks. Variance parameters common require bounds (0, Inf). implement bound ADMB, specify model parameter log standard deviation, template exponentiate use throughout. parameter transformation, Jacobian adjustment needed. can accomplished subtracting parameter log space negative log-likelihood. instance, use parameter log_sd template, let sigma=exp(log_sd), update objective function Jacobian: f-=log_sd;. recommended half-normal prior standard deviations can added , e.g., f+=dnorm(sigma,0,2). also holds positively constrained parameters many ecology fisheries: somatic growth rates, maximum length, unfished recruits, etc.","code":""},{"path":"/articles/NUTS-for-ADMB-models.html","id":"initializing-chains","dir":"Articles","previous_headings":"Sampling for ADMB models","what":"Initializing chains","title":"NUTS for ADMB models","text":"generally recommended initialize multiple chains “dispersed” values relative typical set posterior. sampling functions can accept list lists (one chain), function returns list parameters (e.g., init <- function() list(=rnorm(1), eta=rnorm(10)). initial values specified init=NULL ADMB attempt read optimized values stored admodel.hes file. Typically MLE (really MPD) values. Starting chains model discouraged makes diagnostic tools like Rhat (see ) inefficient. discussion “…Rhat ratio overestimate underestimate variance, overestimate overestimate starting points diffuse.” Consequently strongly encourage creating function generate reasonable random initial values. model inactive parameters (negative phases) completely ignored MCMC analysis (sampling, inputs, outputs, etc.), initial values active parameters. means read .par file use initial values inactive parameters.","code":""},{"path":"/articles/NUTS-for-ADMB-models.html","id":"parallel-sampling","dir":"Articles","previous_headings":"Sampling for ADMB models","what":"Parallel sampling","title":"NUTS for ADMB models","text":"Parallel sampling done default version 1.1.0. done parallelizing multiple chains, calculations within chain. snowfall package used. n.cores chains run making temporary copies directory path (contain model executable, data inputs, required files). separate R session sampling done results merged together temporary folders deleted. errors occur, temporary folders may need deleted manually. default behavior set n.cores one fewer available system, user can override setting n.cores=1 chains run serial can useful debugging purposes.","code":""},{"path":[]},{"path":"/articles/NUTS-for-ADMB-models.html","id":"diagnosing-mcmc-chains","dir":"Articles","previous_headings":"Diagnostics and plotting results","what":"Diagnosing MCMC chains","title":"NUTS for ADMB models","text":"MCMC diagnostics refers checking signs non-convergence Markov chains using inference, key step Bayesian inference. large literature related refer unfamiliar readers Stan manual chapter convergence. Note user entirely responsible component analysis, adnuts provides tools help . rstan package provides improved function calculating effective sample size R̂\\hat{R} statistics vis function rstan::monitor. function automatically run completed runs stored output. large models (either many parameters many iterations) operation can slow thus user may disable argument skip_monitor, however situation rare quantities always checked. use hierarchical mark-recapture model swallows demonstrate functionality, taken examples [@monnahan2017] read RDS file previous run. diagnostic information can directly accessed via fitted object fit. : Rhat values sufficiently close 1 minimum effective sample size 71 inference longer chains run. model parameters NUTS sampler parameters can extracted data frame. functions options whether include warmup log-posterior (lp) column, also whether return unbounded parameters. latter can useful debugging issues parameters high density near bounds poor mixing issues using RWM chains. object returned sample_nuts sample_rwm' can also plugged directly ShinyStan interactive tool environment calling wrapper functionlaunch_shinyadmb(fit)loading theshinystanlibrary. See ShinyStan documentation information . designed provide NUTS specific diagnostics, also serves general tool MCMC diagnostics thus beneficial RWM chains well. desired, output samples can converted intomcmc` objects use CODA R package. instance, CODA traceplots can accessed like : bayesplot little massaging. Future versions adnuts may link directly. now can done manually energy diagnostic:","code":"fit <- readRDS('fit.RDS') print(fit) #> Model 'swallows' has 177 pars, and was fit using NUTS with a '' metric #> 2 chain(s) of 500 total iterations (250 warmup) were used #> Average run time per chain was 2.57 minutes  #> Minimum ESS=71 (14.2%), and maximum Rhat=1.063 #> !! Warning: Signs of non-convergence found. Do not use for inference !! #> There were 0 divergences after warmup summary(fit$monitor$n_eff) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>    71.0   417.2   548.5   541.4   695.0  1238.0 summary(fit$monitor$Rhat) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.9965  1.0001  1.0029  1.0045  1.0063  1.0626 post <- extract_samples(fit) str(post[,1:5]) #> 'data.frame':    500 obs. of  5 variables: #>  $ sigmayearphi: num  0.646 0.454 0.392 0.771 0.917 ... #>  $ sigmaphi    : num  -0.688 -0.996 -0.398 -1.275 -0.94 ... #>  $ sigmap      : num  -0.1945 -0.3027 0.0436 -0.1589 -0.3653 ... #>  $ a[1]        : num  1.398 1.543 1.567 0.561 1.302 ... #>  $ a[2]        : num  1.369 1.551 1.248 0.955 0.395 ... sp <- extract_sampler_params(fit) str(sp) #> 'data.frame':    500 obs. of  8 variables: #>  $ chain        : num  1 1 1 1 1 1 1 1 1 1 ... #>  $ iteration    : num  251 252 253 254 255 256 257 258 259 260 ... #>  $ accept_stat__: num  0.0658 0.9882 0.827 0.8954 0.9686 ... #>  $ stepsize__   : num  0.0802 0.0802 0.0802 0.0802 0.0802 ... #>  $ treedepth__  : num  5 6 6 6 6 6 6 6 6 6 ... #>  $ n_leapfrog__ : num  31 63 63 63 63 63 63 63 63 63 ... #>  $ divergent__  : num  0 0 0 0 0 0 0 0 0 0 ... #>  $ energy__     : num  -1863 -1848 -1856 -1861 -1875 ... post <- extract_samples(fit, as.list=TRUE) postlist <- coda::mcmc.list(lapply(post, coda::mcmc)) coda::traceplot(postlist) library(bayesplot) library(dplyr) library(tidyr) library(ggplot2) color_scheme_set(\"red\") np <- extract_sampler_params(fit) %>%   pivot_longer(-c(chain, iteration), names_to='Parameter', values_to='Value') %>%   select(Iteration=iteration, Parameter, Value, Chain=chain) %>%   mutate(Parameter=factor(Parameter),          Iteration=as.integer(Iteration),          Chain=as.integer(Chain)) %>% as.data.frame() mcmc_nuts_energy(np) + ggtitle(\"NUTS Energy Diagnostic\") + theme_minimal()"},{"path":"/articles/NUTS-for-ADMB-models.html","id":"plotting-output","dir":"Articles","previous_headings":"","what":"Plotting output","title":"NUTS for ADMB models","text":"convenience function plot_marginals provided quickly plot marginal posterior distributions options overlay asymptotic estimates.  Many ADMB models well defined modes estimated covariance matrices used quantify uncertainty. pairs_admb function can used plot pairwise posterior draws vs MLE estimate confidence ellipses. Major discrepancies two cause concern. , can good diagnostic tool frequentist Bayesian inference. particular, often informative plot slowest mixing parameters key ones name follows.   last plot shows three hypervariances hierarchical model. diagonal shows traces two chains (colors), alternative options argument diag ‘trace’ (default), ‘hist’ histogram, ‘acf’ autocorrelation function. remaining plots show pairwise posterior samples (black points) remaining parameters. Divergences shown green points exist (none ). red point shows posterior mode ellipse shows 95% bivariate confidence region, taken inverse Hessian calculated ADMB. Since log-posterior (lp__) parameter ellipse. Note posterior samples asymptotic approximations two fixed effects match closely, whereas sigmaphi hypervariance parameter notable mismatch. mismatch surprising estimates optimizing hierarchical models reliable. Since adaptive NUTS used sampling, information contained red used shown illustration. option metric='mle' use inverse Hessian tuning parameter (see section metric ). options plotting fits like available help file ?pairs_admb.","code":"plot_marginals(fit, pars=1:9) pairs_admb(fit, pars=1:3, order='slow') #> Warning in pairs_admb(fit, pars = 1:3, order = \"slow\"): 'pairs_admb' is deprecated. #> Use 'pairs' instead. #> See help(\"Deprecated\") and help(\"adnuts-deprecated\"). pairs_admb(fit, pars=c('sigmaphi', 'sigmap', 'sigmayearphi')) #> Warning in pairs_admb(fit, pars = c(\"sigmaphi\", \"sigmap\", \"sigmayearphi\")): 'pairs_admb' is deprecated. #> Use 'pairs' instead. #> See help(\"Deprecated\") and help(\"adnuts-deprecated\")."},{"path":"/articles/NUTS-for-ADMB-models.html","id":"mass-matrix-adaptation","dir":"Articles","previous_headings":"","what":"Mass matrix adaptation","title":"NUTS for ADMB models","text":"assume reader familiar basics mass matrix effect sampling NUTS (, see section ). Note mass matrix represents geometry posterior untransformed (unbounded) space, parameter space defined user. space typically hidden user nonetheless important recognize thinking mass matrix. ADMB capability diagonal dense (full matrix, version 12.2) estimation warmup (adaptation). initial matrix can likewise easily initialized two ways. First unit diagonal, second “MLE” option, accurately covariance matrix calculated inverting Hessian maximum posterior density (mode – informally referred MLE often). refer Σ\\Sigma. 6 options mass matrix, summarized subsequent table. Note options 3 6 available adnuts version 1.1.0 available ADMB >= 12.2. Also differences default behavior running sample_nuts vs. command line. Note dense estimation considered experimental feature. option Stan rarely used. Stan users almost always use option 2 (default adnuts). models fit advice evolve. now best guess: dd refers dimensionality (# parameters) guidance rough guess. reason dimensionality matters numerical cost using dense matrix diagonal one, one scales poorly dimensionality. However, computationally expensive model (prediction log density calculations) smaller relative cost dense calculations. Thus interplay mass matrix form, dimensionality, model computational cost, MCMC sampling efficiency. addition options, arbitrary matrix M can passed via metric=M. works using R overwrite admodel.cov file ADMB runs reads thinking estimated matrix. file admodel_original.cov copied case user wants revert . Probably realistic usage feature already run pilot chain want rerun longer, wish use samples generate estimated mass matrix. case use M=fit$covar.est estimate unbounded space (see ). Note M=diag(d) equivalent first three rows M=Σ\\Sigma equivalent last three rows. following figure shows step size single chain warmup six options simple linear model, demonstrates general differences among . three start unit diagonal matrix apparent small initial step sizes, three start dense larger. clear shift stepsize iteration 125 first mass matrix update happens (improved knowledge geometry optimal step size changes). second update happens later apparent, indicating first sufficient. fits dense matrix end approximate step size, larger without . Option 3 starts diagonal updating dense matrix performs equivalently. diagonal options, option 1 update, option two starts unit diagonal aftering updating diagonal performs equally well option 5 starts well. behavior trivial model, often hard estimate good dense mass matrix, especially first phases warmup samples. cases Cholesky decomposition estimated matrix may fail. Instead crashing run coded ADMB instead diagonal estimate case, try dense update next phase, repeating warmup . Warnings printed console happens. option use situation still open question. Certainly hierarchical models Σ\\Sigma helpful doesn’t exist, option 2 likely best. fisheries stock assessment models already rely Σ\\Sigma options 4-6 worth exploring.","code":""},{"path":[]},{"path":"/articles/NUTS-for-ADMB-models.html","id":"brief-review-of-hamiltonian-monte-carlo","dir":"Articles","previous_headings":"The no-U-turn sampler implementation","what":"Brief review of Hamiltonian Monte Carlo","title":"NUTS for ADMB models","text":"Hamiltonian Monte Carlo powerful family MCMC algorithms use gradients propose efficient transitions. review basics refer interested readers [@neal2011; @betancourt2017intro; @monnahan2017]. Instead randomly generating proposed point, rejected/accepted, HMC generates trajectories point chosen rejected/accepted. trajectories use gradient information analogy ball rolling surface often used. trajectories efficient can transition nearly anywhere posterior (stark contrast random walk algorithms). However, need well-tuned. Generally three aspects algorithms need tuned. step size. big steps points single trajectory. Bigger steps means fewer calculations (thus faster), negative cost rejecting points. trajectory length. long trajectory depends many factors, constant posterior. short, HMC resembles inefficient random walk behavior. long, computations wasted. “mass matrix” used. matrix tells algorithm global shape posterior can generate better trajectories. large discrepancies marginal variances exist, trajectories less efficient (e.g., one parameter marginal variance 1, another marginal variance 1000). -U-turn sampler powerful sampler automated tuning first two aspects [@hoffman2014]. warmup tunes step size target acceptance rate (default 0.8) shown optimal [@betancourt2014]. importantly, though, uses recursive tree building algorithm continue doubling trajectory “U-turn” occurs, meaning going wasteful computationally. Thus, trajectory lengths automatically optimal. original algorithm implemented Bayesian statistical software Stan [@carpenter2017; @stan2017]. addition automation NUTS, Stan provides scheme adapting step size warmup phase. Estimated diagonal mass matrices correct global differences scale, correlations. dense matrix can also adapted, corrects global correlations, comes higher computation cost. Typically diagonal matrix best thus default Stan adnuts. three extensions lead efficient HMC sampling little user intervention wide class statistical models, including hierarchical ones [@monnahan2017]. Since publication, developments made HMC theoretical practical research. instance, Stan now includes update called “exhaustive” HMC [@betancourt2016] efficiently samples points trajectory.","code":""},{"path":"/articles/NUTS-for-ADMB-models.html","id":"algorithm-implementation-details","dir":"Articles","previous_headings":"The no-U-turn sampler implementation","what":"Algorithm implementation details","title":"NUTS for ADMB models","text":"ADMB adnuts uses original algorithm presented [@hoffman2014]. However also uses similar mass matrix adaptation scheme used Stan. algorithm initiated unit diagonal mass matrix. first 50 iterations step size adapted. next 75 iterations estimated variance parameter (untransformed space) calculated used new mass matrix. next update occurs twice iterations previous update. process repeats last 25 samples warmup phase. phase mass matrix held constant step size adapt. See Stan manual [@stan2017] details. step size adapted warmup iterations. information returned mass matrix adaptation currently. warmup phase , adaptation done. adaptation warmup samples valid samples posterior must discarded used inference.","code":""},{"path":"/articles/NUTS-for-ADMB-models.html","id":"user-intervention","dir":"Articles","previous_headings":"The no-U-turn sampler implementation","what":"User intervention","title":"NUTS for ADMB models","text":"cases need adjust behavior NUTS algorithm improve sampling. review three options intervention (step size, trajectory lengths, mass matrix) user can take, might need . maximum tree depth argument used prevent excessively long trajectories (can occur poorly specified models). set 12 (.e., length 212=40962^12=4096 steps) default, typically long enough U-turn occur. However, cases model may need make longer trajectories maintain efficient sampling. case get warnings exceeding maximum tree depth. Rerun model control=list(max_treedepth=14) higher, needed. Recall single NUTS trajectory consists set posterior samples, resulting numerical approximation path along posterior. step size controls close approximation along true path. step size large encounters extreme curvature posterior divergence occur. Divergences ignored lead bias inference. Instead, force model take smaller step sizes increasing target acceptance rate. Thus, get warnings divergences, rerun model control=list(adapt_delta=.9) higher, necessary. divergences go away, investigate cause try eliminate extreme curvature model, example reparameterization [@stan2017; @monnahan2017]. extreme global correlations model, NUTS inefficient using diagonal mass matrix (default). case, can pass dense matrix, estimated externally previous runs (previous fits contain element covar.est can passed next call). control=list(metric=M) M matrix untransformed space approximates posterior. ADMB models, can try using MLE covariance setting control=list(metric=\"mle\"). Note , technical reasons, need reoptimize model command line argument-hbf`. (ADMB uses different transformation functions HMC covariance mismatched otherwise). Note using dense mass matrix additional computational overhead, particularly higher dimensions. , dense matrix leads shorter trajectories, take longer calculate. Whether dense metric worth increase sampling efficiency depend model. following figure demonstrates effect mass matrix 2d normal model box constraints. columns denote different model “spaces” rows different mass matrices. Random, arbitrary NUTS trajectories show red top posterior draws (points). right column model space, middle untransformed, far left untransformed rotated mass matrix. Note differences scales axes among plots. key rightmost column. top panel mass matrix (.e., unit diagonal), trajectories ungulate back forth move across posterior. Thus go one end straight. diagonal matrix used, trajectories become noticeably straighter. Finally, dense matrix trajectories even better. effect mass matrix: trajectories can move regions posterior easily.","code":""},{"path":"/articles/NUTS-for-ADMB-models.html","id":"algorithm-validity","dir":"Articles","previous_headings":"","what":"Algorithm validity","title":"NUTS for ADMB models","text":"Software bugs MCMC algorithms can manifest biased sampling target distribution. serious issue one can hard detect. One way check run algorithms known distributions check estimated properties analytical. checked normal, t df=4 df=10, gamma, inverse gamma, truncated normal, multivariate normal. ran long chains (1 million samples) thinning rate 10 NUTS, compared equivalent set points RWM IID samples Monte Carlo samples (e.g., rnorm). Long chains thining ensured residual autocorrelation. repeated 20 chains RWM, NUTS MLE metric, adaptive NUTS, Monte Carlo (mc). Results plotted relative error different probabilities (via pnorm etc.). cases mean 0, MC indistinguishable MCMC. provides strong evidence algorithms coded correctly. mean finite samples target distributions unbiased.","code":""},{"path":[]},{"path":"/articles/SNUTS-for-TMB-models.html","id":"differences-between-tmb-and-rtmb","dir":"Articles","previous_headings":"","what":"Differences between TMB and RTMB","title":"Sparse NUTS for TMB models","text":"adnuts implements sparse -u-turn sampler (SNUTS) introduced detailed [@monnahan2025]. works TMB models Stan currently way pass use sparse metric. TMB RTMB can used parallel. sample_snuts function detect used internally adjust accordingly. RTMB model uses external functions data sets must passed via list globals argument available rebuild ‘obj’ parallel R sessions. Optionally, model_name can specified call, otherwise model labeled “RTMB” output. TMB models require globals input model name pulled DLL name, can overridden desired.","code":""},{"path":"/articles/SNUTS-for-TMB-models.html","id":"snuts-for-tmb-models-from-existing-packages-sdmtmb-glmmtmb-etc-","dir":"Articles","previous_headings":"","what":"SNUTS for TMB models from existing packages (sdmTMB, glmmTMB, etc.)","title":"Sparse NUTS for TMB models","text":"adnuts works custom TMB RTMB models developed locally, also come packages. packages return TMB ‘obj’ can passed sample_snuts. instance glmmTMB package can run like :","code":"library(glmmTMB) data(Salamanders) obj <- glmmTMB(count~spp * mined + (1|site), Salamanders, family=\"nbinom2\")$obj"},{"path":"/articles/SNUTS-for-TMB-models.html","id":"basic-usage","dir":"Articles","previous_headings":"","what":"Basic usage","title":"Sparse NUTS for TMB models","text":"recommended usage TMB users let sample_snuts function automatically detect metric use length warmup, especially pilot runs model development. demonstrate basic usage using simple RTMB version eight schools model examined extensively Bayesian literature. first step build TMB object ‘obj’ incorporates priors Jacobians parameter transformations. Note R function returns negative un-normalized log-posterior density.","code":"library(RTMB) dat <- list(y=c(28,  8, -3,  7, -1,  1, 18, 12),             sigma=c(15, 10, 16, 11,  9, 11, 10, 18)) pars <- list(mu=0, logtau=0, eta=rep(1,8)) f <- function(pars){   getAll(dat, pars)   theta <- mu + exp(logtau) * eta;   lp <- sum(dnorm(eta, 0,1, log=TRUE))+ # prior     sum(dnorm(y,theta,sigma,log=TRUE))+ #likelihood     logtau                          # jacobian   REPORT(theta)   return(-lp) } obj <- MakeADFun(func=f, parameters=pars,                  random=\"eta\", silent=TRUE)"},{"path":"/articles/SNUTS-for-TMB-models.html","id":"posterior-sampling-with-snuts","dir":"Articles","previous_headings":"Basic usage","what":"Posterior sampling with SNUTS","title":"Sparse NUTS for TMB models","text":"common task draw samples posterior density defined model. done sample_snuts function follows: returned object fit (object ‘adfit’ S3 class) contains posterior samples relevant information Bayesian analysis. Notice optimization done calling sample_snuts. model already optimized, can skip setting skip_optimization=TRUE, even pass QQ Σ=Q−1\\Sigma=Q^{-1} via arguments Q Qinv bypass step save run time. returned fitted object contains slot called mle conditional mode (‘est’), marginal standard errors ‘se’, joint correlation matrix (‘cor’).","code":"fit <- sample_snuts(obj, refresh=0, seed=1,                     model_name = 'schools',                     cores=1, chains=1,                     globals=list(dat=dat)) #> Optimizing... #> Getting Q... #> Inverting Q... #> Q is 62.22% zeroes, with condition factor=56 (min=0.044, max=2.5) #> Rebuilding RTMB obj without random effects... #> diag metric selected b/c of low correlations #> log-posterior at inits=-34.661; at conditional mode=-34.661 #> Starting MCMC sampling... #>  #>  #> Gradient evaluation took 0.000113 seconds #> 1000 transitions using 10 leapfrog steps per transition would take 1.13 seconds. #> Adjust your expectations accordingly! #>  #>  #>  #>  Elapsed Time: 0.062 seconds (Warm-up) #>                0.377 seconds (Sampling) #>                0.439 seconds (Total) #> 5 of 1150 (0.43%) iterations ended with a divergence. #> These divergent transitions indicate that HMC is not fully able to explore the posterior distribution. #> Try increasing adapt_delta closer to 1. #> If this doesn't remove all divergences, try to reparameterize the model. #> Loading required package: microbenchmark #>  #>  #> Model 'schools' has 10 pars, and was fit using NUTS with a 'diag' metric #> 1 chain(s) of 1150 total iterations (150 warmup) were used #> Average run time per chain was 0.44 seconds  #> Minimum ESS=296.92 (29.69%), and maximum Rhat=1.002 #> There were 0 divergences after warmup str(fit$mle) #> List of 5 #>  $ nopar: int 10 #>  $ est  : Named num [1:10] 7.92441 1.8414 0.47811 0.00341 -0.2329 ... #>   ..- attr(*, \"names\")= chr [1:10] \"mu\" \"logtau\" \"eta[1]\" \"eta[2]\" ... #>  $ se   : Named num [1:10] 4.725 0.732 0.959 0.872 0.945 ... #>   ..- attr(*, \"names\")= chr [1:10] \"mu\" \"logtau\" \"eta[1]\" \"eta[2]\" ... #>  $ cor  : num [1:10, 1:10] 1 0.0558 -0.1031 -0.2443 -0.114 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:10] \"mu\" \"logtau\" \"eta[1]\" \"eta[2]\" ... #>   .. ..$ : chr [1:10] \"mu\" \"logtau\" \"eta[1]\" \"eta[2]\" ... #>  $ Q    :Formal class 'dsCMatrix' [package \"Matrix\"] with 7 slots #>   .. ..@ i       : int [1:27] 0 1 2 3 4 5 6 7 8 9 ... #>   .. ..@ p       : int [1:11] 0 10 19 20 21 22 23 24 25 26 ... #>   .. ..@ Dim     : int [1:2] 10 10 #>   .. ..@ Dimnames:List of 2 #>   .. .. ..$ : chr [1:10] \"mu\" \"logtau\" \"eta[1]\" \"eta[2]\" ... #>   .. .. ..$ : chr [1:10] \"mu\" \"logtau\" \"eta[1]\" \"eta[2]\" ... #>   .. ..@ x       : num [1:27] 0.0603 -0.0144 0.028 0.0631 0.0246 ... #>   .. ..@ uplo    : chr \"L\" #>   .. ..@ factors :List of 1 #>   .. .. ..$ SPdCholesky:Formal class 'dCHMsuper' [package \"Matrix\"] with 10 slots #>   .. .. .. .. ..@ x       : num [1:100] 1.06 0 0 0 0 ... #>   .. .. .. .. ..@ super   : int [1:2] 0 10 #>   .. .. .. .. ..@ pi      : int [1:2] 0 10 #>   .. .. .. .. ..@ px      : int [1:2] 0 100 #>   .. .. .. .. ..@ s       : int [1:10] 0 1 2 3 4 5 6 7 8 9 #>   .. .. .. .. ..@ type    : int [1:6] 2 1 1 1 1 1 #>   .. .. .. .. ..@ colcount: int [1:10] 3 3 3 3 3 3 4 3 2 1 #>   .. .. .. .. ..@ perm    : int [1:10] 9 8 7 6 5 4 0 2 3 1 #>   .. .. .. .. ..@ Dim     : int [1:2] 10 10 #>   .. .. .. .. ..@ Dimnames:List of 2 #>   .. .. .. .. .. ..$ : chr [1:10] \"mu\" \"logtau\" \"eta[1]\" \"eta[2]\" ... #>   .. .. .. .. .. ..$ : chr [1:10] \"mu\" \"logtau\" \"eta[1]\" \"eta[2]\" ..."},{"path":"/articles/SNUTS-for-TMB-models.html","id":"diagnostics","dir":"Articles","previous_headings":"Basic usage","what":"Diagnostics","title":"Sparse NUTS for TMB models","text":"common MCMC diagnostics potential scale reduction (Rhat) minimum ESS, well NUTS divergences (see diagnostics section rstan manual), printed console default can accessed depth via monitor slot: specialized pairs plotting function available (formally called pairs_admb) examine pair-wise behavior posteriors. can useful help diagnose particularly slow mixing parameters. function also displays conditional mode (point) 95% bivariate confidence region (ellipses) calculated approximate covariance matrix Σ=Q−1\\Sigma=Q^{-1}. parameters show can specified either vie character vector like pars=c('mu', 'logtau', 'eta[1]') integer vector like pars=1:3, using latter parameters can ordered slowest mixing (‘slow’), fastest mixing (‘fast’) largest discrepancies approximate marginal variance QQ posterior samples (‘mismatch’). NUTS divergences shown green points. See help information ?pairs.adfit.  cases useful diagnose NUTS behavior examining “sampler parameters”, contain information individual NUTS trajectories.  ShinyStan tool also available provides convenient, interactive way check diagnostics via function launch_shinytmb(obj), also explore estimates important quantities. key tool workflow ‘adnuts’.","code":"print(fit) #> Model 'schools' has 10 pars, and was fit using NUTS with a 'diag' metric #> 1 chain(s) of 1150 total iterations (150 warmup) were used #> Average run time per chain was 0.44 seconds  #> Minimum ESS=296.92 (29.69%), and maximum Rhat=1.002 #> There were 0 divergences after warmup  fit$monitor |> str() #> drws_smm [11 × 12] (S3: draws_summary/tbl_df/tbl/data.frame) #>  $ variable: chr [1:11] \"mu\" \"logtau\" \"eta[1]\" \"eta[2]\" ... #>  $ mean    : num [1:11] 1.715 1.992 0.425 -0.019 -0.218 ... #>  $ median  : num [1:11] 1.6549 2.2596 0.4623 -0.0369 -0.2074 ... #>  $ sd      : num [1:11] 1.008 1.496 1.031 1.015 0.973 ... #>  $ mad     : num [1:11] 0.95 1.215 1.001 0.956 0.946 ... #>  $ q5      : num [1:11] 0.096 -0.729 -1.349 -1.74 -1.809 ... #>  $ q95     : num [1:11] 3.43 3.82 2.06 1.64 1.46 ... #>  $ rhat    : num [1:11] 1.001 0.999 1 1 1.002 ... #>  $ ess_bulk: num [1:11] 833 324 1535 1498 1545 ... #>  $ ess_tail: num [1:11] 498 288 893 717 828 ... #>  $ n_eff   : num [1:11] 833 324 1535 1498 1545 ... #>  $ Rhat    : num [1:11] 1.001 0.999 1 1 1.002 ... #>  - attr(*, \"num_args\")= list() pairs(fit, order='slow') extract_sampler_params(fit) |> str() #> 'data.frame':    1000 obs. of  8 variables: #>  $ chain        : num  1 1 1 1 1 1 1 1 1 1 ... #>  $ iteration    : num  151 152 153 154 155 156 157 158 159 160 ... #>  $ accept_stat__: num  0.988 0.973 0.99 0.929 0.842 ... #>  $ stepsize__   : num  0.536 0.536 0.536 0.536 0.536 ... #>  $ treedepth__  : num  3 3 3 3 3 3 3 3 3 3 ... #>  $ n_leapfrog__ : num  7 7 7 7 7 7 7 7 7 7 ... #>  $ divergent__  : num  0 0 0 0 0 0 0 0 0 0 ... #>  $ energy__     : num  46.1 45.2 42.3 39.8 39.7 ... ## or plot them directly plot_sampler_params(fit)"},{"path":"/articles/SNUTS-for-TMB-models.html","id":"bayesian-inference","dir":"Articles","previous_headings":"Basic usage","what":"Bayesian inference","title":"Sparse NUTS for TMB models","text":"checking signs non-convergence results can used inference. Posterior samples parameters can extracted examined R casting fitted object R data.frame. posterior samples can put back TMB object report() function extract desired “generated quantity” Stan terminology. Likewise, marginal distributions can explored visually compared approximate estimate conditional mode Σ\\Sigma (red lines):","code":"post <- as.data.frame(fit) post |> str() #> 'data.frame':    1000 obs. of  10 variables: #>  $ mu    : num  6 9.67 3.93 12.17 7.92 ... #>  $ logtau: num  0.0852 0.7415 2.0695 2.6354 2.4339 ... #>  $ eta[1]: num  0.944 -0.79 0.202 1.447 -0.473 ... #>  $ eta[2]: num  0.659 -1.061 1.001 -1.135 0.503 ... #>  $ eta[3]: num  -1.162 1.08 -0.917 0.305 -1.236 ... #>  $ eta[4]: num  -0.5655 0.7594 -0.3337 0.0423 -0.6287 ... #>  $ eta[5]: num  0.914 -0.855 0.315 -1.349 -0.233 ... #>  $ eta[6]: num  0.899 -1.269 -0.68 -0.231 -0.832 ... #>  $ eta[7]: num  1.5982 -0.9183 0.7886 0.0198 0.6867 ... #>  $ eta[8]: num  -0.202 0.262 -0.209 0.771 -0.996 ... ## now get a generated quantity, here theta which is a vector of ## length 8 so becomes a matrix of posterior samples theta <- apply(post,1, \\(x) obj$report(x)$theta) |> t() theta |> str() #>  num [1:1000, 1:8] 7.03 8.01 5.53 32.35 2.53 ... plot_marginals(fit)"},{"path":"/articles/SNUTS-for-TMB-models.html","id":"a-more-complicated-example","dir":"Articles","previous_headings":"","what":"A more complicated example","title":"Sparse NUTS for TMB models","text":"demonstrate basic usage use complicated model. modified ChickWeight random slopes intercepts example RTMB introduction. Modifications include: switching SD parameters log space adding Jacobian, adding broad priors SDs, adding ‘loglik’ vector PSIS-LOO ().","code":"parameters <- list(   mua=0,          ## Mean slope   logsda=0,          ## Std of slopes   mub=0,          ## Mean intercept   logsdb=0,          ## Std of intercepts   logsdeps=1,        ## Residual Std   a=rep(0, 50),   ## Random slope by chick   b=rep(0, 50)    ## Random intercept by chick )  f <- function(parms) {   require(RTMB) # for tmbstan   getAll(ChickWeight, parms, warn=FALSE)   sda <- exp(logsda)   sdb <- exp(logsdb)   sdeps <- exp(logsdeps)   ## Optional (enables extra RTMB features)   weight <- OBS(weight)   predWeight <- a[Chick] * Time + b[Chick]   loglik <- dnorm(weight, predWeight, sd=sdeps, log=TRUE)      # calculate the target density   lp <-   sum(loglik)+ # likelihood     # random effect vectors     sum(dnorm(a, mean=mua, sd=sda, log=TRUE)) +      sum(dnorm(b, mean=mub, sd=sdb, log=TRUE)) +     # broad half-normal priors on SD pars     dnorm(sda, 0, 10, log=TRUE) +      dnorm(sdb, 0, 10, log=TRUE) +      dnorm(sdeps, 0, 10, log=TRUE) +      # jacobian adjustments     logsda + logsdb + logsdeps      # reporting   REPORT(loglik)       # for PSIS-LOO   ADREPORT(predWeight) # delta method   REPORT(predWeight)   # standard report      return(-lp) # negative log-posterior density }  obj <- MakeADFun(f, parameters, random=c(\"a\", \"b\"), silent=TRUE)"},{"path":"/articles/SNUTS-for-TMB-models.html","id":"asymptotic-frequentist-approximatation-vs-full-posterior","dir":"Articles","previous_headings":"","what":"Asymptotic (frequentist) approximatation vs full posterior","title":"Sparse NUTS for TMB models","text":"Instead sampling posterior MCMC (SNUTS), can use asymptotic tools TMB get quick approximation parameters, covariances, also uncertainties generated quantities via generalized delta method. See TMB documentation background. Briefly, marginal posterior mode found joint precision matrix QQ determined conditional mode. Σ=Q−1\\Sigma=Q{-1} covariance parameters. First optimize model call TMB’s sdreport function get approximate uncertainties via delta method joint precision matrix QQ.  Now run SNUTS get posterior samples compare .","code":"# optimize opt <- with(obj, nlminb(par, fn, gr)) # get generalized delta method results and Q sdrep <- sdreport(obj, getJointPrecision=TRUE)  # get the generalized delta method estimates of asymptotic # standard errors est <-as.list(sdrep, 'Estimate', report=TRUE)$predWeight se <- as.list(sdrep, 'Std. Error', report=TRUE)$predWeight  Q <- sdrep$jointPrecision # can get the joint covariance and correlation like this Sigma <- as.matrix(solve(Q)) cor <- cov2cor(Sigma) plot_Q(Q=Q) # some very strong negative correlations so I expect a dense or # sparse metric to be selected with SNUTS. Because I optimized # above can skip that mcmc <- sample_snuts(obj, chains=1, init='random', seed=1234,                      refresh=0, skip_optimization=TRUE,                      Q=Q, Qinv=Sigma) #> Q is 91.85% zeroes, with condition factor=74028 (min=0.014, max=1018.9) #> Rebuilding RTMB obj without random effects... #> dense metric selected b/c faster than sparse and high correlation (0.81) #> log-posterior at inits=-2627.037; at conditional mode=-2574.481 #> Starting MCMC sampling... #>  #>  #> Gradient evaluation took 0.000121 seconds #> 1000 transitions using 10 leapfrog steps per transition would take 1.21 seconds. #> Adjust your expectations accordingly! #>  #>  #>  #>  Elapsed Time: 0.225 seconds (Warm-up) #>                1.122 seconds (Sampling) #>                1.347 seconds (Total) #> 1 of 1150 (0.09%) iterations ended with a divergence. #> These divergent transitions indicate that HMC is not fully able to explore the posterior distribution. #> Try increasing adapt_delta closer to 1. #> If this doesn't remove all divergences, try to reparameterize the model. #>  #>  #> Model 'RTMB' has 105 pars, and was fit using NUTS with a 'dense' metric #> 1 chain(s) of 1150 total iterations (150 warmup) were used #> Average run time per chain was 1.35 seconds  #> Minimum ESS=324.07 (32.41%), and maximum Rhat=1.023 #> There were 0 divergences after warmup post <- as.data.frame(mcmc)  plot_uncertainties(mcmc) ## get posterior of generated quantities predWeight <- apply(post,1, \\(x) obj$report(x)$predWeight) |>    t() predWeight |> str() #>  num [1:1000, 1:578] 28.1 29.3 23.5 24.8 26.7 ...  # compare asymptotic vs posterior intervals of first few chicks par(mfrow=c(2,3)) for(ii in 1:6){   y <- predWeight[,ii]   x <- seq(min(y), max(y), len=200)   y2 <- dnorm(x,est[ii], se[ii])   hist(y, freq=FALSE, ylim=c(0,max(y2)))   lines(x, y2, col=2, lwd=2) } dev.off() #> null device  #>           1"},{"path":"/articles/SNUTS-for-TMB-models.html","id":"simulation-of-parameters-and-data","dir":"Articles","previous_headings":"","what":"Simulation of parameters and data","title":"Sparse NUTS for TMB models","text":"Simulation data can done directly R. Specialized simulation functionality exists TMB, lesser degree RTMB, keep simple demonstration purposes. data parameters can simulated explore .","code":""},{"path":"/articles/SNUTS-for-TMB-models.html","id":"prior-and-posterior-predictive-distributions","dir":"Articles","previous_headings":"Simulation of parameters and data","what":"Prior and posterior predictive distributions","title":"Sparse NUTS for TMB models","text":"Prior predictive sampling done way shown .","code":"# simulation of data sets can be done manually in R. For instance # to get posterior predictive I loop through each posterior # sample and draw new data. set.seed(351231) simdat <- apply(post,1, \\(x){    yhat <- obj$report(x)$predWeight    ysim <- rnorm(n=length(yhat), yhat, sd=exp(x['logsdeps'])) }) |> t() boxplot(simdat[,1:24], main='Posterior predictive') points(ChickWeight$weight[1:24], col=2, cex=2, pch=16)"},{"path":"/articles/SNUTS-for-TMB-models.html","id":"joint-precision-sampling","dir":"Articles","previous_headings":"Simulation of parameters and data","what":"Joint precision sampling","title":"Sparse NUTS for TMB models","text":"Samples can drawn QQ, assuming multivariate normality, follows: samples put back report function get distribution generated quantity, instance.","code":"# likewise I can simulate draws from Q to get approximate samples postQ <- mvtnorm::rmvnorm(1000, mean=mcmc$mle$est, sigma=Sigma)"},{"path":"/articles/SNUTS-for-TMB-models.html","id":"model-selection-with-psis-loo","dir":"Articles","previous_headings":"","what":"Model selection with PSIS-LOO","title":"Sparse NUTS for TMB models","text":"PSIS-LOO recommended way compare predictive performance Bayesian models. use compare simplified Chicks model using map argument turn estimation random intercepts (‘b’). requires vector log-likelihood values available posterior draw. facilitate via REPORT(loglik) call .","code":"library(loo) #> This is loo version 2.8.0 #> - Online documentation and vignettes at mc-stan.org/loo #> - As of v2.0.0 loo defaults to 1 core but we recommend using as many as possible. Use the 'cores' argument or set options(mc.cores = NUM_CORES) for an entire session. #> - Windows 10 users: loo may be very slow if 'mc.cores' is set in your .Rprofile file (see https://github.com/stan-dev/loo/issues/94). options(mc.cores=parallel::detectCores()) loglik <- apply(post,1, \\(x) obj$report(x)$loglik) |>    t()  loo1 <- loo(loglik, cores=4) #> Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details. print(loo1) #>  #> Computed from 1000 by 578 log-likelihood matrix. #>  #>          Estimate   SE #> elpd_loo  -2351.8 19.9 #> p_loo        88.5  6.9 #> looic      4703.6 39.7 #> ------ #> MCSE of elpd_loo is NA. #> MCSE and ESS estimates assume independent draws (r_eff=1). #>  #> Pareto k diagnostic values: #>                           Count Pct.    Min. ESS #> (-Inf, 0.67]   (good)     572   99.0%   103      #>    (0.67, 1]   (bad)        6    1.0%   <NA>     #>     (1, Inf)   (very bad)   0    0.0%   <NA>     #> See help('pareto-k-diagnostic') for details. plot(loo1) # I can compare that to a simpler model which doesn't have # random effects on the slope obj2 <- MakeADFun(f, parameters, random=c(\"a\"), silent=TRUE,                   map=list(b=factor(rep(NA, length(parameters$b))),                             logsdb=factor(NA),                            mub=factor(NA))) mcmc2 <- sample_snuts(obj2, chains=1, seed=1215, refresh=0) #> Optimizing... #> Getting Q... #> Inverting Q... #> Q is 88.9% zeroes, with condition factor=8423 (min=0.128, max=1080.5) #> Rebuilding RTMB obj without random effects... #> diag metric selected b/c of low correlations #> log-posterior at inits=-2745.519; at conditional mode=-2745.519 #> Starting MCMC sampling... #>  #>  #> Gradient evaluation took 7.9e-05 seconds #> 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds. #> Adjust your expectations accordingly! #>  #>  #>  #>  Elapsed Time: 0.118 seconds (Warm-up) #>                0.694 seconds (Sampling) #>                0.812 seconds (Total) #> 1 of 1150 (0.09%) iterations ended with a divergence. #> These divergent transitions indicate that HMC is not fully able to explore the posterior distribution. #> Try increasing adapt_delta closer to 1. #> If this doesn't remove all divergences, try to reparameterize the model. #>  #>  #> Model 'RTMB' has 53 pars, and was fit using NUTS with a 'diag' metric #> 1 chain(s) of 1150 total iterations (150 warmup) were used #> Average run time per chain was 0.81 seconds  #> Minimum ESS=402.16 (40.22%), and maximum Rhat=1.007 #> There were 0 divergences after warmup post2 <- as.data.frame(mcmc2) loglik2 <- apply(post2,1, \\(x) obj2$report(x)$loglik) |>    t() loo2 <- loo(loglik2, cores=4) #> Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details. print(loo2) #>  #> Computed from 1000 by 578 log-likelihood matrix. #>  #>          Estimate   SE #> elpd_loo  -2613.1 14.4 #> p_loo        31.8  3.0 #> looic      5226.2 28.9 #> ------ #> MCSE of elpd_loo is NA. #> MCSE and ESS estimates assume independent draws (r_eff=1). #>  #> Pareto k diagnostic values: #>                           Count Pct.    Min. ESS #> (-Inf, 0.67]   (good)     577   99.8%   195      #>    (0.67, 1]   (bad)        1    0.2%   <NA>     #>     (1, Inf)   (very bad)   0    0.0%   <NA>     #> See help('pareto-k-diagnostic') for details. loo_compare(loo1, loo2) #>        elpd_diff se_diff #> model1    0.0       0.0  #> model2 -261.3      19.3"},{"path":[]},{"path":"/articles/SNUTS-for-TMB-models.html","id":"adaptation-of-stan-diagonal-mass-matrix","dir":"Articles","previous_headings":"Advanced features","what":"Adaptation of Stan diagonal mass matrix","title":"Sparse NUTS for TMB models","text":"estimate QQ well approximate posterior surface, may advantageous adapt diagonal mass matrix account changes scale. can controlled via adapt_stan_metric argument. argument automatically set FALSE using metric ‘stan’ ‘unit’ since metrics theory already descale posterior. can overridden setting equal TRUE run three versions model compare NUTS stepsize. model version without adaptation uses shorter warmup period  apparent first warmup phase model Stan defaults (‘adapted’ plot) large adjustment stepsize corresponds long trajectory lengths thus increased computational time. descaled using QQ adaptation nothing (‘descaled + adapted’), short warmup period can used SNUTS (‘descaled + adapted’) case, often default warmup short adaptation disabled SNUTS. cases longer warmup mass matrix adaptation make difference, see example ‘wildf’ model @monnahan2025.","code":"adapted1 <- sample_snuts(obj, chains=1, seed=1234, refresh=0,                         skip_optimization=TRUE, Q=Q, Qinv=Sigma,                         metric='auto', adapt_stan_metric = TRUE) #> Q is 91.85% zeroes, with condition factor=74028 (min=0.014, max=1018.9) #> Rebuilding RTMB obj without random effects... #> dense metric selected b/c faster than sparse and high correlation (0.81) #> log-posterior at inits=-2574.481; at conditional mode=-2574.481 #> Starting MCMC sampling... #>  #>  #> Gradient evaluation took 0.000117 seconds #> 1000 transitions using 10 leapfrog steps per transition would take 1.17 seconds. #> Adjust your expectations accordingly! #>  #>  #>  #>  Elapsed Time: 1.631 seconds (Warm-up) #>                1.967 seconds (Sampling) #>                3.598 seconds (Total) #> 5 of 2000 (0.25%) iterations ended with a divergence. #> These divergent transitions indicate that HMC is not fully able to explore the posterior distribution. #> Try increasing adapt_delta closer to 1. #> If this doesn't remove all divergences, try to reparameterize the model. #>  #>  #> Model 'RTMB' has 105 pars, and was fit using NUTS with a 'dense' metric #> 1 chain(s) of 2000 total iterations (1000 warmup) were used #> Average run time per chain was 3.6 seconds  #> Minimum ESS=661.27 (66.13%), and maximum Rhat=1.008 #> There were 0 divergences after warmup adapted2 <- sample_snuts(obj, chains=1, seed=1234, refresh=0,                      skip_optimization=TRUE, Q=Q, Qinv=Sigma,                      metric='stan', adapt_stan_metric = TRUE) #> Rebuilding RTMB obj without random effects... #> log-posterior at inits=-2574.399 #> Starting MCMC sampling... #>  #>  #> Gradient evaluation took 6.8e-05 seconds #> 1000 transitions using 10 leapfrog steps per transition would take 0.68 seconds. #> Adjust your expectations accordingly! #>  #>  #>  #>  Elapsed Time: 7.68 seconds (Warm-up) #>                2.872 seconds (Sampling) #>                10.552 seconds (Total) #> 23 of 2000 (1.15%) iterations ended with a divergence. #> These divergent transitions indicate that HMC is not fully able to explore the posterior distribution. #> Try increasing adapt_delta closer to 1. #> If this doesn't remove all divergences, try to reparameterize the model. #>  #>  #> Model 'RTMB' has 105 pars, and was fit using NUTS with a 'stan' metric #> 1 chain(s) of 2000 total iterations (1000 warmup) were used #> Average run time per chain was 10.55 seconds  #> Minimum ESS=580.82 (58.08%), and maximum Rhat=1.007 #> There were 0 divergences after warmup sp1 <- extract_sampler_params(mcmc, inc_warmup = TRUE) |>   subset(iteration <= 1050) |>    cbind(type='descaled + not adapted') sp2 <- extract_sampler_params(adapted1, inc_warmup = TRUE) |>   subset(iteration <= 1050) |>    cbind(type='descaled + adapted') sp3 <- extract_sampler_params(adapted2, inc_warmup = TRUE) |>   subset(iteration <= 1050) |>    cbind(type='adapted') sp <- rbind(sp1, sp2, sp3) ggplot(sp, aes(x=iteration, y=stepsize__, color=type)) + geom_line() +   scale_y_log10() + theme_bw() + theme(legend.position = 'top') +   labs(color=NULL, x='warmup')"},{"path":"/articles/SNUTS-for-TMB-models.html","id":"embedded-laplace-approximation-snuts","dir":"Articles","previous_headings":"Advanced features","what":"Embedded Laplace approximation SNUTS","title":"Sparse NUTS for TMB models","text":"approach uses NUTS (SNUTS) sample marginal posterior using Laplace approximation integrate random effects. first explored @monnahan2018 later detail @margossian2020 called ‘embedded Laplace approximation’. @monnahan2025 applied much larger set models found mixed results. trivial try SNUTS simply declaring laplace=TRUE. can see 5 model parameters (fixed effects), diagonal metric chosen due minimal correlations among parameters. ELA typically take longer run, higher minESS best compare efficiency (minESS per time) . Exploring ELA good opportunity show SNUTS can fail. demonstrate notoriously difficult ‘funnel’ model hierarchical model without data. model strongly varying curvature thus well-approximated QQ SNUTS mixes poorly. turning ELA, mixes fine recovers ","code":"ela <- sample_snuts(obj, chains=1, laplace=TRUE, refresh=0) #> Optimizing... #> Getting M for fixed effects... #> Qinv is 0% zeroes, with condition factor=3107 (min=0.001, max=3.3) #> diag metric selected b/c low correlations #> log-posterior at inits=-2451.942; at conditional mode=-17038.961 #> Starting MCMC sampling... #>  #>  #> Gradient evaluation took 0.000769 seconds #> 1000 transitions using 10 leapfrog steps per transition would take 7.69 seconds. #> Adjust your expectations accordingly! #>  #>  #>  #>  Elapsed Time: 0.847 seconds (Warm-up) #>                4.64 seconds (Sampling) #>                5.487 seconds (Total) #> 1 of 1150 (0.09%) iterations ended with a divergence. #> These divergent transitions indicate that HMC is not fully able to explore the posterior distribution. #> Try increasing adapt_delta closer to 1. #> If this doesn't remove all divergences, try to reparameterize the model. #>  #>  #> Model 'RTMB' has 5 pars, and was fit using NUTS with a 'diag' metric #> 1 chain(s) of 1150 total iterations (150 warmup) were used #> Average run time per chain was 5.49 seconds  #> Minimum ESS=636.49 (63.65%), and maximum Rhat=1.001 #> There were 0 divergences after warmup # Funnel example ported to RTMB from # https://mc-stan.org/docs/cmdstan-guide/diagnose_utility.html#running-the-diagnose-command ## the (negative) posterior density as a function in R f <- function(pars){   getAll(pars)   lp <- dnorm(y, 0, 3, log=TRUE) + # prior     sum(dnorm(x, 0, exp(y/2), log=TRUE)) # likelihood   return(-lp) # TMB expects negative log posterior } obj <- RTMB::MakeADFun(f, list(y=-1.12, x=rep(0,9)), random='x', silent=TRUE)  ### Now SNUTS # devtools::install_github('Cole-Monnahan-NOAA/adnuts', ref='sparse_M') fit <- sample_snuts(obj, seed=1213, refresh=0, init='random') #> Optimizing... #> Getting Q... #> Inverting Q... #> Q is 100% zeroes, with condition factor=9 (min=0.111, max=1) #> Rebuilding RTMB obj without random effects... #> diag metric selected b/c of low correlations #> log-posterior at inits=-237.116; at conditional mode=-10.288 #> Starting MCMC sampling... #> Preparing parallel workspace... #> Chain 1: Gradient evaluation took 0.00012 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.2 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 2: Gradient evaluation took 0.000127 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1.27 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 3: Gradient evaluation took 0.000103 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 1.03 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 4: Gradient evaluation took 0.000102 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 1.02 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  Elapsed Time: 0.415 seconds (Warm-up) #> Chain 4:                2.627 seconds (Sampling) #> Chain 4:                3.042 seconds (Total) #> Chain 3:  Elapsed Time: 0.897 seconds (Warm-up) #> Chain 3:                2.43 seconds (Sampling) #> Chain 3:                3.327 seconds (Total) #> Chain 1:  Elapsed Time: 0.294 seconds (Warm-up) #> Chain 1:                3.827 seconds (Sampling) #> Chain 1:                4.121 seconds (Total) #> Chain 2:  Elapsed Time: 0.642 seconds (Warm-up) #> Chain 2:                6.623 seconds (Sampling) #> Chain 2:                7.265 seconds (Total) #> 39 of 4600 (0.85%) iterations ended with a divergence. #> These divergent transitions indicate that HMC is not fully able to explore the posterior distribution. #> Try increasing adapt_delta closer to 1. #> If this doesn't remove all divergences, try to reparameterize the model. #> 4 of 4 chains had an E-BFMI below the nominal threshold of 0.3 which suggests that HMC may have trouble exploring the target distribution. #> If possible, try to reparameterize the model. #>  #>  #> Model 'RTMB' has 10 pars, and was fit using NUTS with a 'diag' metric #> 4 chain(s) of 1150 total iterations (150 warmup) were used #> Average run time per chain was 4.44 seconds  #> Minimum ESS=92.75 (2.32%), and maximum Rhat=1.044 #> !! Warning: Signs of non-convergence found. Do not use for inference !! #> There were 4 divergences after warmup pairs(fit, pars=1:2) # hasn't recovered the prior b/c it's not converged, particularly # for small y values post <- as.data.frame(fit) hist(post$y, freq=FALSE, xlim=c(-10,10)) lines(x<-seq(-10,10, len=200), dnorm(x,0,3)) abline(v=fit$mle$est[1], col=2, lwd=2) # Now turn on ELA and it easily recovers the prior on y fit.ela <- sample_snuts(obj, laplace=TRUE, refresh=0, init='random', seed=12312) #> Optimizing... #> Getting M for fixed effects... #> diag metric selected b/c only 1 parameter #> log-posterior at inits=-3.181; at conditional mode=-2.087 #> Starting MCMC sampling... #> Preparing parallel workspace... #> Chain 1: Gradient evaluation took 0.023581 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 235.81 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 2: Gradient evaluation took 0.019007 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 190.07 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 3: Gradient evaluation took 0.017706 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 177.06 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 4: Gradient evaluation took 0.022063 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 220.63 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 1:  Elapsed Time: 0.217 seconds (Warm-up) #> Chain 1:                1.149 seconds (Sampling) #> Chain 1:                1.366 seconds (Total) #> Chain 2:  Elapsed Time: 0.196 seconds (Warm-up) #> Chain 2:                1.136 seconds (Sampling) #> Chain 2:                1.332 seconds (Total) #> Chain 3:  Elapsed Time: 0.225 seconds (Warm-up) #> Chain 3:                1.1 seconds (Sampling) #> Chain 3:                1.325 seconds (Total) #> Chain 4:  Elapsed Time: 0.214 seconds (Warm-up) #> Chain 4:                1.103 seconds (Sampling) #> Chain 4:                1.317 seconds (Total) #> 6 of 4600 (0.13%) iterations ended with a divergence. #> These divergent transitions indicate that HMC is not fully able to explore the posterior distribution. #> Try increasing adapt_delta closer to 1. #> If this doesn't remove all divergences, try to reparameterize the model. #>  #>  #> Model 'RTMB' has 1 pars, and was fit using NUTS with a 'diag' metric #> 4 chain(s) of 1150 total iterations (150 warmup) were used #> Average run time per chain was 1.33 seconds  #> Minimum ESS=1834.24 (45.86%), and maximum Rhat=1.002 #> There were 0 divergences after warmup # you just get the prior back b/c the Laplace approximation is # accurate pairs(fit.ela) post.ela <- as.data.frame(fit.ela) hist(post.ela$y, freq=FALSE, breaks=30) lines(x<-seq(-10,10, len=200), dnorm(x,0,3))"},{"path":"/articles/SNUTS-for-TMB-models.html","id":"linking-to-other-stan-algorithms-via-stanestimators","dir":"Articles","previous_headings":"","what":"Linking to other Stan algorithms via StanEstimators","title":"Sparse NUTS for TMB models","text":"sample_snuts links StanEstimators::stan_sample function NUTS sampling. However, package provides algorithms given model may interest users. focus Pathfinder algorithm RTMB model.","code":"# Construct a joint model (no random effects) obj2 <- MakeADFun(func=obj$env$data, parameters=obj$env$parList(),                    map=obj$env$map, random=NULL, silent=TRUE) # TMB does negative log densities so convert to form used by Stan fn <- function(x) -obj2$fn(x) grad_fun <- function(x) -obj2$gr(x) pf <- StanEstimators::stan_pathfinder(fn=fn, grad_fun=grad_fun, refresh=100,                       par_inits = obj$env$last.par.best) #>  #> Path [1] :Initial log joint density = -10.287998 #> Path [1] : Iter      log prob        ||dx||      ||grad||     alpha      alpha0      # evals       ELBO    Best ELBO        Notes  #>               2       8.084e+01      3.600e+01   4.441e-15    1.000e+00  1.000e+00        51 -1.583e+21 -1.583e+21                   #> Path [1] :Best Iter: [1] ELBO (-30.672905) evaluations: (51) #> Path [2] :Initial log joint density = -10.287998 #> Path [2] : Iter      log prob        ||dx||      ||grad||     alpha      alpha0      # evals       ELBO    Best ELBO        Notes  #>               2       8.084e+01      3.600e+01   4.441e-15    1.000e+00  1.000e+00        51 -1.901e+20 -1.901e+20                   #> Path [2] :Best Iter: [1] ELBO (-52.886267) evaluations: (51) #> Path [3] :Initial log joint density = -10.287998 #> Path [3] : Iter      log prob        ||dx||      ||grad||     alpha      alpha0      # evals       ELBO    Best ELBO        Notes  #>               2       8.084e+01      3.600e+01   4.441e-15    1.000e+00  1.000e+00        51 -8.823e+20 -8.823e+20                   #> Path [3] :Best Iter: [1] ELBO (-44.689254) evaluations: (51) #> Path [4] :Initial log joint density = -10.287998 #> Path [4] : Iter      log prob        ||dx||      ||grad||     alpha      alpha0      # evals       ELBO    Best ELBO        Notes  #>               2       8.084e+01      3.600e+01   4.441e-15    1.000e+00  1.000e+00        51 -2.386e+20 -2.386e+20                   #> Path [4] :Best Iter: [1] ELBO (-41.926718) evaluations: (51) #> Total log probability function evaluations:4104 #> Pareto k value (1.8) is greater than 0.7. Importance resampling was not able to improve the approximation, which may indicate that the approximation itself is poor."},{"path":"/articles/SNUTS-for-TMB-models.html","id":"linking-to-other-bayesian-tools","dir":"Articles","previous_headings":"","what":"Linking to other Bayesian tools","title":"Sparse NUTS for TMB models","text":"straightforward pass adnuts output Bayesian R packages. demonstrate bayesplot.","code":"library(bayesplot) #> This is bayesplot version 1.11.1 #> - Online documentation and vignettes at mc-stan.org/bayesplot #> - bayesplot theme set to bayesplot::theme_default() #>    * Does _not_ affect other ggplot2 plots #>    * See ?bayesplot_theme_set for details on theme setting library(tidyr) post <- as.data.frame(mcmc) pars <- mcmc$par_names[1:6] mcmc_areas(post, pars=pars) mcmc_trace(post, pars=pars) color_scheme_set(\"red\") np <- extract_sampler_params(fit) %>%   pivot_longer(-c(chain, iteration), names_to='Parameter', values_to='Value') %>%   select(Iteration=iteration, Parameter, Value, Chain=chain) %>%   mutate(Parameter=factor(Parameter),          Iteration=as.integer(Iteration),          Chain=as.integer(Chain)) %>% as.data.frame() mcmc_nuts_energy(np) + ggtitle(\"NUTS Energy Diagnostic\") + theme_minimal() #> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. #> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. # finally, posterior predictive for first 24 observations ppc_intervals(y=ChickWeight$weight[1:24], yrep=simdat[,1:24])"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Cole Monnahan. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Monnahan CC, Kristensen K (2018) -U-turn sampling fast Bayesian inference ADMB TMB: Introducing adnuts tmbstan R packages. PLoS ONE 13(5): e0197954.   https://doi.org/10.1371/journal.pone.0197954 Monnahan CC (2018). adnuts: -U-Turn MCMC Sampling 'ADMB' 'TMB' Models. R package version 1.1.2.9000.","code":"@Article{,   title = {No-U-turn sampling for fast Bayesian inference in ADMB and TMB: Introducing the adnuts and tmbstan R packages.},   author = {Cole C. Monnahan and Kasper Kristensen},   year = {2018},   journal = {PLoS ONE},   volume = {13},   number = {5},   pages = {e0197954}, } @Manual{,   title = {adnuts: No-U-Turn MCMC Sampling for ADMB Models.},   author = {Cole C. Monnahan},   year = {2018},   note = {R package version 1.1.2.9000}, }"},{"path":"/index.html","id":"adnuts","dir":"","previous_headings":"","what":"Sparse No-U-Turn MCMC Sampling for Template Model Builder","title":"Sparse No-U-Turn MCMC Sampling for Template Model Builder","text":"main:  dev: aim ‘adnuts’ (pronounced -D nuts) provide advanced MCMC sampling ‘TMB’ ‘ADMB’ models. TMB models uses sparse NUTS (SNUTS; Monnahan et al. prep) algorithm decorrelate posterior using joint precision matrix. R package ‘tmbstan’ (available CRAN) provides alternative TMB closely links Stan. development SNUTS, ‘adnuts’ primarily used ADMB models. foreseeable future SNUTS via ‘adnuts’ likely best general option TMB users. ADMB mimics ‘Stan’ functionality feel, specifically providing -U-turn (NUTS) sampling adaptive mass matrix parallel execution. Development ADMB features winding , functionality expected maintained coming years. See following paper introduction package capabilities, contrast tmbstan: Monnahan CC, Kristensen K (2018) -U-turn sampling fast Bayesian inference ADMB TMB: Introducing adnuts tmbstan R packages. PLoS ONE 13(5):e0197954. https://doi.org/10.1371/journal.pone.0197954 Monnahan CC, Thorson, J.T., Kristensen, K, Carpenter, B (prep). Leveraging sparsity improve -u-turn sampling efficiency hierarchical Bayesian models.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Sparse No-U-Turn MCMC Sampling for Template Model Builder","text":"use SNUTS TMB development version must installed, well StanEstimators package CRAN can installed : development version ‘adnuts’ required SNUTS functionality submitted CRAN upon acceptance SNUTS paper. devtools::install_github('Cole-Monnahan-NOAA/adnuts', ref='dev') basic example can run : brief demonstration file best place help get started, also user guide: see vignette('adnuts') detailed information.","code":"# we recommend running this is a fresh R session or restarting your current session install.packages('StanEstimators', repos = c('<https://andrjohns.r-universe.dev>', '<https://cloud.r-project.org>')) library(adnuts) TMB::runExample('simple') mcmc <- sample_snuts(obj)"},{"path":"/index.html","id":"admb-installation-and-usage","dir":"","previous_headings":"","what":"ADMB Installation and Usage","title":"Sparse No-U-Turn MCMC Sampling for Template Model Builder","text":"July 2025 package ‘adnuts’ primarily designed TMB models sampling sparse NUTS algorithm. ADMB functionality still exists install use can found . adnuts R package version 1.1.2 can installed CRAN: install.packages('adnuts'). Future minor releases listed may released CRAN latest stable version can installed : devtools::install_github('Cole-Monnahan-NOAA/adnuts') sample_rwm sample_nuts functions draw posterior samples ADMB model using MCMC algorithm (random walk Metropolis -U-turn sampler). returned fitted object contains samples information. function ‘extract_samples’ can used get posterior samples (post warmup thinning) data frame inference, ‘launch_shinyadmb’ can used interactive diagnostics based ‘ShinyStan’. brief demonstration file best place help get started, also user guide: vignette('adnuts') detailed information. ‘adnuts’ designed specifically use ADMB fisheries ’stock assessments, interested authors referred : Monnahan, C.C., T.. Branch, J.T. Thorson, .J. Stewart, C.S. Szuwalksi (2020) Overcoming long Bayesian run times integrated fisheries stock assessments. ICES Journal Marine Science. https://dx.doi.org/10.1093/icesjms/fsz059","code":""},{"path":"/index.html","id":"admb-installation","dir":"","previous_headings":"","what":"ADMB Installation","title":"Sparse No-U-Turn MCMC Sampling for Template Model Builder","text":"use ADMB functionality need build model version 12.0 (released December 2017) later, otherwise functionality available. See ADMB installation instructions information. ADMB 12.2 highly recommended provides better console output, fixes bugs, adds improved adaptation capabilities compared 12.0. can check ADMB version compiled model command line command model.exe -version prints version among things.","code":""},{"path":"/index.html","id":"known-issues","dir":"","previous_headings":"","what":"Known issues","title":"Sparse No-U-Turn MCMC Sampling for Template Model Builder","text":"Windows users may experience issues model name long. cases OS rename output files using “short” version. ’ll see files like “MODEL~1.par”. package tries handle highly recommended simply shorten filename. instead ‘model_filename_2021.tpl’ use e.g. ‘model_21’. Analyses reproducible setting initial values seed sample_rwm sample_nuts (passed ADMB ‘-mcseed’). However, may entirely consistent across OS platforms. chains start may eventually diverge. likely due minuscule differences gradient log-posterior calculations systems compilers.","code":""},{"path":"/index.html","id":"disclaimer","dir":"","previous_headings":"","what":"Disclaimer","title":"Sparse No-U-Turn MCMC Sampling for Template Model Builder","text":"“United States Department Commerce (DOC) GitHub project code provided ‘’ basis user assumes responsibility use. DOC relinquished control information longer responsibility protect integrity, confidentiality, availability information. claims Department Commerce stemming use GitHub project governed applicable Federal law. reference specific commercial products, processes, services service mark, trademark, manufacturer, otherwise, constitute imply endorsement, recommendation favoring Department Commerce. Department Commerce seal logo, seal logo DOC bureau, shall used manner imply endorsement commercial product activity DOC United States Government.”  U.S. Department Commerce | National Oceanographic Atmospheric Administration | NOAA Fisheries","code":""},{"path":"/reference/adfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Constructor for the ","title":"Constructor for the ","text":"Constructor \"adfit\" (-D fit) class","code":""},{"path":"/reference/adfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constructor for the ","text":"","code":"adfit(x)"},{"path":"/reference/adfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constructor for the ","text":"x Fitted object sample_admb","code":""},{"path":"/reference/adfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Constructor for the ","text":"object class \"adfit\"","code":""},{"path":"/reference/adnuts-package.html","id":null,"dir":"Reference","previous_headings":"","what":"adnuts: No-U-turn sampling for AD Model Builder (ADMB) — adnuts-package","title":"adnuts: No-U-turn sampling for AD Model Builder (ADMB) — adnuts-package","text":"Draw Bayesian posterior samples ADMB model using -U-turn MCMC sampler. Adaptation schemes used specifying tuning parameters necessary, parallel execution reduces overall run time.","code":""},{"path":"/reference/adnuts-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"adnuts: No-U-turn sampling for AD Model Builder (ADMB) — adnuts-package","text":"software package Stan pioneered use -U-turn (NUTS) sampling Bayesian models (Hoffman Gelman 2014, Carpenter et al. 2017). algorithm provides fast, efficient sampling across wide range models, including hierarchical ones, thus can used generic modeling tool (Monnahan et al. 2017). functionality provided adnuts based loosely Stan R package rstan adnuts R package provides R workflow NUTS   sampling ADMB models (Fournier et al. 2011), including   adaptation step size metric (mass matrix), parallel   execution, links diagnostic inference tools   provided rstan shinystan.  ADMB   implementation NUTS code bundled ADMB source   (version 12.0). Thus, user builds   ADMB model NUTS code incorporated model   executable. Thus, adnuts simply provides convenient   set wrappers easily execute, diagnose, make   inference model. details can found   package vignette. Note previous versions adnuts included   functionality TMB models, replaced   tmbstan (Kristensen et al. 2016, Monnahan   Kristensen 2018).","code":""},{"path":"/reference/adnuts-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"adnuts: No-U-turn sampling for AD Model Builder (ADMB) — adnuts-package","text":"Carpenter, B., Gelman, ., Hoffman, M.D., Lee, D., Goodrich, B.,   Betancourt, M., Riddell, ., Guo, J.Q., Li, P., Riddell, .,   2017. Stan: Probabilistic Programming Language.  J Stat   Softw. 76:1-29. Fournier, D.., Skaug, H.J., Ancheta, J., Ianelli, J., Magnusson, .,   Maunder, M.N., Nielsen, ., Sibert, J., 2012. AD Model Builder: using   automatic differentiation statistical inference highly   parameterized complex nonlinear models.  Optim Method   Softw. 27:233-249. Hoffman, M.D., Gelman, ., 2014. -U-turn sampler: adaptively   setting path lengths Hamiltonian Monte Carlo.  J Mach Learn   Res. 15:1593-1623. Kristensen, K., Nielsen, ., Berg, C.W., Skaug, H., Bell, B.M.,   2016. TMB: Automatic differentiation Laplace approximation.  J   Stat Softw. 70:21. Kristensen, K., 2017. TMB: General random effect model builder tool   inspired ADMB. R package version 1.7.11. Monnahan, C.C., Thorson, J.T., Branch, T.., 2017. Faster estimation   Bayesian models ecology using Hamiltonian Monte Carlo.  Methods   Ecology Evolution. 8:339-348. Monnahan C.C., Kristensen K. (2018). -U-turn sampling fast  Bayesian inference ADMB TMB: Introducing adnuts  tmbstan R packages PLoS ONE 13(5): e0197954.  https://doi.org/10.1371/journal.pone.0197954 Stan Development Team, 2016. Stan modeling language users guide   reference manual, version 2.11.0. Stan Development Team, 2016. RStan: R interface Stan. R package version 2.14.1. http://mc-stan.org.","code":""},{"path":[]},{"path":"/reference/adnuts-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"adnuts: No-U-turn sampling for AD Model Builder (ADMB) — adnuts-package","text":"Maintainer: Cole Monnahan cole.monnahan@noaa.gov (ORCID)","code":""},{"path":"/reference/as.data.frame.adfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert object of class adfit to data.frame. Calls extract_samples — as.data.frame.adfit","title":"Convert object of class adfit to data.frame. Calls extract_samples — as.data.frame.adfit","text":"Convert object class adfit data.frame. Calls extract_samples","code":""},{"path":"/reference/as.data.frame.adfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert object of class adfit to data.frame. Calls extract_samples — as.data.frame.adfit","text":"","code":"# S3 method for class 'adfit' as.data.frame(x, row.names = NULL, optional = FALSE, ...)"},{"path":"/reference/as.data.frame.adfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert object of class adfit to data.frame. Calls extract_samples — as.data.frame.adfit","text":"x Fitted object sample_rwm row.names Ignored optional Ignored ... Ignored","code":""},{"path":"/reference/as.data.frame.adfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert object of class adfit to data.frame. Calls extract_samples — as.data.frame.adfit","text":"data frame parameters columns samples   rows.","code":""},{"path":"/reference/as.data.frame.adfit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert object of class adfit to data.frame. Calls extract_samples — as.data.frame.adfit","text":"calls default settings   extract_samples, warmup samples   column log-posterior (lp__). Use function   directly finer control.","code":""},{"path":"/reference/as.tmbfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Construtor for tmbfit objects — as.tmbfit","title":"Construtor for tmbfit objects — as.tmbfit","text":"Construtor tmbfit objects","code":""},{"path":"/reference/as.tmbfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construtor for tmbfit objects — as.tmbfit","text":"","code":"as.tmbfit(x, parnames, mle, invf, metric, model = \"anonymous\")"},{"path":"/reference/as.tmbfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construtor for tmbfit objects — as.tmbfit","text":"x fitted MCMC object parnames character vector unique par names mle list MLE parameters invf inverse function parameters metric metric used model character giving model name","code":""},{"path":"/reference/check_identifiable.html","id":null,"dir":"Reference","previous_headings":"","what":"Check identifiability from model Hessian — check_identifiable","title":"Check identifiability from model Hessian — check_identifiable","text":"Check identifiability model Hessian","code":""},{"path":"/reference/check_identifiable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check identifiability from model Hessian — check_identifiable","text":"","code":"check_identifiable(model, path = getwd())"},{"path":"/reference/check_identifiable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check identifiability from model Hessian — check_identifiable","text":"model Model name without file extension path Path model folder, defaults working directory","code":""},{"path":"/reference/check_identifiable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check identifiability from model Hessian — check_identifiable","text":"Prints output bad parameters invisibly returns .","code":""},{"path":"/reference/check_identifiable.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check identifiability from model Hessian — check_identifiable","text":"Read admodel.hes file check eigenvalues   determine parameters identifiable thus cause   Hessian non-invertible. Use identify parameters   problematic. function converted version   FishStatsUtils package.","code":""},{"path":"/reference/dot-check_ADMB_version.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that the model is compiled with the right version of ADMB which is 12.0 or later — .check_ADMB_version","title":"Check that the model is compiled with the right version of ADMB which is 12.0 or later — .check_ADMB_version","text":"Check  model compiled right version ADMB 12.0 later","code":""},{"path":"/reference/dot-check_ADMB_version.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that the model is compiled with the right version of ADMB which is 12.0 or later — .check_ADMB_version","text":"","code":".check_ADMB_version(model, path = getwd(), min.version = 12, warn = TRUE)"},{"path":"/reference/dot-check_ADMB_version.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check that the model is compiled with the right version of ADMB which is 12.0 or later — .check_ADMB_version","text":"model Model name without file extension path Path model folder, defaults working directory. NULL value specifies working directory (default). min.version Minimum valid version (numeric). Defaults 12.0. warn Boolean whether throw warnings ","code":""},{"path":"/reference/dot-check_ADMB_version.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check that the model is compiled with the right version of ADMB which is 12.0 or later — .check_ADMB_version","text":"Nothing, errors either model run   version incompatible. compatible nothing   happens.","code":""},{"path":"/reference/dot-check_ADMB_version.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check that the model is compiled with the right version of ADMB which is 12.0 or later — .check_ADMB_version","text":"functionality packages adnuts   imbedded ADMB source code model   compiled contained model executable.   code exist adnuts fail. solution   update ADMB recompile model.","code":""},{"path":"/reference/dot-check_console_printing.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if the session is interactive or Rstudio which has implications for parallel output — .check_console_printing","title":"Check if the session is interactive or Rstudio which has implications for parallel output — .check_console_printing","text":"Check session interactive Rstudio implications parallel output","code":""},{"path":"/reference/dot-check_console_printing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if the session is interactive or Rstudio which has implications for parallel output — .check_console_printing","text":"","code":".check_console_printing(parallel)"},{"path":"/reference/dot-check_console_printing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if the session is interactive or Rstudio which has implications for parallel output — .check_console_printing","text":"parallel Boolean whether chain executed parallel mode .","code":""},{"path":"/reference/dot-check_console_printing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if the session is interactive or Rstudio which has implications for parallel output — .check_console_printing","text":"Boolean whether output printed console   progressively, saved file printed end.","code":""},{"path":"/reference/dot-check_console_printing.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check if the session is interactive or Rstudio which has implications for parallel output — .check_console_printing","text":"using RStudio RGui, parallel output   show console. workaround captured   cluster file read printed.","code":""},{"path":"/reference/dot-check_model_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that the file can be found — .check_model_path","title":"Check that the file can be found — .check_model_path","text":"Check file can found","code":""},{"path":"/reference/dot-check_model_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that the file can be found — .check_model_path","text":"","code":".check_model_path(model, path)"},{"path":"/reference/dot-check_model_path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check that the file can be found — .check_model_path","text":"model Model name without file extension path Path model folder, defaults working","code":""},{"path":"/reference/dot-getADMBHessian.html","id":null,"dir":"Reference","previous_headings":"","what":"Read in admodel.hes file — .getADMBHessian","title":"Read in admodel.hes file — .getADMBHessian","text":"Read admodel.hes file","code":""},{"path":"/reference/dot-getADMBHessian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read in admodel.hes file — .getADMBHessian","text":"","code":".getADMBHessian(path, full = FALSE)"},{"path":"/reference/dot-getADMBHessian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read in admodel.hes file — .getADMBHessian","text":"path Path folder containing admodel.hes file full Whether return just Hessian (FALSE - default) full","code":""},{"path":"/reference/dot-getADMBHessian.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read in admodel.hes file — .getADMBHessian","text":"Hessian matrix","code":""},{"path":"/reference/dot-get_inits.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a single initial value vector in untransformed model space — .get_inits","title":"Get a single initial value vector in untransformed model space — .get_inits","text":"Get single initial value vector untransformed model space","code":""},{"path":"/reference/dot-get_inits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a single initial value vector in untransformed model space — .get_inits","text":"","code":".get_inits(init, metric, obj2, seed, inputs)"},{"path":"/reference/dot-get_inits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a single initial value vector in untransformed model space — .get_inits","text":"init initial value strategy obj2 joint TMB model seed RNG seed inputs list returned .get_inputs.","code":""},{"path":"/reference/dot-get_inputs.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare inputs for sparse sampling @param obj Object @param skip_optimization Whether to skip or not @param laplace Whether to due the LA or not @param metric Which metric @param Q Sparse precision @param Qinv Inverse of Q @return A list containing Q, Qinv, the mle list, and timings — .get_inputs","title":"Prepare inputs for sparse sampling @param obj Object @param skip_optimization Whether to skip or not @param laplace Whether to due the LA or not @param metric Which metric @param Q Sparse precision @param Qinv Inverse of Q @return A list containing Q, Qinv, the mle list, and timings — .get_inputs","text":"Prepare inputs sparse sampling  @param obj Object  @param skip_optimization Whether skip  @param laplace Whether due LA  @param metric metric  @param Q Sparse precision  @param Qinv Inverse Q  @return list containing Q, Qinv, mle list, timings","code":""},{"path":"/reference/dot-get_inputs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare inputs for sparse sampling @param obj Object @param skip_optimization Whether to skip or not @param laplace Whether to due the LA or not @param metric Which metric @param Q Sparse precision @param Qinv Inverse of Q @return A list containing Q, Qinv, the mle list, and timings — .get_inputs","text":"","code":".get_inputs(obj, skip_optimization, laplace, metric, Q, Qinv)"},{"path":"/reference/dot-make_unique_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to take a character vector of parameter names and force them to be unique by appending numbers in square brackets as needed — .make_unique_names","title":"Function to take a character vector of parameter names and force them to be unique by appending numbers in square brackets as needed — .make_unique_names","text":"Function take character vector parameter names force unique appending numbers square brackets needed","code":""},{"path":"/reference/dot-make_unique_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to take a character vector of parameter names and force them to be unique by appending numbers in square brackets as needed — .make_unique_names","text":"","code":".make_unique_names(x)"},{"path":"/reference/dot-make_unique_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to take a character vector of parameter names and force them to be unique by appending numbers in square brackets as needed — .make_unique_names","text":"x Character vector","code":""},{"path":"/reference/dot-print.mat.stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Print matrix stats — .print.mat.stats","title":"Print matrix stats — .print.mat.stats","text":"Print matrix stats","code":""},{"path":"/reference/dot-print.mat.stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print matrix stats — .print.mat.stats","text":"","code":".print.mat.stats(x)"},{"path":"/reference/dot-print.mat.stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print matrix stats — .print.mat.stats","text":"x matrix object name","code":""},{"path":"/reference/dot-rotate_posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Update algorithm for mass matrix. — .rotate_posterior","title":"Update algorithm for mass matrix. — .rotate_posterior","text":"Update algorithm mass matrix.","code":""},{"path":"/reference/dot-rotate_posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update algorithm for mass matrix. — .rotate_posterior","text":"","code":".rotate_posterior(metric, fn, gr, Q, Qinv, y.cur)"},{"path":"/reference/dot-rotate_posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update algorithm for mass matrix. — .rotate_posterior","text":"metric metric use fn current fn function. gr current gr function Q sparse precision matrix Qinv inverse Q y.cur current parameter vector unrotated (Y) space.","code":""},{"path":"/reference/dot-rotate_space.html","id":null,"dir":"Reference","previous_headings":"","what":"Update algorithm for mass matrix. — .rotate_space","title":"Update algorithm for mass matrix. — .rotate_space","text":"Update algorithm mass matrix.","code":""},{"path":"/reference/dot-rotate_space.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update algorithm for mass matrix. — .rotate_space","text":"","code":".rotate_space(fn, gr, M, y.cur)"},{"path":"/reference/dot-rotate_space.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update algorithm for mass matrix. — .rotate_space","text":"fn current fn function. gr current gr function M new mass matrix y.cur current parameter vector unrotated (Y) space.","code":""},{"path":"/reference/dot-sample_admb.html","id":null,"dir":"Reference","previous_headings":"","what":"Hidden wrapper function for sampling from ADMB models — .sample_admb","title":"Hidden wrapper function for sampling from ADMB models — .sample_admb","text":"Hidden wrapper function sampling ADMB models","code":""},{"path":"/reference/dot-sample_admb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hidden wrapper function for sampling from ADMB models — .sample_admb","text":"","code":".sample_admb(   model,   path = getwd(),   iter = 2000,   init = NULL,   chains = 3,   warmup = NULL,   seeds = NULL,   thin = 1,   mceval = FALSE,   duration = NULL,   cores = NULL,   control = NULL,   verbose = TRUE,   algorithm = \"NUTS\",   skip_optimization = TRUE,   skip_monitor = FALSE,   skip_unbounded = TRUE,   admb_args = NULL )"},{"path":"/reference/dot-sample_admb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hidden wrapper function for sampling from ADMB models — .sample_admb","text":"model Name model (.e., 'model' model.tpl). non-Windows systems automatically converted './model' internally. Windows, long file names sometimes shortened e.g., 'long_model_filename' 'LONG_~1'. work, throw warnings. Please shorten model name. See https://en.wikipedia.org/wiki/8.3_filename. path Path model executable. Defaults working directory. Often best model files separate subdirectory, particularly parallel. iter number samples draw. init Can either list containing vector chain, function returns vector parameters, NULL specifies use MLE stored admodel.hes file. generally recommended use dispersed initial values improve diagnostic checks (starting point makes less likely find multiple modes). chains number chains run. warmup number warmup iterations. seeds vector seeds, one chain. thin thinning rate apply samples. Typically used NUTS. mceval Whether run model -mceval samples merged chains. duration number minutes model quit running. recommended set warmup carefully iter higher expected runs duration. usually results chains different lengths, minimum taken across . cores number cores use parallel execution. Default number available system minus 1. cores=1, serial execution occurs (even chains>1), otherwise parallel execution via package snowfall used. slow analyses recommended set chains<=cores core needs run single chain. control list control sampler. See details use. verbose Flag whether show console output (default) suppress completely except warnings errors. Works serial parallel execution. algorithm algorithm use, one \"NUTS\" \"RWM\" skip_optimization Whether run optimizer running MCMC. rarely need better run get covariance matrix, estimates needed adaptive NUTS. skip_monitor Whether skip calculating diagnostics (effective sample size, Rhat) via rstan::monitor function. can slow models high dimension many iterations. result used plots summaries recommended turn . model run skip_monitor=FALSE can recreate post-hoc setting fit$monitor=rstan::monitor(fit$samples, fit$warmup, print=FALSE). skip_unbounded Whether skip returning unbounded version posterior samples addition bounded ones. may advisable set FALSE large models save space. admb_args character string gets passed command line, allowing finer control","code":""},{"path":"/reference/dot-update_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert model name depending on system — .update_model","title":"Convert model name depending on system — .update_model","text":"Convert model name depending system","code":""},{"path":"/reference/dot-update_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert model name depending on system — .update_model","text":"","code":".update_model(model)"},{"path":"/reference/dot-update_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert model name depending on system — .update_model","text":"model Model name without file extension","code":""},{"path":"/reference/dot-update_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert model name depending on system — .update_model","text":"Updated model name use system call","code":""},{"path":"/reference/extract_sampler_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract sampler parameters from a fit. — extract_sampler_params","title":"Extract sampler parameters from a fit. — extract_sampler_params","text":"Extract information NUTS trajectories, acceptance ratio treedepth, fitted object.","code":""},{"path":"/reference/extract_sampler_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract sampler parameters from a fit. — extract_sampler_params","text":"","code":"extract_sampler_params(fit, inc_warmup = FALSE)"},{"path":"/reference/extract_sampler_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract sampler parameters from a fit. — extract_sampler_params","text":"fit list returned sample_admb. inc_warmup Whether extract warmup samples (default). Warmup samples never used inference, may useful diagnostics.","code":""},{"path":"/reference/extract_sampler_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract sampler parameters from a fit. — extract_sampler_params","text":"invisible data.frame containing samples (rows)   parameter (columns). multiple chains exist rbinded   together.","code":""},{"path":"/reference/extract_sampler_params.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract sampler parameters from a fit. — extract_sampler_params","text":"trajectory (iteration) NUTS associated information   trajectory: stepsize, acceptance ratio, treedepth, number   leapfrog steps. function extracts data.frame,   may useful diagnosing issues certain cases. general,   user need examine , preferably via   plot_sampler_params  launch_shinyadmb.","code":""},{"path":[]},{"path":"/reference/extract_sampler_params.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract sampler parameters from a fit. — extract_sampler_params","text":"","code":"fit <- readRDS(system.file('examples', 'fit.RDS', package='adnuts')) sp <- extract_sampler_params(fit, inc_warmup=TRUE) str(sp) #> 'data.frame':\t3000 obs. of  8 variables: #>  $ chain        : num  1 1 1 1 1 1 1 1 1 1 ... #>  $ iteration    : num  1 2 3 4 5 6 7 8 9 10 ... #>  $ accept_stat__: num  1.33e-06 9.97e-01 9.62e-01 9.79e-01 7.32e-01 ... #>  $ stepsize__   : num  0.0292 0.0288 0.0322 0.0404 0.0347 ... #>  $ treedepth__  : num  4 4 2 4 1 3 1 3 4 2 ... #>  $ n_leapfrog__ : num  15 15 3 11 1 7 1 7 11 3 ... #>  $ divergent__  : num  0 0 0 0 0 0 0 0 0 0 ... #>  $ energy__     : num  28.3 17.5 12 12.6 12.6 ..."},{"path":"/reference/extract_samples.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract posterior samples from a model fit. — extract_samples","title":"Extract posterior samples from a model fit. — extract_samples","text":"helper function extract posterior samples across multiple chains single data.frame.","code":""},{"path":"/reference/extract_samples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract posterior samples from a model fit. — extract_samples","text":"","code":"extract_samples(   fit,   inc_warmup = FALSE,   inc_lp = FALSE,   as.list = FALSE,   unbounded = FALSE )"},{"path":"/reference/extract_samples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract posterior samples from a model fit. — extract_samples","text":"fit list returned sample_admb. inc_warmup Whether extract warmup samples (default). Warmup samples never used inference, may useful diagnostics. inc_lp Whether include column log posterior density (last column). diagnostics can useful. .list Whether return samples list (one element per chain). converted CODA mcmc object. unbounded Boolean flag whether return samples unbounded (untransformed) space. differences init_bounded types used ADMB template. can useful model debugging.","code":""},{"path":"/reference/extract_samples.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract posterior samples from a model fit. — extract_samples","text":".list FALSE, invisible data.frame containing samples   (rows) parameter (columns). multiple chains exist   rbinded together, maintaining order within chain. .list   TRUE, samples returned list matrices.","code":""},{"path":"/reference/extract_samples.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract posterior samples from a model fit. — extract_samples","text":"function loosely based rstan function   extract. Merging samples across chains used   inference appropriate diagnostic checks. calculate   diagnostics like Rhat effective sample size using   function, instead, use monitor. Likewise, warmup   samples valid never used inference, may   useful cases diagnosing issues.","code":""},{"path":"/reference/extract_samples.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract posterior samples from a model fit. — extract_samples","text":"","code":"## A previously run fitted ADMB model fit <- readRDS(system.file('examples', 'fit.RDS', package='adnuts')) post <- extract_samples(fit) tail(apply(post, 2, median)) #>        a        b  #> 1.928753 4.031563"},{"path":"/reference/get_post.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract posterior samples from a tmbfit object — get_post","title":"Extract posterior samples from a tmbfit object — get_post","text":"Extract posterior samples tmbfit object","code":""},{"path":"/reference/get_post.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract posterior samples from a tmbfit object — get_post","text":"","code":"get_post(x, invf, parnames, array = FALSE)"},{"path":"/reference/get_post.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract posterior samples from a tmbfit object — get_post","text":"x fitted tmbfit object invf inverse function decorrelate parameters parnames vector parameter names, excluding lp__ array Whether return data.frame (default) array used constructing objects downstream","code":""},{"path":"/reference/is.adfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Check object of class adfit — is.adfit","title":"Check object of class adfit — is.adfit","text":"Check object class adfit","code":""},{"path":"/reference/is.adfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check object of class adfit — is.adfit","text":"","code":"is.adfit(x)"},{"path":"/reference/is.adfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check object of class adfit — is.adfit","text":"x Returned list sample_admb","code":""},{"path":"/reference/launch_shinyadmb.html","id":null,"dir":"Reference","previous_headings":"","what":"Launch shinystan for an ADMB fit. — launch_shinyadmb","title":"Launch shinystan for an ADMB fit. — launch_shinyadmb","text":"Launch shinystan ADMB fit.","code":""},{"path":"/reference/launch_shinyadmb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Launch shinystan for an ADMB fit. — launch_shinyadmb","text":"","code":"launch_shinyadmb(fit)"},{"path":"/reference/launch_shinyadmb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Launch shinystan for an ADMB fit. — launch_shinyadmb","text":"fit named list returned sample_admb.","code":""},{"path":[]},{"path":"/reference/launch_shinytmb.html","id":null,"dir":"Reference","previous_headings":"","what":"Launch shinystan for a TMB fit. — launch_shinytmb","title":"Launch shinystan for a TMB fit. — launch_shinytmb","text":"Launch shinystan TMB fit.","code":""},{"path":"/reference/launch_shinytmb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Launch shinystan for a TMB fit. — launch_shinytmb","text":"","code":"launch_shinytmb(fit)"},{"path":"/reference/launch_shinytmb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Launch shinystan for a TMB fit. — launch_shinytmb","text":"fit named list returned sample_tmb.","code":""},{"path":[]},{"path":"/reference/pairs.adfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot pairwise parameter posteriors and optionally the MLE points and confidence ellipses. — pairs.adfit","title":"Plot pairwise parameter posteriors and optionally the MLE points and confidence ellipses. — pairs.adfit","text":"Plot pairwise parameter posteriors optionally MLE points confidence ellipses.","code":""},{"path":"/reference/pairs.adfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot pairwise parameter posteriors and optionally the MLE points and confidence ellipses. — pairs.adfit","text":"","code":"# S3 method for class 'adfit' pairs(   fit,   pars = NULL,   order = c(\"orig\", \"slow\", \"fast\", \"mismatch\", \"cor\"),   inc_warmup = FALSE,   diag = c(\"trace\", \"acf\", \"hist\"),   acf.ylim = c(-1, 1),   ymult = NULL,   axis.col = gray(0.5),   label.cex = 0.8,   limits = NULL,   add.mle = TRUE,   add.monitor = TRUE,   add.inits = FALSE,   unbounded = FALSE,   ... )"},{"path":"/reference/pairs.adfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot pairwise parameter posteriors and optionally the MLE points and confidence ellipses. — pairs.adfit","text":"fit list returned sample_nuts. pars character vector parameters integers representing parameters subset. Useful model larger number parameters just want show key ones. order order consider parameters. Options 'orig' (default) use order declared model, 'slow' 'fast' based effective sample sizes ordered slowest fastest mixing respectively. 'mismatch' sorts parameters large discrepancies MLE posterior marginal variances, defined absolute relative difference MLE posterior .e., abs((mle-post)/post). Finally, 'cor' orders largest maximum absolute pairwise posterior correlation (including lp__). See example usage. inc_warmup Whether include warmup samples (default). diag type plot include diagonal, options 'acf' plots autocorrelation function acf, 'hist' shows marginal posterior histograms, 'trace' trace plot. acf.ylim using acf function diagonal, specify y limit. default c(-1,1). ymult vector length ncol(posterior) specifying much room give using hist option diagonal. use label blocking part plot. default 1.3 parameters. axis.col Color axes label.cex Control size outer diagonal labels (default 1) limits list containing ranges parameter use plotting. add.mle Boolean whether add 95% confidence ellipses add.monitor Boolean whether print effective sample add.inits Boolean whether add initial values plot unbounded Whether use bounded unbounded version parameters.  size (ESS) Rhat values diagonal. ... Arguments passed plot call lower triangular panels (scatterplots).","code":""},{"path":"/reference/pairs.adfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot pairwise parameter posteriors and optionally the MLE points and confidence ellipses. — pairs.adfit","text":"Produces plot, returns nothing.","code":""},{"path":"/reference/pairs.adfit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot pairwise parameter posteriors and optionally the MLE points and confidence ellipses. — pairs.adfit","text":"function modified base pairs   code work specifically fits 'adnuts'   package using either NUTS RWM MCMC algorithms.   invertible Hessian found (fit$mle)   estimated covariances available compare added   automatically (red ellipses). Likewise, \"monitor\" object   rstan::monitor attached fit$monitor   provides effective sample sizes (ESS) Rhat   values. ESS used potentially order parameters   via argument order, also printed diagonal.","code":""},{"path":"/reference/pairs.adfit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot pairwise parameter posteriors and optionally the MLE points and confidence ellipses. — pairs.adfit","text":"Cole Monnahan","code":""},{"path":"/reference/pairs.adfit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot pairwise parameter posteriors and optionally the MLE points and confidence ellipses. — pairs.adfit","text":"","code":"fit <- readRDS(system.file('examples', 'fit.RDS', package='adnuts')) pairs(fit)  pairs(fit, pars=1:2)  pairs(fit, pars=c(2,1))  pairs(fit, pars=c('b', 'a')) pairs(fit, pars=1:2, order='slow')  pairs(fit, pars=1:2, order='fast')  pairs(fit, pars=1:2, order='mismatch')"},{"path":"/reference/pairs_admb.html","id":null,"dir":"Reference","previous_headings":"","what":"Deprecated function to make custom pairs plots for 'adfit' objects. Use S3 class method 'pairs' instead, and see ?pairs.adfit for help. — pairs_admb","title":"Deprecated function to make custom pairs plots for 'adfit' objects. Use S3 class method 'pairs' instead, and see ?pairs.adfit for help. — pairs_admb","text":"Deprecated function make custom pairs plots 'adfit' objects. Use S3 class method 'pairs' instead, see ?pairs.adfit help.","code":""},{"path":"/reference/pairs_admb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deprecated function to make custom pairs plots for 'adfit' objects. Use S3 class method 'pairs' instead, and see ?pairs.adfit for help. — pairs_admb","text":"","code":"pairs_admb(...)"},{"path":"/reference/pairs_admb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deprecated function to make custom pairs plots for 'adfit' objects. Use S3 class method 'pairs' instead, and see ?pairs.adfit for help. — pairs_admb","text":"... Passed ","code":""},{"path":"/reference/plot.adfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot object of class adfit — plot.adfit","title":"Plot object of class adfit — plot.adfit","text":"Plot object class adfit","code":""},{"path":"/reference/plot.adfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot object of class adfit — plot.adfit","text":"","code":"# S3 method for class 'adfit' plot(x, y, ...)"},{"path":"/reference/plot.adfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot object of class adfit — plot.adfit","text":"x Fitted object sample_admb y Ignored ... Ignored","code":""},{"path":"/reference/plot.adfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot object of class adfit — plot.adfit","text":"Plot created","code":""},{"path":"/reference/plot_marginals.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot marginal distributions for a fitted model — plot_marginals","title":"Plot marginal distributions for a fitted model — plot_marginals","text":"Plot marginal distributions fitted model","code":""},{"path":"/reference/plot_marginals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot marginal distributions for a fitted model — plot_marginals","text":"","code":"plot_marginals(   fit,   pars = NULL,   mfrow = NULL,   add.mle = TRUE,   add.monitor = TRUE,   breaks = 30 )"},{"path":"/reference/plot_marginals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot marginal distributions for a fitted model — plot_marginals","text":"fit fitted object returned sample_admb. pars numeric character vector parameters plot, plotting subset total (defaults ) mfrow custom grid size (vector two) called par(mfrow), overriding defaults. add.mle Whether add marginal normal distributions determined inverse Hessian file add.monitor Whether add ESS Rhat information breaks number breaks use hist(), defaulting 30","code":""},{"path":"/reference/plot_marginals.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot marginal distributions for a fitted model — plot_marginals","text":"function plots grid cells parameters   model, comparing marginal posterior histogram vs   asymptotic normal (red lines) inverse   Hessian. intended use quickly gauge differences   frequentist Bayesian inference   model. fit$monitor exists effective sample size (ESS) R-hat estimates printed top right corner. See https://mc-stan.org/rstan/reference/Rhat.html information. Generally Rhat>1.05 ESS<100 (per chain) suggest inference may unreliable. function customized work multipage PDFs, specifically: pdf('marginals.pdf', onefile=TRUE, width=7,height=5) produces nice readable file.","code":""},{"path":"/reference/plot_marginals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot marginal distributions for a fitted model — plot_marginals","text":"","code":"fit <- readRDS(system.file('examples', 'fit.RDS', package='adnuts')) plot_marginals(fit, pars=1:2)"},{"path":"/reference/plot_Q.html","id":null,"dir":"Reference","previous_headings":"","what":"Make an image plot showing the correlation (lower triangle) and sparsity (upper triangle). — plot_Q","title":"Make an image plot showing the correlation (lower triangle) and sparsity (upper triangle). — plot_Q","text":"Make image plot showing correlation (lower triangle) sparsity (upper triangle).","code":""},{"path":"/reference/plot_Q.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make an image plot showing the correlation (lower triangle) and sparsity (upper triangle). — plot_Q","text":"","code":"plot_Q(fit, Q = NULL)"},{"path":"/reference/plot_Q.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make an image plot showing the correlation (lower triangle) and sparsity (upper triangle). — plot_Q","text":"fit fitted object Q sparse matrix. NULL extracted fit.","code":""},{"path":"/reference/plot_Q.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make an image plot showing the correlation (lower triangle) and sparsity (upper triangle). — plot_Q","text":"plot created Matrix::image.","code":""},{"path":"/reference/plot_Q.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make an image plot showing the correlation (lower triangle) and sparsity (upper triangle). — plot_Q","text":"function used visualize sparsity   correlation patterns joint model. upper triangle   shows whether element 0 (white) (gray),   lower triangle shows correlation calculated   cov2cor(solve(Q)).","code":""},{"path":"/reference/plot_sampler_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot adaptation metrics for a fitted model. — plot_sampler_params","title":"Plot adaptation metrics for a fitted model. — plot_sampler_params","text":"Plot adaptation metrics fitted model.","code":""},{"path":"/reference/plot_sampler_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot adaptation metrics for a fitted model. — plot_sampler_params","text":"","code":"plot_sampler_params(fit, plot = TRUE)"},{"path":"/reference/plot_sampler_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot adaptation metrics for a fitted model. — plot_sampler_params","text":"fit fitted object returned sample_admb. plot Whether plot results","code":""},{"path":"/reference/plot_sampler_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot adaptation metrics for a fitted model. — plot_sampler_params","text":"Prints invisibly returns ggplot object","code":""},{"path":"/reference/plot_sampler_params.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot adaptation metrics for a fitted model. — plot_sampler_params","text":"utility function quickly plots adaptation output NUTS chains.","code":""},{"path":"/reference/plot_sampler_params.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot adaptation metrics for a fitted model. — plot_sampler_params","text":"","code":"fit <- readRDS(system.file('examples', 'fit.RDS', package='adnuts')) plot_sampler_params(fit)"},{"path":"/reference/plot_uncertainties.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot MLE vs MCMC marginal standard deviations for each parameter — plot_uncertainties","title":"Plot MLE vs MCMC marginal standard deviations for each parameter — plot_uncertainties","text":"Plot MLE vs MCMC marginal standard deviations parameter","code":""},{"path":"/reference/plot_uncertainties.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot MLE vs MCMC marginal standard deviations for each parameter — plot_uncertainties","text":"","code":"plot_uncertainties(fit, log = TRUE, plot = TRUE)"},{"path":"/reference/plot_uncertainties.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot MLE vs MCMC marginal standard deviations for each parameter — plot_uncertainties","text":"fit fitted object returned sample_admb log Whether plot axes log space (default TRUE). plot Whether plot .","code":""},{"path":"/reference/plot_uncertainties.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot MLE vs MCMC marginal standard deviations for each parameter — plot_uncertainties","text":"Invisibly returns data.frame parameter name (row)   estimated uncertainties method (columns).","code":""},{"path":"/reference/plot_uncertainties.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot MLE vs MCMC marginal standard deviations for each parameter — plot_uncertainties","text":"can helpful compare uncertainty estimates   two paradigms. plots marginal posterior   standard deviation vs frequentist standard error   estimated .cor file. Large differences often   indicate issues one estimation method.","code":""},{"path":"/reference/plot_uncertainties.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot MLE vs MCMC marginal standard deviations for each parameter — plot_uncertainties","text":"","code":"fit <- readRDS(system.file('examples', 'fit.RDS', package='adnuts')) x <- plot_uncertainties(fit, plot=FALSE) head(x) #>   par   sd.post  sd.mle #> a   a 0.2028936 0.15547 #> b   b 0.9112519 0.70394"},{"path":"/reference/print.adfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Print summary of adfit object — print.adfit","title":"Print summary of adfit object — print.adfit","text":"Print summary adfit object","code":""},{"path":"/reference/print.adfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print summary of adfit object — print.adfit","text":"","code":"# S3 method for class 'adfit' print(x, ...)"},{"path":"/reference/print.adfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print summary of adfit object — print.adfit","text":"x Fitted object sample_admb ... Ignored","code":""},{"path":"/reference/print.adfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print summary of adfit object — print.adfit","text":"Summary printed console","code":""},{"path":"/reference/sample_admb.html","id":null,"dir":"Reference","previous_headings":"","what":"Deprecated version of wrapper function. Use sample_nuts or sample_rwm instead. — sample_admb","title":"Deprecated version of wrapper function. Use sample_nuts or sample_rwm instead. — sample_admb","text":"Deprecated version wrapper function. Use sample_nuts sample_rwm instead.","code":""},{"path":"/reference/sample_admb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deprecated version of wrapper function. Use sample_nuts or sample_rwm instead. — sample_admb","text":"","code":"sample_admb(   model,   path = getwd(),   iter = 2000,   init = NULL,   chains = 3,   warmup = NULL,   seeds = NULL,   thin = 1,   mceval = FALSE,   duration = NULL,   parallel = FALSE,   cores = NULL,   control = NULL,   skip_optimization = TRUE,   algorithm = \"NUTS\",   skip_monitor = FALSE,   skip_unbounded = TRUE,   admb_args = NULL )"},{"path":"/reference/sample_admb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deprecated version of wrapper function. Use sample_nuts or sample_rwm instead. — sample_admb","text":"model Name model (.e., 'model' model.tpl). non-Windows systems automatically converted './model' internally. Windows, long file names sometimes shortened e.g., 'long_model_filename' 'LONG_~1'. work, throw warnings. Please shorten model name. See https://en.wikipedia.org/wiki/8.3_filename. path Path model executable. Defaults working directory. Often best model files separate subdirectory, particularly parallel. iter number samples draw. init Can either list containing vector chain, function returns vector parameters, NULL specifies use MLE stored admodel.hes file. generally recommended use dispersed initial values improve diagnostic checks (starting point makes less likely find multiple modes). chains number chains run. warmup number warmup iterations. seeds vector seeds, one chain. thin thinning rate apply samples. Typically used NUTS. mceval Whether run model -mceval samples merged chains. duration number minutes model quit running. recommended set warmup carefully iter higher expected runs duration. usually results chains different lengths, minimum taken across . parallel deprecated argument, use cores=1 serial execution cores>1 parallel (default parallel cores equal available-1) cores number cores use parallel execution. Default number available system minus 1. cores=1, serial execution occurs (even chains>1), otherwise parallel execution via package snowfall used. slow analyses recommended set chains<=cores core needs run single chain. control list control sampler. See details use. skip_optimization Whether run optimizer running MCMC. rarely need better run get covariance matrix, estimates needed adaptive NUTS. algorithm algorithm use, one \"NUTS\" \"RWM\" skip_monitor Whether skip calculating diagnostics (effective sample size, Rhat) via rstan::monitor function. can slow models high dimension many iterations. result used plots summaries recommended turn . model run skip_monitor=FALSE can recreate post-hoc setting fit$monitor=rstan::monitor(fit$samples, fit$warmup, print=FALSE). skip_unbounded Whether skip returning unbounded version posterior samples addition bounded ones. may advisable set FALSE large models save space. admb_args character string gets passed command line, allowing finer control","code":""},{"path":"/reference/sample_admb.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Deprecated version of wrapper function. Use sample_nuts or sample_rwm instead. — sample_admb","text":"deprecated cease exist   future releases","code":""},{"path":"/reference/sample_inits.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to generate random initial values from a previous fit using adnuts — sample_inits","title":"Function to generate random initial values from a previous fit using adnuts — sample_inits","text":"Function generate random initial values previous fit using adnuts","code":""},{"path":"/reference/sample_inits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to generate random initial values from a previous fit using adnuts — sample_inits","text":"","code":"sample_inits(fit, chains)"},{"path":"/reference/sample_inits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to generate random initial values from a previous fit using adnuts — sample_inits","text":"fit outputted list sample_admb chains number chains subsequent run, determines number return.","code":""},{"path":"/reference/sample_inits.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to generate random initial values from a previous fit using adnuts — sample_inits","text":"list lists can passed back   sample_admb.","code":""},{"path":"/reference/sample_snuts.html","id":null,"dir":"Reference","previous_headings":"","what":"NUTS sampling for TMB models using a sparse metric (BETA). — sample_snuts","title":"NUTS sampling for TMB models using a sparse metric (BETA). — sample_snuts","text":"NUTS sampling TMB models using sparse metric (BETA).","code":""},{"path":"/reference/sample_snuts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NUTS sampling for TMB models using a sparse metric (BETA). — sample_snuts","text":"","code":"sample_snuts(   obj,   num_samples = 1000,   num_warmup = NULL,   chains = 4,   cores = chains,   thin = 1,   adapt_stan_metric = NULL,   control = NULL,   seed = NULL,   laplace = FALSE,   init = c(\"last.par.best\", \"random\", \"random-t\", \"unif\"),   metric = c(\"auto\", \"unit\", \"diag\", \"dense\", \"sparse\", \"stan\", \"sparse-naive\"),   skip_optimization = FALSE,   Q = NULL,   Qinv = NULL,   globals = NULL,   model_name = NULL,   refresh = NULL,   print = TRUE,   rotation_only = FALSE,   iter = 2000,   warmup = floor(iter/2),   ... )"},{"path":"/reference/sample_snuts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"NUTS sampling for TMB models using a sparse metric (BETA). — sample_snuts","text":"obj TMB object random effects turned optimized. num_samples number post-warmup iterations run per chain. num_warmup number warmup iterations run per chain. default NULL indicates automatically determine based settings (recommended). chains Number chains cores Number parallel cores use, defaults chains set 1 execute serial chains. thin thinning rate (defaults 1). adapt_stan_metric boolean whether Stan engage diagonal mass matrix adaptation. default NULL indicates automatically select depending settings. See details. control NUTS control list, currently available options 'adapt_delta', 'max_treedepth', 'metric' type metric adaptation Stan options ('unit_e', 'diag_e', 'dense_e'). dense sparse metrics usually can 'unit_e' skip adaptation. NULL values (default) revert stan_sample defaults. seed Random number seed, used generating initial values ('random\") NUTS. laplace Whether leave Laplace approximation use NUTS sample fixed effects, turn sample joint parameter space (default). init Either 'last.par.best' (default), 'random', 'random-t', 'unif'. former starts joint mode, 'random' 'random-t' draw multivariate normal multivariate t 2 degrees freedom distributions using inverse joint precision matrix covariance matrix. 'random-t' provided allow dispersed initial values. 'unif' draw U(-2,2) samples parameters, similar ot Stan's default behavior. joint NLL undefined initial values model exit return initial vector investigation user, desired. Note StanEstimators::stan_sample allows init vector chains currently. seed specified set thus inits used reproducible. inits also returned 'inits' slot fitted object. metric character specifying metric use. Defaults \"auto\" uses algorithm select best metric (see details), otherwise one \"sparse\", \"dense\", \"diag\", \"unit\", \"Stan\", \"sparse-naive\" can specified. skip_optimization Whether skip optimization (default). Q sparse precision matrix. calculated internally specified (default). Qinv dense matrix (M). calculated internally specified (default). globals named list objects pass new R sessions running parallel using RTMB. Typically `data` object now. model_name optional character giving model name. NULL use DLL name RTMB models just 'RTMB'. name used printing. refresh often print updates console (integer). 0 turn printing. default 100. print Whether print summary run (default) rotation_only Whether return rotation object (debugging purposes) iter (Deprecated) Total iterations run (warmup + sampling) warmup (Deprecated) Total warmup iterations. Defaults iter/2 based Stan defaults, using dense, sparse, diag metrics much shorter warmup can used (e.g., 150), especially paired 'unit_e' Stan metric. Use plot_sampler_params investigate warmup performance adjust necessary subsequent runs. ... Additional arguments pass StanEstimators::stan_sample.","code":""},{"path":"/reference/sample_snuts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"NUTS sampling for TMB models using a sparse metric (BETA). — sample_snuts","text":"fitted MCMC object class 'adfit'","code":""},{"path":"/reference/sample_snuts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"NUTS sampling for TMB models using a sparse metric (BETA). — sample_snuts","text":"TMB metric used decorrelate descale posterior distribution sampling Stan's algorithms. chosen metric reasoning selection printed console sampling begins. Metric Options 'auto': default setting. uses internal    algorithm determine optimal metric model. choice    depends availability precision matrix (\\(Q\\)) /   covariance matrix (\\(M=Q^{-1}\\)), extent parameter    correlations, speed gradient calculations. 'dense' 'sparse': options    decorrelate descale posterior. However,    'sparse' metric computationally efficient    models high-dimensional, sparse precision matrices.    models without random effects 'sparse' option    available 'diag': option descales posterior, using    marginal standard deviations derived covariance matrix    \\(M\\). account correlations. 'unit': option uses identity matrix,    default behavior Stan. Unlike 'Stan' option ,    model still optimized find mode, \\(Q\\) matrix    calculated. ensures full mle object (containing    mode, standard errors, correlations) returned. 'sparse-naive': metric constructed    mathematically equivalent 'dense' often    computationally faster. generally recommended testing    exploration. 'stan': special flag reverts sampler    standard Stan behavior. skips optimization \\(Q\\)    matrix calculations ensures Stan's mass matrix adaptation    engaged warmup. Important Distinction Note metric parameter described specific TMB distinct Stan metric, controlled via control list argument sampling function. Stan default adapts diagonal mass matrix (metric_e) using series expanding windows. Q good estimate global covariance needed disabling Stan's metric adaptation recommended. can done setting `adapt_stan_metric=FALSE`. left NULL Stan's adaptation done metrics 'stan' 'unit' two options descale posterior. case, recommended use longer warmup period account adaptive procedure.","code":""},{"path":"/reference/sample_sparse_tmb.html","id":null,"dir":"Reference","previous_headings":"","what":"Deprecated version of sample_snuts — sample_sparse_tmb","title":"Deprecated version of sample_snuts — sample_sparse_tmb","text":"Deprecated version sample_snuts","code":""},{"path":"/reference/sample_sparse_tmb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deprecated version of sample_snuts — sample_sparse_tmb","text":"","code":"sample_sparse_tmb(...)"},{"path":"/reference/sample_tmb.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian inference of a TMB model using the no-U-turn sampler. — sample_tmb","title":"Bayesian inference of a TMB model using the no-U-turn sampler. — sample_tmb","text":"Draw Bayesian posterior samples Template Model Builder (TMB) model using MCMC algorithm. function generates posterior samples inference can made. Adaptation schemes used specification tuning parameters necessary, parallel execution reduces overall run time.","code":""},{"path":"/reference/sample_tmb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian inference of a TMB model using the no-U-turn sampler. — sample_tmb","text":"","code":"sample_tmb(   obj,   iter = 2000,   init,   chains = 3,   seeds = NULL,   warmup = floor(iter/2),   lower = NULL,   upper = NULL,   thin = 1,   parallel = FALSE,   cores = NULL,   path = NULL,   algorithm = \"NUTS\",   laplace = FALSE,   control = NULL,   ... )"},{"path":"/reference/sample_tmb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian inference of a TMB model using the no-U-turn sampler. — sample_tmb","text":"obj TMB model object. iter number samples draw. init Can either list containing vector chain, function returns vector parameters, NULL specifies use MLE stored admodel.hes file. generally recommended use dispersed initial values improve diagnostic checks (starting point makes less likely find multiple modes). chains number chains run. seeds vector seeds, one chain. warmup number warmup iterations. lower vector lower bounds parameters. Allowed values -Inf numeric. upper vector upper bounds parameters. Allowed values Inf numeric. thin thinning rate apply samples. Typically used NUTS. parallel deprecated argument, use cores=1 serial execution cores>1 parallel (default parallel cores equal available-1) cores number cores use parallel execution. Default number available system minus 1. cores=1, serial execution occurs (even chains>1), otherwise parallel execution via package snowfall used. slow analyses recommended set chains<=cores core needs run single chain. path Path model executable. Defaults working directory. Often best model files separate subdirectory, particularly parallel. algorithm algorithm use. NUTS default recommended one, \"RWM\" random walk Metropolis sampler \"HMC\" static HMC sampler available. last two deprecated may use situations. algorithms require different arguments; see help files information. laplace Whether use Laplace approximation parameters declared random. Default turn functionality integrate across parameters MCMC. control list control sampler. See details use. ... arguments passed samplers","code":""},{"path":"/reference/sample_tmb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian inference of a TMB model using the no-U-turn sampler. — sample_tmb","text":"list containing samples, properties sampler   useful diagnosing behavior efficiency.","code":""},{"path":"/reference/sample_tmb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian inference of a TMB model using the no-U-turn sampler. — sample_tmb","text":"function implements algorithm 6 Hoffman Gelman (2014), loosely follows package rstan. step size can   adapted specified manually. metric (.e., mass matrix) can   unit diagonal, adapted diagonal (default recommended), dense   matrix specified user. control algorithms can   specified control argument.  Elements : adapt_delta target acceptance rate. metric mass metric use. Options : \"unit\" unit diagonal   matrix; \"diag\" estimate diagonal matrix warmup; matrix   used directly (untransformed space). adapt_engaged Whether adaptation step size metric turned . max_treedepth Maximum treedepth NUTS algorithm. stepsize stepsize NUTS algorithm. NULL   adapted warmup.","code":""},{"path":"/reference/sample_tmb.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Bayesian inference of a TMB model using the no-U-turn sampler. — sample_tmb","text":"deprecated cease exist   future releases","code":""},{"path":[]},{"path":"/reference/sample_tmb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Bayesian inference of a TMB model using the no-U-turn sampler. — sample_tmb","text":"Cole Monnahan","code":""},{"path":"/reference/sample_tmb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian inference of a TMB model using the no-U-turn sampler. — sample_tmb","text":"","code":"## Build a fake TMB object with objective & gradient functions and some ## other flags if (FALSE) { # \\dontrun{ f <- function(x, order=0){   if(order != 1) # negative log density     -sum(dnorm(x=x, mean=0, sd=1, log=TRUE))   else x # gradient of negative log density } init <- function() rnorm(2) obj <- list(env=list(DLL='demo', last.par.best=c(x=init()), f=f,   beSilent=function() NULL)) ## Run NUTS for this object fit <- sample_tmb(obj, iter=1000, chains=3, init=init) ## Check basic diagnostics mon <- rstan::monitor(fit$samples, print=FALSE) Rhat <- mon[,\"Rhat\"] max(Rhat) ess <- mon[, 'n_eff'] min(ess) ## Or do it interactively with ShinyStan launch_shinytmb(fit) } # }"},{"path":"/reference/sample_tmb_hmc.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw MCMC samples from a model posterior using a static HMC sampler. — sample_tmb_hmc","title":"Draw MCMC samples from a model posterior using a static HMC sampler. — sample_tmb_hmc","text":"Draw MCMC samples model posterior using static HMC sampler.","code":""},{"path":"/reference/sample_tmb_hmc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw MCMC samples from a model posterior using a static HMC sampler. — sample_tmb_hmc","text":"","code":"sample_tmb_hmc(   iter,   fn,   gr,   init,   L,   eps,   warmup = floor(iter/2),   seed = NULL,   chain = 1,   thin = 1,   control = NULL )"},{"path":"/reference/sample_tmb_hmc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw MCMC samples from a model posterior using a static HMC sampler. — sample_tmb_hmc","text":"iter number samples draw. fn function returns log posterior density. gr function returns vector gradients log posterior density (fn). init Can either list containing vector chain, function returns vector parameters, NULL specifies use MLE stored admodel.hes file. generally recommended use dispersed initial values improve diagnostic checks (starting point makes less likely find multiple modes). L number leapfrog steps take. NUTS algorithm require input. L=1 function perform Langevin sampling. contexts L can roughly thought thinning rate. eps step size. numeric value passed, used throughout entire chain. NULL value initiate sampler_params eps using dual averaging algorithm first warmup steps. warmup number warmup iterations. seed random seed use. chain chain number, printing . thin thinning rate apply samples. Typically used NUTS. control list control sampler. See details use.","code":""},{"path":"/reference/sample_tmb_hmc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw MCMC samples from a model posterior using a static HMC sampler. — sample_tmb_hmc","text":"list containing samples ('par') algorithm details   step size adaptation acceptance probabilities per iteration   ('sampler_params').","code":""},{"path":"/reference/sample_tmb_hmc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Draw MCMC samples from a model posterior using a static HMC sampler. — sample_tmb_hmc","text":"function implements algorithm 5 Hoffman Gelman   (2014), includes adaptive step sizes (eps) via   algorithm called dual averaging.","code":""},{"path":"/reference/sample_tmb_hmc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Draw MCMC samples from a model posterior using a static HMC sampler. — sample_tmb_hmc","text":"Neal, R. M. (2011). MCMC using Hamiltonian   dynamics. Handbook Markov Chain Monte Carlo. Hoffman   Gelman (2014). -U-Turn sampler: Adaptively setting path lengths   Hamiltonian Monte Carlo. J. Mach. Learn. Res.  15:1593-1623. Hoffman Gelman (2014). -U-Turn sampler: Adaptively setting   path lengths Hamiltonian Monte Carlo. J. Mach. Learn. Res.   15:1593-1623.","code":""},{"path":[]},{"path":"/reference/sample_tmb_nuts.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw MCMC samples from a model posterior using the No-U-Turn (NUTS) sampler with dual averaging. — sample_tmb_nuts","title":"Draw MCMC samples from a model posterior using the No-U-Turn (NUTS) sampler with dual averaging. — sample_tmb_nuts","text":"Draw MCMC samples model posterior using -U-Turn (NUTS) sampler dual averaging.","code":""},{"path":"/reference/sample_tmb_nuts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw MCMC samples from a model posterior using the No-U-Turn (NUTS) sampler with dual averaging. — sample_tmb_nuts","text":"","code":"sample_tmb_nuts(   iter,   fn,   gr,   init,   warmup = floor(iter/2),   chain = 1,   thin = 1,   seed = NULL,   control = NULL )"},{"path":"/reference/sample_tmb_nuts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw MCMC samples from a model posterior using the No-U-Turn (NUTS) sampler with dual averaging. — sample_tmb_nuts","text":"iter number samples draw. fn function returns log posterior density. gr function returns vector gradients log posterior density (fn). init Can either list containing vector chain, function returns vector parameters, NULL specifies use MLE stored admodel.hes file. generally recommended use dispersed initial values improve diagnostic checks (starting point makes less likely find multiple modes). warmup number warmup iterations. chain chain number, printing . thin thinning rate apply samples. Typically used NUTS. seed random seed use. control list control sampler. See details use.","code":""},{"path":"/reference/sample_tmb_nuts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Draw MCMC samples from a model posterior using the No-U-Turn (NUTS) sampler with dual averaging. — sample_tmb_nuts","text":"function implements algorithm 6 Hoffman Gelman   (2014), includes adaptive step sizes (eps) via   algorithm called dual averaging. also includes adaptation scheme   tune diagonal mass matrix (metric) warmup. fn gr functions must Jacobians already   applied transformations used.","code":""},{"path":"/reference/sample_tmb_nuts.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Draw MCMC samples from a model posterior using the No-U-Turn (NUTS) sampler with dual averaging. — sample_tmb_nuts","text":"Hoffman Gelman (2014). -U-Turn sampler: Adaptively setting   path lengths Hamiltonian Monte Carlo. J. Mach. Learn. Res.   15:1593-1623.","code":""},{"path":[]},{"path":"/reference/sample_tmb_rwm.html","id":null,"dir":"Reference","previous_headings":"","what":"[Deprecated] Draw MCMC samples from a model posterior using a Random Walk Metropolis (RWM) sampler. — sample_tmb_rwm","title":"[Deprecated] Draw MCMC samples from a model posterior using a Random Walk Metropolis (RWM) sampler. — sample_tmb_rwm","text":"[Deprecated] Draw MCMC samples model posterior using Random Walk Metropolis (RWM) sampler.","code":""},{"path":"/reference/sample_tmb_rwm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"[Deprecated] Draw MCMC samples from a model posterior using a Random Walk Metropolis (RWM) sampler. — sample_tmb_rwm","text":"","code":"sample_tmb_rwm(   iter,   fn,   init,   alpha = 1,   chain = 1,   warmup = floor(iter/2),   thin = 1,   seed = NULL,   control = NULL )"},{"path":"/reference/sample_tmb_rwm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"[Deprecated] Draw MCMC samples from a model posterior using a Random Walk Metropolis (RWM) sampler. — sample_tmb_rwm","text":"iter number samples draw. fn function returns log posterior density. init Can either list containing vector chain, function returns vector parameters, NULL specifies use MLE stored admodel.hes file. generally recommended use dispersed initial values improve diagnostic checks (starting point makes less likely find multiple modes). alpha amount scale proposal, .e, Xnew=Xcur+alpha*Xproposed Xproposed generated mean-zero multivariate normal. Varying alpha varies acceptance rate. chain chain number, printing . warmup number warmup iterations. thin thinning rate apply samples. Typically used NUTS. seed random seed use. control list control sampler. See details use.","code":""},{"path":"/reference/sample_tmb_rwm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"[Deprecated] Draw MCMC samples from a model posterior using a Random Walk Metropolis (RWM) sampler. — sample_tmb_rwm","text":"list containing samples metadata.","code":""},{"path":"/reference/sample_tmb_rwm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"[Deprecated] Draw MCMC samples from a model posterior using a Random Walk Metropolis (RWM) sampler. — sample_tmb_rwm","text":"algorithm yet contain adaptation alpha trial error may required efficient sampling.","code":""},{"path":"/reference/sample_tmb_rwm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"[Deprecated] Draw MCMC samples from a model posterior using a Random Walk Metropolis (RWM) sampler. — sample_tmb_rwm","text":"Metropolis, N., Rosenbluth, .W., Rosenbluth, M.N., Teller, .H.,   Teller, E., 1953. Equation state calculations fast computing   machines.  J Chem Phys. 21:1087-1092.","code":""},{"path":[]},{"path":"/reference/summary.adfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Print summary of object of class adfit — summary.adfit","title":"Print summary of object of class adfit — summary.adfit","text":"Print summary object class adfit","code":""},{"path":"/reference/summary.adfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print summary of object of class adfit — summary.adfit","text":"","code":"# S3 method for class 'adfit' summary(object, ...)"},{"path":"/reference/summary.adfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print summary of object of class adfit — summary.adfit","text":"object Fitted object sample_admb ... Ignored","code":""},{"path":"/reference/summary.adfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print summary of object of class adfit — summary.adfit","text":"Summary printed screen","code":""},{"path":"/reference/wrappers.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian inference of an ADMB model using the no-U-turn sampler (NUTS) or random walk Metropolis (RWM) algorithms. — sample_nuts","title":"Bayesian inference of an ADMB model using the no-U-turn sampler (NUTS) or random walk Metropolis (RWM) algorithms. — sample_nuts","text":"Draw Bayesian posterior samples AD Model Builder (ADMB) model using MCMC algorithm. `sample_nuts` `sample_rwm` generates posterior samples inference can made.","code":""},{"path":"/reference/wrappers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian inference of an ADMB model using the no-U-turn sampler (NUTS) or random walk Metropolis (RWM) algorithms. — sample_nuts","text":"","code":"sample_nuts(   model,   path = getwd(),   iter = 2000,   init = NULL,   chains = 3,   warmup = NULL,   seeds = NULL,   thin = 1,   mceval = FALSE,   duration = NULL,   parallel = FALSE,   cores = NULL,   control = NULL,   skip_optimization = TRUE,   verbose = TRUE,   skip_monitor = FALSE,   skip_unbounded = TRUE,   admb_args = NULL,   extra.args = NULL )  sample_rwm(   model,   path = getwd(),   iter = 2000,   init = NULL,   chains = 3,   warmup = NULL,   seeds = NULL,   thin = 1,   mceval = FALSE,   duration = NULL,   parallel = FALSE,   cores = NULL,   control = NULL,   skip_optimization = TRUE,   verbose = TRUE,   skip_monitor = FALSE,   skip_unbounded = TRUE,   admb_args = NULL,   extra.args = NULL )"},{"path":"/reference/wrappers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian inference of an ADMB model using the no-U-turn sampler (NUTS) or random walk Metropolis (RWM) algorithms. — sample_nuts","text":"model Name model (.e., 'model' model.tpl). non-Windows systems automatically converted './model' internally. Windows, long file names sometimes shortened e.g., 'long_model_filename' 'LONG_~1'. work, throw warnings. Please shorten model name. See https://en.wikipedia.org/wiki/8.3_filename. path Path model executable. Defaults working directory. Often best model files separate subdirectory, particularly parallel. iter number samples draw. init Can either list containing vector chain, function returns vector parameters, NULL specifies use MLE stored admodel.hes file. generally recommended use dispersed initial values improve diagnostic checks (starting point makes less likely find multiple modes). chains number chains run. warmup number warmup iterations. seeds vector seeds, one chain. thin thinning rate apply samples. Typically used NUTS. mceval Whether run model -mceval samples merged chains. duration number minutes model quit running. recommended set warmup carefully iter higher expected runs duration. usually results chains different lengths, minimum taken across . parallel deprecated argument, use cores=1 serial execution cores>1 parallel (default parallel cores equal available-1) cores number cores use parallel execution. Default number available system minus 1. cores=1, serial execution occurs (even chains>1), otherwise parallel execution via package snowfall used. slow analyses recommended set chains<=cores core needs run single chain. control list control sampler. See details use. skip_optimization Whether run optimizer running MCMC. rarely need better run get covariance matrix, estimates needed adaptive NUTS. verbose Flag whether show console output (default) suppress completely except warnings errors. Works serial parallel execution. skip_monitor Whether skip calculating diagnostics (effective sample size, Rhat) via rstan::monitor function. can slow models high dimension many iterations. result used plots summaries recommended turn . model run skip_monitor=FALSE can recreate post-hoc setting fit$monitor=rstan::monitor(fit$samples, fit$warmup, print=FALSE). skip_unbounded Whether skip returning unbounded version posterior samples addition bounded ones. may advisable set FALSE large models save space. admb_args character string gets passed command line, allowing finer control extra.args Deprecated, use admb_args instead.","code":""},{"path":"/reference/wrappers.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian inference of an ADMB model using the no-U-turn sampler (NUTS) or random walk Metropolis (RWM) algorithms. — sample_nuts","text":"Adaptation schemes used NUTS specifying tuning parameters necessary. See vignette options adaptation step size mass matrix.  RWM algorithm provides new functionality available previous versions ADMB. However, `sample_rwm` improved console output, setup parallel execution, smooth workflow diagnostics. Parallel chains run argument `cores` greater one. entails copying folder, starting new R session run chain, merged back together. Note console output inconsistent using parallel, may show. Windows R terminal shows output live, GUI . RStudio special case show live, instead captured returned end. strongly recommended start serial execution debugging parallel chains difficult. Note algorithm code ADMB source code, 'adnuts' provides wrapper . command line arguments returned can examined user. See vignette information. function implements algorithm 6 Hoffman Gelman (2014), loosely follows package rstan. step size can   adapted specified manually. metric (.e., mass matrix) can   unit diagonal, adapted diagonal (default recommended), dense   matrix specified user, adapted dense matrix.  control algorithms can   specified control argument.  Elements : adapt_delta target acceptance rate, values   closer 1 forcing smaller step sizes. Defaults 0.8. metric mass metric use. Options : \"unit\" unit diagonal   matrix; NULL estimate diagonal matrix warmup; matrix   used directly (untransformed space). adapt_mass Whether adaptation diagonal mass matrix turned   . adapt_mass_dense Whether dense adaptation mass   matrix turned . max_treedepth Maximum treedepth NUTS algorithm. stepsize stepsize NUTS algorithm. NULL   adapted warmup. adapt_init_buffer initial buffer size mass matrix   adaptation sample information used (default   50) adapt_term_buffer terminal buffer size (default 75)   mass   matrix adaptation (final fast phase) adapt_window initial size mass matrix   adaptation window, gets doubled time thereafter. refresh rate refresh progress   console. Defaults even 10   progress updates. adaptation scheme (step size mass matrix) based heavily   software Stan, details can found   documentation vignette.","code":""},{"path":"/reference/wrappers.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Bayesian inference of an ADMB model using the no-U-turn sampler (NUTS) or random walk Metropolis (RWM) algorithms. — sample_nuts","text":"user responsible specifying   model properly (priors, starting values, desired parameters   fixed, etc.), well assessing convergence   validity resulting samples (e.g.,   coda package), function   launch_shinytmb making   inference. Specifically, priors must specified   template file parameter. Unspecified priors   implicitly uniform.","code":""},{"path":"/reference/wrappers.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Bayesian inference of an ADMB model using the no-U-turn sampler (NUTS) or random walk Metropolis (RWM) algorithms. — sample_nuts","text":"Cole Monnahan","code":""},{"path":"/reference/wrappers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian inference of an ADMB model using the no-U-turn sampler (NUTS) or random walk Metropolis (RWM) algorithms. — sample_nuts","text":"","code":"if (FALSE) { # \\dontrun{ ## This is the packaged simple regression model path.simple <- system.file('examples', 'simple', package='adnuts') ## It is best to have your ADMB files in a separate folder and provide that ## path, so make a copy of the model folder locally. path <- 'simple' dir.create(path) trash <- file.copy(from=list.files(path.simple, full.names=TRUE), to=path) ## Compile and run model oldwd <- getwd() setwd(path) system('admb simple.tpl') system('simple') setwd('..') init <- function() rnorm(2) ## Run NUTS with defaults fit <- sample_nuts(model='simple', init=init, path=path) unlink(path, TRUE) # cleanup folder setwd(oldwd) } # }"},{"path":"/news/index.html","id":"adnuts-1129000-development","dir":"Changelog","previous_headings":"","what":"adnuts 1.1.2.9000 (development)","title":"adnuts 1.1.2.9000 (development)","text":"Add sparse NUTS option TMB & RTMB models, shift focus package back TMB. Main function sample_snuts defaults automatically detect metric set warmup samples use. Update pairs_admb function S3 method pairs add ‘mismatch’ ‘cor’ options order, argument add.inits plot initial values. Add plot_Q function. Cleaned console output Minor bug fixes improvements","code":""},{"path":"/news/index.html","id":"adnuts-112-2021-03-02","dir":"Changelog","previous_headings":"","what":"adnuts 1.1.2 (2021-03-02)","title":"adnuts 1.1.2 (2021-03-02)","text":"CRAN release: 2021-03-02 Improve console output RStudio users. broken NUTS chains serial. Add new argument ‘verbose’ suppresses almost console output set FALSE Update demo file, vignette README preparation submission CRAN Add new function plot_uncertainties Expand continuous testing Add slot ‘par_names’ objects type adfit","code":""},{"path":"/news/index.html","id":"adnuts-111-2021-02-19","dir":"Changelog","previous_headings":"","what":"adnuts 1.1.1 (2021-02-19)","title":"adnuts 1.1.1 (2021-02-19)","text":"Add slot par_names adfit objects Add method .data.frame class adfit Improved expanded testing via continuous integration Print ADMB command console fails run properly help user diagnose issues Improve console output RStudio users. now print conclusion parallel runs. Fix bugs model names MacOS (use ./model instead model internally) Fix small bug mceval=TRUE newest version stock synthesis Fix sample_tmb work short-term use","code":""},{"path":"/news/index.html","id":"adnuts-110-2020-07-13","dir":"Changelog","previous_headings":"","what":"adnuts 1.1.0 (2020-07-13)","title":"adnuts 1.1.0 (2020-07-13)","text":"Change sample_admb sample_nuts sample_rwm run NUTS RWM algorithms, respectively. Rework metric options allow user access ADMB 12.2’s new dense mass matrix adaptation scheme. Added new section demonstrating vignette. Add control via ‘skip_monitor’, ‘skip_unbounded’, ‘skip_optimization’ arguments Remove TMB references documentation vignette, instead pointing users package ‘tmbstan’, collate deprecated R code single file Migrate new github repo: github.com/Cole-Monnahan-NOAA per NOAA’s policy Add testing via testthat package Turn calculation ESS Rhat manually, get used subsequent functions Created S3 class ‘adfit’ generic methods print, summary, plot Updated pairs_admb ‘order’ argument quickly plotting slow/fast parameters Add new function plot_marginals quickly plotting posterior histograms Add new function plot_sampler_params plot NUTS sampling Make parallel default deprecate ‘parallel’ argument. Fix bug parallel path failed absolute. Now can relative absolute. Add check valid version ADMB Minor bug fixes documentation updates Improve error handling testing routines","code":""},{"path":"/news/index.html","id":"adnuts-101-2019-03-15","dir":"Changelog","previous_headings":"","what":"adnuts 1.0.1 (2019-03-15)","title":"adnuts 1.0.1 (2019-03-15)","text":"CRAN release: 2019-04-04 Update ADMB algorithms use “-maxfn 0 -phase 1000” instead “-noest”. helps Stock Synthesis likely models initialization skipped -noest can lead unusual undesirable behavior. Also changed behavior inits=NULL pull MLE values admodel.hes file instead pulling .par file inits. fixes models negative phases used. Add function check_identifiable examines .hes file reports parameters well identified. Add function sample_inits generate inits previous fitted object. Read MLE values .hes file inits=NULL, instead .par file. Add informative errors common issues. Minor bug fixes updates.","code":""},{"path":"/news/index.html","id":"adnuts-100-2018-02-04","dir":"Changelog","previous_headings":"","what":"adnuts 1.0.0 (2018-02-04)","title":"adnuts 1.0.0 (2018-02-04)","text":"CRAN release: 2018-02-08 Initial release.","code":""}]
